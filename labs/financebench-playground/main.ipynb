{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade40fc8",
   "metadata": {},
   "source": [
    "# General Tips\n",
    "## Using virtual environments\n",
    "**Step 1:** CD to desired directory and Create a Virtual Environment `python3 -m venv myenv`. (Run `py -3.13 -m venv myenv` for a specific version of python)\n",
    "\n",
    "Check your python installed versions with `py -0` on Windows (`python3 --version` on Linux)\n",
    "\n",
    "**Step 2:** Activate the Environment `source myenv/bin/activate` (on Linux) and `myenv\\Scripts\\activate` (on Windows).\n",
    "\n",
    "**Step 3:** Install Any Needed Packages. e.g: `pip install requests pandas`. Or better to use `requirements.txt` file (`pip install -r requirements.txt`)\n",
    "\n",
    "**Step 4:** List All Installed Packages using `pip list`\n",
    "\n",
    "## Connecting the Jupyter Notebook to the vistual env\n",
    "1. Make sure that myenv is activate (`myenv\\Scripts\\activate`)\n",
    "2. Run this inside the virtual environment: `pip install ipykernel`\n",
    "3. Still inside the environment: `python -m ipykernel install --user --name=myenv --display-name \"Whatever Python Kernel Name\"`\n",
    "   \n",
    "   --name=myenv: internal identifier for the kernel\n",
    "   \n",
    "   --display-name: name that shows up in VS Code kernel picker\n",
    "4. Open VS Code and select the kernel\n",
    "\n",
    "   At the top-right, click \"Select Kernel\".\n",
    "   Look for “Whatever Python Kernel Name” — pick that.\n",
    "5. If you don’t see it right away, try: Reloading VS Code, Or running Reload Window from Command Palette (Ctrl+Shift+P)\n",
    "\n",
    "## Useful Commands\n",
    "1. Use `py -0` to check which python installation we have on Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c85eb",
   "metadata": {},
   "source": [
    "## Step 0: Setup Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49666301",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"nomic-embed-text\"\n",
    "chunk_sizes = [128, 256, 512, 1024]\n",
    "chunk_overlap_percentage = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe242c59",
   "metadata": {},
   "source": [
    "# Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e8ba30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehrdad/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"PatronusAI/financebench\", split=\"train\")\n",
    "\n",
    "# Define PDF directory path\n",
    "pdf_dir = \"../pdfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16e2f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records:  150\n",
      "Keys:  {'financebench_id': 'financebench_id_03029', 'company': '3M', 'doc_name': '3M_2018_10K', 'question_type': 'metrics-generated', 'question_reasoning': 'Information extraction', 'domain_question_num': None, 'question': 'What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the question by relying on the details shown in the cash flow statement.', 'answer': '$1577.00', 'justification': 'The metric capital expenditures was directly extracted from the company 10K. The line item name, as seen in the 10K, was: Purchases of property, plant and equipment (PP&E).', 'dataset_subset_label': 'OPEN_SOURCE', 'evidence': [{'evidence_text': 'Table of Contents \\n3M Company and Subsidiaries\\nConsolidated Statement of Cash Flow s\\nYears ended December 31\\n \\n(Millions)\\n \\n2018\\n \\n2017\\n \\n2016\\n \\nCash Flows from Operating Activities\\n \\n \\n \\n \\n \\n \\n \\nNet income including noncontrolling interest\\n \\n$\\n5,363 \\n$\\n4,869 \\n$\\n5,058 \\nAdjustments to reconcile net income including noncontrolling interest to net cash\\nprovided by operating activities\\n \\n \\n \\n \\n \\n \\n \\nDepreciation and amortization\\n \\n \\n1,488 \\n \\n1,544 \\n \\n1,474 \\nCompany pension and postretirement contributions\\n \\n \\n(370) \\n \\n(967) \\n \\n(383) \\nCompany pension and postretirement expense\\n \\n \\n410 \\n \\n334 \\n \\n250 \\nStock-based compensation expense\\n \\n \\n302 \\n \\n324 \\n \\n298 \\nGain on sale of businesses\\n \\n \\n(545) \\n \\n(586) \\n \\n(111) \\nDeferred income taxes\\n \\n \\n(57) \\n \\n107 \\n \\n 7 \\nChanges in assets and liabilities\\n \\n \\n \\n \\n \\n \\n \\nAccounts receivable\\n \\n \\n(305) \\n \\n(245) \\n \\n(313) \\nInventories\\n \\n \\n(509) \\n \\n(387) \\n \\n57 \\nAccounts payable\\n \\n \\n408 \\n \\n24 \\n \\n148 \\nAccrued income taxes (current and long-term)\\n \\n \\n134 \\n \\n967 \\n \\n101 \\nOther net\\n \\n \\n120 \\n \\n256 \\n \\n76 \\nNet cash provided by (used in) operating activities\\n \\n \\n6,439 \\n \\n6,240 \\n \\n6,662 \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Investing Activities\\n \\n \\n \\n \\n \\n \\n \\nPurchases of property, plant and equipment (PP&E)\\n \\n \\n(1,577) \\n \\n(1,373) \\n \\n(1,420) \\nProceeds from sale of PP&E and other assets\\n \\n \\n262 \\n \\n49 \\n \\n58 \\nAcquisitions, net of cash acquired\\n \\n \\n13 \\n \\n(2,023) \\n \\n(16) \\nPurchases of marketable securities and investments\\n \\n \\n(1,828) \\n \\n(2,152) \\n \\n(1,410) \\nProceeds from maturities and sale of marketable securities and investments\\n \\n \\n2,497 \\n \\n1,354 \\n \\n1,247 \\nProceeds from sale of businesses, net of cash sold\\n \\n \\n846 \\n \\n1,065 \\n \\n142 \\nOther net\\n \\n \\n 9 \\n \\n(6) \\n \\n(4) \\nNet cash provided by (used in) investing activities\\n \\n \\n222 \\n \\n(3,086) \\n \\n(1,403) \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Financing Activities\\n \\n \\n \\n \\n \\n \\n \\nChange in short-term debt net\\n \\n \\n(284) \\n \\n578 \\n \\n(797) \\nRepayment of debt (maturities greater than 90 days)\\n \\n \\n(1,034) \\n \\n(962) \\n \\n(992) \\nProceeds from debt (maturities greater than 90 days)\\n \\n \\n2,251 \\n \\n1,987 \\n \\n2,832 \\nPurchases of treasury stock\\n \\n \\n(4,870) \\n \\n(2,068) \\n \\n(3,753) \\nProceeds from issuance of treasury stock pursuant to stock option and benefit plans\\n \\n \\n485 \\n \\n734 \\n \\n804 \\nDividends paid to shareholders\\n \\n \\n(3,193) \\n \\n(2,803) \\n \\n(2,678) \\nOther net\\n \\n \\n(56) \\n \\n(121) \\n \\n(42) \\nNet cash provided by (used in) financing activities\\n \\n \\n(6,701) \\n \\n(2,655) \\n \\n(4,626) \\n \\n \\n \\n \\n \\n \\n \\n \\nEffect of exchange rate changes on cash and cash equivalents\\n \\n \\n(160) \\n \\n156 \\n \\n(33) \\n \\n \\n \\n \\n \\n \\n \\n \\nNet increase (decrease) in cash and cash equivalents\\n \\n \\n(200) \\n \\n655 \\n \\n600 \\nCash and cash equivalents at beginning of year\\n \\n \\n3,053 \\n \\n2,398 \\n \\n1,798 \\nCash and cash equivalents at end of period\\n \\n$\\n2,853 \\n$\\n3,053 \\n$\\n2,398 \\n \\nThe accompanying Notes to Consolidated Financial Statements are an integral part of this statement.\\n \\n60', 'doc_name': '3M_2018_10K', 'evidence_page_num': 59, 'evidence_text_full_page': 'Table of Contents \\n3M Company and Subsidiaries\\nConsolidated Statement of Cash Flow s\\nYears ended December 31\\n \\n(Millions)\\n \\n2018\\n \\n2017\\n \\n2016\\n \\nCash Flows from Operating Activities\\n \\n \\n \\n \\n \\n \\n \\nNet income including noncontrolling interest\\n \\n$\\n5,363 \\n$\\n4,869 \\n$\\n5,058 \\nAdjustments to reconcile net income including noncontrolling interest to net cash\\nprovided by operating activities\\n \\n \\n \\n \\n \\n \\n \\nDepreciation and amortization\\n \\n \\n1,488 \\n \\n1,544 \\n \\n1,474 \\nCompany pension and postretirement contributions\\n \\n \\n(370) \\n \\n(967) \\n \\n(383) \\nCompany pension and postretirement expense\\n \\n \\n410 \\n \\n334 \\n \\n250 \\nStock-based compensation expense\\n \\n \\n302 \\n \\n324 \\n \\n298 \\nGain on sale of businesses\\n \\n \\n(545) \\n \\n(586) \\n \\n(111) \\nDeferred income taxes\\n \\n \\n(57) \\n \\n107 \\n \\n 7 \\nChanges in assets and liabilities\\n \\n \\n \\n \\n \\n \\n \\nAccounts receivable\\n \\n \\n(305) \\n \\n(245) \\n \\n(313) \\nInventories\\n \\n \\n(509) \\n \\n(387) \\n \\n57 \\nAccounts payable\\n \\n \\n408 \\n \\n24 \\n \\n148 \\nAccrued income taxes (current and long-term)\\n \\n \\n134 \\n \\n967 \\n \\n101 \\nOther net\\n \\n \\n120 \\n \\n256 \\n \\n76 \\nNet cash provided by (used in) operating activities\\n \\n \\n6,439 \\n \\n6,240 \\n \\n6,662 \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Investing Activities\\n \\n \\n \\n \\n \\n \\n \\nPurchases of property, plant and equipment (PP&E)\\n \\n \\n(1,577) \\n \\n(1,373) \\n \\n(1,420) \\nProceeds from sale of PP&E and other assets\\n \\n \\n262 \\n \\n49 \\n \\n58 \\nAcquisitions, net of cash acquired\\n \\n \\n13 \\n \\n(2,023) \\n \\n(16) \\nPurchases of marketable securities and investments\\n \\n \\n(1,828) \\n \\n(2,152) \\n \\n(1,410) \\nProceeds from maturities and sale of marketable securities and investments\\n \\n \\n2,497 \\n \\n1,354 \\n \\n1,247 \\nProceeds from sale of businesses, net of cash sold\\n \\n \\n846 \\n \\n1,065 \\n \\n142 \\nOther net\\n \\n \\n 9 \\n \\n(6) \\n \\n(4) \\nNet cash provided by (used in) investing activities\\n \\n \\n222 \\n \\n(3,086) \\n \\n(1,403) \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Financing Activities\\n \\n \\n \\n \\n \\n \\n \\nChange in short-term debt net\\n \\n \\n(284) \\n \\n578 \\n \\n(797) \\nRepayment of debt (maturities greater than 90 days)\\n \\n \\n(1,034) \\n \\n(962) \\n \\n(992) \\nProceeds from debt (maturities greater than 90 days)\\n \\n \\n2,251 \\n \\n1,987 \\n \\n2,832 \\nPurchases of treasury stock\\n \\n \\n(4,870) \\n \\n(2,068) \\n \\n(3,753) \\nProceeds from issuance of treasury stock pursuant to stock option and benefit plans\\n \\n \\n485 \\n \\n734 \\n \\n804 \\nDividends paid to shareholders\\n \\n \\n(3,193) \\n \\n(2,803) \\n \\n(2,678) \\nOther net\\n \\n \\n(56) \\n \\n(121) \\n \\n(42) \\nNet cash provided by (used in) financing activities\\n \\n \\n(6,701) \\n \\n(2,655) \\n \\n(4,626) \\n \\n \\n \\n \\n \\n \\n \\n \\nEffect of exchange rate changes on cash and cash equivalents\\n \\n \\n(160) \\n \\n156 \\n \\n(33) \\n \\n \\n \\n \\n \\n \\n \\n \\nNet increase (decrease) in cash and cash equivalents\\n \\n \\n(200) \\n \\n655 \\n \\n600 \\nCash and cash equivalents at beginning of year\\n \\n \\n3,053 \\n \\n2,398 \\n \\n1,798 \\nCash and cash equivalents at end of period\\n \\n$\\n2,853 \\n$\\n3,053 \\n$\\n2,398 \\n \\nThe accompanying Notes to Consolidated Financial Statements are an integral part of this statement.\\n \\n60\\n \\n'}], 'gics_sector': 'Industrials', 'doc_type': '10k', 'doc_period': 2018, 'doc_link': 'https://investors.3m.com/financials/sec-filings/content/0001558370-19-000470/0001558370-19-000470.pdf'}\n",
      "Dataset [0]:  {'financebench_id': 'financebench_id_03029', 'company': '3M', 'doc_name': '3M_2018_10K', 'question_type': 'metrics-generated', 'question_reasoning': 'Information extraction', 'domain_question_num': None, 'question': 'What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the question by relying on the details shown in the cash flow statement.', 'answer': '$1577.00', 'justification': 'The metric capital expenditures was directly extracted from the company 10K. The line item name, as seen in the 10K, was: Purchases of property, plant and equipment (PP&E).', 'dataset_subset_label': 'OPEN_SOURCE', 'evidence': [{'evidence_text': 'Table of Contents \\n3M Company and Subsidiaries\\nConsolidated Statement of Cash Flow s\\nYears ended December 31\\n \\n(Millions)\\n \\n2018\\n \\n2017\\n \\n2016\\n \\nCash Flows from Operating Activities\\n \\n \\n \\n \\n \\n \\n \\nNet income including noncontrolling interest\\n \\n$\\n5,363 \\n$\\n4,869 \\n$\\n5,058 \\nAdjustments to reconcile net income including noncontrolling interest to net cash\\nprovided by operating activities\\n \\n \\n \\n \\n \\n \\n \\nDepreciation and amortization\\n \\n \\n1,488 \\n \\n1,544 \\n \\n1,474 \\nCompany pension and postretirement contributions\\n \\n \\n(370) \\n \\n(967) \\n \\n(383) \\nCompany pension and postretirement expense\\n \\n \\n410 \\n \\n334 \\n \\n250 \\nStock-based compensation expense\\n \\n \\n302 \\n \\n324 \\n \\n298 \\nGain on sale of businesses\\n \\n \\n(545) \\n \\n(586) \\n \\n(111) \\nDeferred income taxes\\n \\n \\n(57) \\n \\n107 \\n \\n 7 \\nChanges in assets and liabilities\\n \\n \\n \\n \\n \\n \\n \\nAccounts receivable\\n \\n \\n(305) \\n \\n(245) \\n \\n(313) \\nInventories\\n \\n \\n(509) \\n \\n(387) \\n \\n57 \\nAccounts payable\\n \\n \\n408 \\n \\n24 \\n \\n148 \\nAccrued income taxes (current and long-term)\\n \\n \\n134 \\n \\n967 \\n \\n101 \\nOther net\\n \\n \\n120 \\n \\n256 \\n \\n76 \\nNet cash provided by (used in) operating activities\\n \\n \\n6,439 \\n \\n6,240 \\n \\n6,662 \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Investing Activities\\n \\n \\n \\n \\n \\n \\n \\nPurchases of property, plant and equipment (PP&E)\\n \\n \\n(1,577) \\n \\n(1,373) \\n \\n(1,420) \\nProceeds from sale of PP&E and other assets\\n \\n \\n262 \\n \\n49 \\n \\n58 \\nAcquisitions, net of cash acquired\\n \\n \\n13 \\n \\n(2,023) \\n \\n(16) \\nPurchases of marketable securities and investments\\n \\n \\n(1,828) \\n \\n(2,152) \\n \\n(1,410) \\nProceeds from maturities and sale of marketable securities and investments\\n \\n \\n2,497 \\n \\n1,354 \\n \\n1,247 \\nProceeds from sale of businesses, net of cash sold\\n \\n \\n846 \\n \\n1,065 \\n \\n142 \\nOther net\\n \\n \\n 9 \\n \\n(6) \\n \\n(4) \\nNet cash provided by (used in) investing activities\\n \\n \\n222 \\n \\n(3,086) \\n \\n(1,403) \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Financing Activities\\n \\n \\n \\n \\n \\n \\n \\nChange in short-term debt net\\n \\n \\n(284) \\n \\n578 \\n \\n(797) \\nRepayment of debt (maturities greater than 90 days)\\n \\n \\n(1,034) \\n \\n(962) \\n \\n(992) \\nProceeds from debt (maturities greater than 90 days)\\n \\n \\n2,251 \\n \\n1,987 \\n \\n2,832 \\nPurchases of treasury stock\\n \\n \\n(4,870) \\n \\n(2,068) \\n \\n(3,753) \\nProceeds from issuance of treasury stock pursuant to stock option and benefit plans\\n \\n \\n485 \\n \\n734 \\n \\n804 \\nDividends paid to shareholders\\n \\n \\n(3,193) \\n \\n(2,803) \\n \\n(2,678) \\nOther net\\n \\n \\n(56) \\n \\n(121) \\n \\n(42) \\nNet cash provided by (used in) financing activities\\n \\n \\n(6,701) \\n \\n(2,655) \\n \\n(4,626) \\n \\n \\n \\n \\n \\n \\n \\n \\nEffect of exchange rate changes on cash and cash equivalents\\n \\n \\n(160) \\n \\n156 \\n \\n(33) \\n \\n \\n \\n \\n \\n \\n \\n \\nNet increase (decrease) in cash and cash equivalents\\n \\n \\n(200) \\n \\n655 \\n \\n600 \\nCash and cash equivalents at beginning of year\\n \\n \\n3,053 \\n \\n2,398 \\n \\n1,798 \\nCash and cash equivalents at end of period\\n \\n$\\n2,853 \\n$\\n3,053 \\n$\\n2,398 \\n \\nThe accompanying Notes to Consolidated Financial Statements are an integral part of this statement.\\n \\n60', 'doc_name': '3M_2018_10K', 'evidence_page_num': 59, 'evidence_text_full_page': 'Table of Contents \\n3M Company and Subsidiaries\\nConsolidated Statement of Cash Flow s\\nYears ended December 31\\n \\n(Millions)\\n \\n2018\\n \\n2017\\n \\n2016\\n \\nCash Flows from Operating Activities\\n \\n \\n \\n \\n \\n \\n \\nNet income including noncontrolling interest\\n \\n$\\n5,363 \\n$\\n4,869 \\n$\\n5,058 \\nAdjustments to reconcile net income including noncontrolling interest to net cash\\nprovided by operating activities\\n \\n \\n \\n \\n \\n \\n \\nDepreciation and amortization\\n \\n \\n1,488 \\n \\n1,544 \\n \\n1,474 \\nCompany pension and postretirement contributions\\n \\n \\n(370) \\n \\n(967) \\n \\n(383) \\nCompany pension and postretirement expense\\n \\n \\n410 \\n \\n334 \\n \\n250 \\nStock-based compensation expense\\n \\n \\n302 \\n \\n324 \\n \\n298 \\nGain on sale of businesses\\n \\n \\n(545) \\n \\n(586) \\n \\n(111) \\nDeferred income taxes\\n \\n \\n(57) \\n \\n107 \\n \\n 7 \\nChanges in assets and liabilities\\n \\n \\n \\n \\n \\n \\n \\nAccounts receivable\\n \\n \\n(305) \\n \\n(245) \\n \\n(313) \\nInventories\\n \\n \\n(509) \\n \\n(387) \\n \\n57 \\nAccounts payable\\n \\n \\n408 \\n \\n24 \\n \\n148 \\nAccrued income taxes (current and long-term)\\n \\n \\n134 \\n \\n967 \\n \\n101 \\nOther net\\n \\n \\n120 \\n \\n256 \\n \\n76 \\nNet cash provided by (used in) operating activities\\n \\n \\n6,439 \\n \\n6,240 \\n \\n6,662 \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Investing Activities\\n \\n \\n \\n \\n \\n \\n \\nPurchases of property, plant and equipment (PP&E)\\n \\n \\n(1,577) \\n \\n(1,373) \\n \\n(1,420) \\nProceeds from sale of PP&E and other assets\\n \\n \\n262 \\n \\n49 \\n \\n58 \\nAcquisitions, net of cash acquired\\n \\n \\n13 \\n \\n(2,023) \\n \\n(16) \\nPurchases of marketable securities and investments\\n \\n \\n(1,828) \\n \\n(2,152) \\n \\n(1,410) \\nProceeds from maturities and sale of marketable securities and investments\\n \\n \\n2,497 \\n \\n1,354 \\n \\n1,247 \\nProceeds from sale of businesses, net of cash sold\\n \\n \\n846 \\n \\n1,065 \\n \\n142 \\nOther net\\n \\n \\n 9 \\n \\n(6) \\n \\n(4) \\nNet cash provided by (used in) investing activities\\n \\n \\n222 \\n \\n(3,086) \\n \\n(1,403) \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Financing Activities\\n \\n \\n \\n \\n \\n \\n \\nChange in short-term debt net\\n \\n \\n(284) \\n \\n578 \\n \\n(797) \\nRepayment of debt (maturities greater than 90 days)\\n \\n \\n(1,034) \\n \\n(962) \\n \\n(992) \\nProceeds from debt (maturities greater than 90 days)\\n \\n \\n2,251 \\n \\n1,987 \\n \\n2,832 \\nPurchases of treasury stock\\n \\n \\n(4,870) \\n \\n(2,068) \\n \\n(3,753) \\nProceeds from issuance of treasury stock pursuant to stock option and benefit plans\\n \\n \\n485 \\n \\n734 \\n \\n804 \\nDividends paid to shareholders\\n \\n \\n(3,193) \\n \\n(2,803) \\n \\n(2,678) \\nOther net\\n \\n \\n(56) \\n \\n(121) \\n \\n(42) \\nNet cash provided by (used in) financing activities\\n \\n \\n(6,701) \\n \\n(2,655) \\n \\n(4,626) \\n \\n \\n \\n \\n \\n \\n \\n \\nEffect of exchange rate changes on cash and cash equivalents\\n \\n \\n(160) \\n \\n156 \\n \\n(33) \\n \\n \\n \\n \\n \\n \\n \\n \\nNet increase (decrease) in cash and cash equivalents\\n \\n \\n(200) \\n \\n655 \\n \\n600 \\nCash and cash equivalents at beginning of year\\n \\n \\n3,053 \\n \\n2,398 \\n \\n1,798 \\nCash and cash equivalents at end of period\\n \\n$\\n2,853 \\n$\\n3,053 \\n$\\n2,398 \\n \\nThe accompanying Notes to Consolidated Financial Statements are an integral part of this statement.\\n \\n60\\n \\n'}], 'gics_sector': 'Industrials', 'doc_type': '10k', 'doc_period': 2018, 'doc_link': 'https://investors.3m.com/financials/sec-filings/content/0001558370-19-000470/0001558370-19-000470.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Records: \", len(ds))\n",
    "print(\"Keys: \", ds[0])\n",
    "print(\"Dataset [0]: \", ds[0])\n",
    "\n",
    "# print(\"List of document links:\")\n",
    "# counter = 0\n",
    "# for doc in ds:\n",
    "#     counter += 1\n",
    "#     print(f\"{counter}: {doc['doc_link']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce91e89",
   "metadata": {},
   "source": [
    "## Verify if all of the pdfs are in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f31deff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique PDF files required: 84\n",
      "Total missing PDF files: 0\n",
      "All required PDF files are present.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Track missing and unique PDF filenames\n",
    "unique_pdfs = set()\n",
    "missing_pdfs = []\n",
    "\n",
    "# Collect unique PDF filenames from the dataset\n",
    "for record in ds:\n",
    "    pdf_filename = record[\"doc_name\"] + \".pdf\"\n",
    "    unique_pdfs.add(pdf_filename)\n",
    "\n",
    "# Check for existence of each unique PDF\n",
    "for pdf_filename in unique_pdfs:\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_filename)\n",
    "    if not os.path.isfile(pdf_path):\n",
    "        missing_pdfs.append(pdf_filename)\n",
    "\n",
    "# Report\n",
    "print(f\"Total unique PDF files required: {len(unique_pdfs)}\")\n",
    "print(f\"Total missing PDF files: {len(missing_pdfs)}\")\n",
    "\n",
    "if missing_pdfs:\n",
    "    print(\"Missing PDF files:\")\n",
    "    for missing_file in missing_pdfs:\n",
    "        print(\" -\", missing_file)\n",
    "else:\n",
    "    print(\"All required PDF files are present.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda594c",
   "metadata": {},
   "source": [
    "## Move Required PDF files that the dataset needs to a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b375ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 84 PDF files to '../financebench_pdfs'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source and target directories\n",
    "source_dir = \"../pdfs\"\n",
    "target_dir = \"../financebench_pdfs\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Track unique doc_names\n",
    "unique_doc_names = {record[\"doc_name\"] for record in ds}\n",
    "\n",
    "# Copy only the needed PDFs\n",
    "copied_count = 0\n",
    "for doc_name in unique_doc_names:\n",
    "    filename = doc_name + \".pdf\"\n",
    "    source_path = os.path.join(source_dir, filename)\n",
    "    target_path = os.path.join(target_dir, filename)\n",
    "\n",
    "    if os.path.isfile(source_path):\n",
    "        shutil.copy2(source_path, target_path)\n",
    "        copied_count += 1\n",
    "    else:\n",
    "        print(f\"Missing file: {filename}\")\n",
    "\n",
    "print(f\"Copied {copied_count} PDF files to '{target_dir}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b866e1",
   "metadata": {},
   "source": [
    "## Load documents using LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090cf7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: AMCOR_2020_10K.pdf\n",
      "Loaded: AMCOR_2020_10K.pdf\n",
      "Processing: PEPSICO_2023Q1_EARNINGS.pdf\n",
      "Loaded: PEPSICO_2023Q1_EARNINGS.pdf\n",
      "Processing: CVSHEALTH_2022_10K.pdf\n",
      "Loaded: CVSHEALTH_2022_10K.pdf\n",
      "Processing: AMCOR_2023_10K.pdf\n",
      "Loaded: AMCOR_2023_10K.pdf\n",
      "Processing: PEPSICO_2022_10K.pdf\n",
      "Loaded: PEPSICO_2022_10K.pdf\n",
      "Processing: NETFLIX_2015_10K.pdf\n",
      "Loaded: NETFLIX_2015_10K.pdf\n",
      "Processing: 3M_2023Q2_10Q.pdf\n",
      "Loaded: 3M_2023Q2_10Q.pdf\n",
      "Processing: 3M_2017_10K.pdf\n",
      "Loaded: 3M_2017_10K.pdf\n",
      "Processing: GENERALMILLS_2019_10K.pdf\n",
      "Loaded: GENERALMILLS_2019_10K.pdf\n",
      "Processing: BESTBUY_2017_10K.pdf\n",
      "Loaded: BESTBUY_2017_10K.pdf\n",
      "Processing: BOEING_2022_10K.pdf\n",
      "Loaded: BOEING_2022_10K.pdf\n",
      "Processing: PEPSICO_2023_8K_dated-2023-05-30.pdf\n",
      "Loaded: PEPSICO_2023_8K_dated-2023-05-30.pdf\n",
      "Processing: COCACOLA_2022_10K.pdf\n",
      "Loaded: COCACOLA_2022_10K.pdf\n",
      "Processing: AES_2022_10K.pdf\n",
      "Loaded: AES_2022_10K.pdf\n",
      "Processing: NIKE_2018_10K.pdf\n",
      "Loaded: NIKE_2018_10K.pdf\n",
      "Processing: AMCOR_2023Q2_10Q.pdf\n",
      "Loaded: AMCOR_2023Q2_10Q.pdf\n",
      "Processing: 3M_2018_10K.pdf\n",
      "Loaded: 3M_2018_10K.pdf\n",
      "Processing: AMERICANWATERWORKS_2020_10K.pdf\n",
      "Loaded: AMERICANWATERWORKS_2020_10K.pdf\n",
      "Processing: ACTIVISIONBLIZZARD_2019_10K.pdf\n",
      "Loaded: ACTIVISIONBLIZZARD_2019_10K.pdf\n",
      "Processing: AMD_2015_10K.pdf\n",
      "Loaded: AMD_2015_10K.pdf\n",
      "Processing: PAYPAL_2022_10K.pdf\n",
      "Loaded: PAYPAL_2022_10K.pdf\n",
      "Processing: CVSHEALTH_2018_10K.pdf\n",
      "Loaded: CVSHEALTH_2018_10K.pdf\n",
      "Processing: GENERALMILLS_2022_10K.pdf\n",
      "Loaded: GENERALMILLS_2022_10K.pdf\n",
      "Processing: PFIZER_2021_10K.pdf\n",
      "Loaded: PFIZER_2021_10K.pdf\n",
      "Processing: JPMORGAN_2022_10K.pdf\n",
      "Loaded: JPMORGAN_2022_10K.pdf\n",
      "Processing: MGMRESORTS_2023Q2_10Q.pdf\n",
      "Loaded: MGMRESORTS_2023Q2_10Q.pdf\n",
      "Processing: BESTBUY_2023_10K.pdf\n",
      "Loaded: BESTBUY_2023_10K.pdf\n",
      "Processing: MGMRESORTS_2022Q4_EARNINGS.pdf\n",
      "Loaded: MGMRESORTS_2022Q4_EARNINGS.pdf\n",
      "Processing: JOHNSON_JOHNSON_2023_8K_dated-2023-08-30.pdf\n",
      "Loaded: JOHNSON_JOHNSON_2023_8K_dated-2023-08-30.pdf\n",
      "Processing: WALMART_2019_10K.pdf\n",
      "Loaded: WALMART_2019_10K.pdf\n",
      "Processing: JOHNSON_JOHNSON_2022Q4_EARNINGS.pdf\n",
      "Loaded: JOHNSON_JOHNSON_2022Q4_EARNINGS.pdf\n",
      "Processing: MICROSOFT_2016_10K.pdf\n",
      "Loaded: MICROSOFT_2016_10K.pdf\n",
      "Processing: Pfizer_2023Q2_10Q.pdf\n",
      "Loaded: Pfizer_2023Q2_10Q.pdf\n",
      "Processing: AMD_2022_10K.pdf\n",
      "Loaded: AMD_2022_10K.pdf\n",
      "Processing: LOCKHEEDMARTIN_2020_10K.pdf\n",
      "Loaded: LOCKHEEDMARTIN_2020_10K.pdf\n",
      "Processing: AMERICANWATERWORKS_2021_10K.pdf\n",
      "Loaded: AMERICANWATERWORKS_2021_10K.pdf\n",
      "Processing: GENERALMILLS_2020_10K.pdf\n",
      "Loaded: GENERALMILLS_2020_10K.pdf\n",
      "Processing: COCACOLA_2017_10K.pdf\n",
      "Loaded: COCACOLA_2017_10K.pdf\n",
      "Processing: ADOBE_2015_10K.pdf\n",
      "Loaded: ADOBE_2015_10K.pdf\n",
      "Processing: JOHNSON_JOHNSON_2023Q2_EARNINGS.pdf\n",
      "Loaded: JOHNSON_JOHNSON_2023Q2_EARNINGS.pdf\n",
      "Processing: 3M_2022_10K.pdf\n",
      "Loaded: 3M_2022_10K.pdf\n",
      "Processing: JOHNSON_JOHNSON_2022_10K.pdf\n",
      "Loaded: JOHNSON_JOHNSON_2022_10K.pdf\n",
      "Processing: WALMART_2018_10K.pdf\n",
      "Loaded: WALMART_2018_10K.pdf\n",
      "Processing: PEPSICO_2021_10K.pdf\n",
      "Loaded: PEPSICO_2021_10K.pdf\n",
      "Processing: MGMRESORTS_2022_10K.pdf\n",
      "Loaded: MGMRESORTS_2022_10K.pdf\n",
      "Processing: CORNING_2020_10K.pdf\n",
      "Loaded: CORNING_2020_10K.pdf\n",
      "Processing: ADOBE_2017_10K.pdf\n",
      "Loaded: ADOBE_2017_10K.pdf\n",
      "Processing: MGMRESORTS_2020_10K.pdf\n",
      "Loaded: MGMRESORTS_2020_10K.pdf\n",
      "Processing: 3M_2016_10K.pdf\n",
      "Loaded: 3M_2016_10K.pdf\n",
      "Processing: JPMORGAN_2023Q2_10Q.pdf\n",
      "Loaded: JPMORGAN_2023Q2_10Q.pdf\n",
      "Processing: ADOBE_2022_10K.pdf\n",
      "Loaded: ADOBE_2022_10K.pdf\n",
      "Processing: JPMORGAN_2021Q1_10Q.pdf\n",
      "Loaded: JPMORGAN_2021Q1_10Q.pdf\n",
      "Processing: PEPSICO_2023_8K_dated-2023-05-05.pdf\n",
      "Loaded: PEPSICO_2023_8K_dated-2023-05-05.pdf\n",
      "Processing: BOEING_2018_10K.pdf\n",
      "Loaded: BOEING_2018_10K.pdf\n",
      "Processing: JPMORGAN_2022Q2_10Q.pdf\n",
      "Loaded: JPMORGAN_2022Q2_10Q.pdf\n",
      "Processing: AMERICANEXPRESS_2022_10K.pdf\n",
      "Loaded: AMERICANEXPRESS_2022_10K.pdf\n",
      "Processing: VERIZON_2021_10K.pdf\n",
      "Loaded: VERIZON_2021_10K.pdf\n",
      "Processing: AMCOR_2022_8K_dated-2022-07-01.pdf\n",
      "Loaded: AMCOR_2022_8K_dated-2022-07-01.pdf\n",
      "Processing: KRAFTHEINZ_2019_10K.pdf\n",
      "Loaded: KRAFTHEINZ_2019_10K.pdf\n",
      "Processing: MICROSOFT_2023_10K.pdf\n",
      "Loaded: MICROSOFT_2023_10K.pdf\n",
      "Processing: NIKE_2021_10K.pdf\n",
      "Loaded: NIKE_2021_10K.pdf\n",
      "Processing: BLOCK_2020_10K.pdf\n",
      "Loaded: BLOCK_2020_10K.pdf\n",
      "Processing: BESTBUY_2019_10K.pdf\n",
      "Loaded: BESTBUY_2019_10K.pdf\n",
      "Processing: AMAZON_2017_10K.pdf\n",
      "Loaded: AMAZON_2017_10K.pdf\n",
      "Processing: MGMRESORTS_2018_10K.pdf\n",
      "Loaded: MGMRESORTS_2018_10K.pdf\n",
      "Processing: BLOCK_2016_10K.pdf\n",
      "Loaded: BLOCK_2016_10K.pdf\n",
      "Processing: NIKE_2023_10K.pdf\n",
      "Loaded: NIKE_2023_10K.pdf\n",
      "Processing: LOCKHEEDMARTIN_2022_10K.pdf\n",
      "Loaded: LOCKHEEDMARTIN_2022_10K.pdf\n",
      "Processing: AMCOR_2023Q4_EARNINGS.pdf\n",
      "Loaded: AMCOR_2023Q4_EARNINGS.pdf\n",
      "Processing: AMERICANWATERWORKS_2022_10K.pdf\n",
      "Loaded: AMERICANWATERWORKS_2022_10K.pdf\n",
      "Processing: BESTBUY_2024Q2_10Q.pdf\n",
      "Loaded: BESTBUY_2024Q2_10Q.pdf\n",
      "Processing: WALMART_2020_10K.pdf\n",
      "Loaded: WALMART_2020_10K.pdf\n",
      "Processing: LOCKHEEDMARTIN_2021_10K.pdf\n",
      "Loaded: LOCKHEEDMARTIN_2021_10K.pdf\n",
      "Processing: COCACOLA_2021_10K.pdf\n",
      "Loaded: COCACOLA_2021_10K.pdf\n",
      "Processing: NIKE_2019_10K.pdf\n",
      "Loaded: NIKE_2019_10K.pdf\n",
      "Processing: FOOTLOCKER_2022_8K_dated-2022-05-20.pdf\n",
      "Loaded: FOOTLOCKER_2022_8K_dated-2022-05-20.pdf\n",
      "Processing: NETFLIX_2017_10K.pdf\n",
      "Loaded: NETFLIX_2017_10K.pdf\n",
      "Processing: FOOTLOCKER_2022_8K_dated_2022-08-19.pdf\n",
      "Loaded: FOOTLOCKER_2022_8K_dated_2022-08-19.pdf\n",
      "Processing: ULTABEAUTY_2023_10K.pdf\n",
      "Loaded: ULTABEAUTY_2023_10K.pdf\n",
      "Processing: AMAZON_2019_10K.pdf\n",
      "Loaded: AMAZON_2019_10K.pdf\n",
      "Processing: ULTABEAUTY_2023Q4_EARNINGS.pdf\n",
      "Loaded: ULTABEAUTY_2023Q4_EARNINGS.pdf\n",
      "Processing: VERIZON_2022_10K.pdf\n",
      "Loaded: VERIZON_2022_10K.pdf\n",
      "Processing: ADOBE_2016_10K.pdf\n",
      "Loaded: ADOBE_2016_10K.pdf\n",
      "Processing: COSTCO_2021_10K.pdf\n",
      "Loaded: COSTCO_2021_10K.pdf\n",
      "Processing: CORNING_2021_10K.pdf\n",
      "Loaded: CORNING_2021_10K.pdf\n",
      "Processing: CORNING_2022_10K.pdf\n",
      "Loaded: CORNING_2022_10K.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "pdf_dir = \"../financebench_pdfs\"\n",
    "pdf_reader = PyMuPDFReader()\n",
    "\n",
    "# List of PDF files\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    file_path = os.path.join(pdf_dir, pdf_file)\n",
    "    print(f\"Processing: {pdf_file}\")\n",
    "    try:\n",
    "        doc = pdf_reader.load(file_path)\n",
    "        documents.extend(doc)  # note: `doc` is a list of Document objects\n",
    "        print(f\"Loaded: {pdf_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {pdf_file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6fc3f",
   "metadata": {},
   "source": [
    "## Create the nodes with specific chunk and overlap size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0784b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from typing import List\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "def generate_nodes(\n",
    "    documents: List[Document],\n",
    "    chunk_size: int = 512,\n",
    "    chunk_overlap: int = 512 // 4 # 20% overlap\n",
    ") -> List:\n",
    "    \"\"\"\n",
    "    Generate nodes from documents using LlamaIndex SentenceSplitter.\n",
    "\n",
    "    Args:\n",
    "        documents: List of LlamaIndex Document objects to process\n",
    "        chunk_size: Maximum characters per chunk (default: 512)\n",
    "        chunk_overlap: Overlap between chunks to preserve context (default: 25% overlap)\n",
    "\n",
    "    Returns:\n",
    "        List of nodes generated from the documents\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If chunk_size or chunk_overlap is invalid\n",
    "        TypeError: If documents is not a list of Document objects\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(documents, list):\n",
    "        raise TypeError(\"Documents must be provided as a list\")\n",
    "    \n",
    "    if not all(isinstance(doc, Document) for doc in documents):\n",
    "        raise TypeError(\"All items in documents list must be LlamaIndex Document objects\")\n",
    "    \n",
    "    if chunk_size <= 0:\n",
    "        raise ValueError(\"Chunk size must be positive\")\n",
    "        \n",
    "    if chunk_overlap < 0:\n",
    "        raise ValueError(\"Chunk overlap cannot be negative\")\n",
    "        \n",
    "    if chunk_overlap >= chunk_size:\n",
    "        raise ValueError(\"Chunk overlap must be less than chunk size\")\n",
    "\n",
    "    # Initialize SentenceSplitter\n",
    "    parser = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    # Generate nodes\n",
    "    nodes = parser.get_nodes_from_documents(documents)\n",
    "    \n",
    "    print(f\"Created {len(nodes)} chunks with chunk_size={chunk_size} and chunk_overlap={chunk_overlap}\")\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "# # Example usage\n",
    "# # Sample documents\n",
    "# sample_text = \"This is a sample document for testing. \" * 50\n",
    "# documents = [Document(text=sample_text)]\n",
    "\n",
    "# try:\n",
    "#     # Generate nodes with default parameters\n",
    "#     nodes = generate_nodes(documents)\n",
    "    \n",
    "#     # Generate nodes with custom parameters\n",
    "#     custom_nodes = generate_nodes(\n",
    "#         documents=documents,\n",
    "#         chunk_size=1000,\n",
    "#         chunk_overlap=200\n",
    "#     )\n",
    "# except (ValueError, TypeError) as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a0b718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.docstore.document import Document as LCDocument\n",
    "from llama_index.core.schema import BaseNode\n",
    "\n",
    "def nodes_to_langchain_docs(\n",
    "    nodes: List[BaseNode],\n",
    "    chunk_size: int,\n",
    "    keep_node_metadata: bool = True\n",
    ") -> List[LCDocument]:\n",
    "    \"\"\"\n",
    "    Convert LlamaIndex nodes to LangChain documents.\n",
    "\n",
    "    Args:\n",
    "        nodes: List of LlamaIndex nodes to convert\n",
    "        chunk_size: Chunk size used for node creation (for metadata)\n",
    "        keep_node_metadata: If True, include original node metadata in addition to chunk_size\n",
    "\n",
    "    Returns:\n",
    "        List of LangChain Document objects\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If nodes is not a list of LlamaIndex BaseNode objects\n",
    "        ValueError: If chunk_size is invalid\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(nodes, list):\n",
    "        raise TypeError(\"Nodes must be provided as a list\")\n",
    "    \n",
    "    if not all(isinstance(node, BaseNode) for node in nodes):\n",
    "        raise TypeError(\"All items in nodes list must be LlamaIndex BaseNode objects\")\n",
    "    \n",
    "    if chunk_size <= 0:\n",
    "        raise ValueError(\"Chunk size must be positive\")\n",
    "\n",
    "    # Convert nodes to LangChain documents\n",
    "    lc_docs = []\n",
    "    for node in nodes:\n",
    "        # Base metadata with chunk_size\n",
    "        metadata = {\"chunk_size\": chunk_size}\n",
    "        \n",
    "        # Add original node metadata if keep_node_metadata is True\n",
    "        if keep_node_metadata:\n",
    "            metadata.update(node.metadata)\n",
    "        \n",
    "        # Create LangChain document\n",
    "        doc = LCDocument(\n",
    "            page_content=node.get_content(),\n",
    "            metadata=metadata\n",
    "        )\n",
    "        lc_docs.append(doc)\n",
    "    \n",
    "    print(f\"Converted {len(lc_docs)} nodes to LangChain documents \"\n",
    "          f\"(keep_node_metadata={keep_node_metadata})\")\n",
    "    \n",
    "    return lc_docs\n",
    "\n",
    "# # Example usage\n",
    "# # Create sample nodes\n",
    "# sample_text = \"This is a sample document for testing. \" * 50\n",
    "# doc = Document(text=sample_text)\n",
    "# doc.metadata = {\"source\": \"sample.pdf\", \"author\": \"John Doe\", \"page\": 1}\n",
    "# parser = SentenceSplitter(chunk_size=500, chunk_overlap=150)\n",
    "# nodes = parser.get_nodes_from_documents([doc])\n",
    "\n",
    "# try:\n",
    "#     # Convert nodes without keeping node metadata\n",
    "#     lc_docs_without_metadata = nodes_to_langchain_docs(\n",
    "#         nodes=nodes,\n",
    "#         chunk_size=500,\n",
    "#         keep_node_metadata=False\n",
    "#     )\n",
    "    \n",
    "#     # Convert nodes keeping node metadata\n",
    "#     lc_docs_with_metadata = nodes_to_langchain_docs(\n",
    "#         nodes=nodes,\n",
    "#         chunk_size=500,\n",
    "#         keep_node_metadata=True\n",
    "#     )\n",
    "    \n",
    "#     # Print sample results\n",
    "#     print(\"\\nSample document without node metadata:\")\n",
    "#     print(lc_docs_without_metadata[0].metadata)\n",
    "    \n",
    "#     print(\"\\nSample document with node metadata:\")\n",
    "#     print(lc_docs_with_metadata[0].metadata)\n",
    "    \n",
    "# except (TypeError, ValueError) as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932462e9",
   "metadata": {},
   "source": [
    "## Populate documents to vectore storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70186eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from llama_index.core.schema import Document, BaseNode\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from langchain.docstore.document import Document as LCDocument\n",
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "def clear_directory_with_retry(directory: str, max_attempts: int = 5, delay: float = 1.0) -> None:\n",
    "    \"\"\"\n",
    "    Attempt to clear a directory with retries to handle file access issues on Windows.\n",
    "\n",
    "    Args:\n",
    "        directory: Path to the directory to clear\n",
    "        max_attempts: Maximum number of retry attempts\n",
    "        delay: Delay between attempts in seconds\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            shutil.rmtree(directory, ignore_errors=True)\n",
    "            print(f\"Cleared existing ChromaDB at {directory}\")\n",
    "            return\n",
    "        except PermissionError as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_attempts} failed: {e}\")\n",
    "            if attempt < max_attempts - 1:\n",
    "                time.sleep(delay)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to clear directory: {e}\")\n",
    "            raise\n",
    "    raise PermissionError(f\"Could not clear directory {directory} after {max_attempts} attempts\")\n",
    "\n",
    "def populate_vector_store(\n",
    "    documents: List[Document],\n",
    "    chunk_sizes: List[int],\n",
    "    embedding_model: str,\n",
    "    collection_name_prefix: str,\n",
    "    persist_directory: str,\n",
    "    chunk_overlap_percentage: int = 30,\n",
    "    keep_node_metadata: bool = False,\n",
    "    clear_old_db: bool = False,\n",
    "    max_batch_size: int = 5000\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Populate Chroma vector store with embeddings for multiple chunk sizes.\n",
    "\n",
    "    Args:\n",
    "        documents: List of LlamaIndex Document objects\n",
    "        chunk_sizes: List of chunk sizes to process\n",
    "        embedding_model: Ollama embedding model name\n",
    "        collection_name_prefix: Prefix for Chroma collection names\n",
    "        persist_directory: Directory to store ChromaDB\n",
    "        chunk_overlap_percentage: Overlap percentage (1-99) for chunks (default: 30)\n",
    "        keep_node_metadata: If True, keep original node metadata\n",
    "        clear_old_db: If True, remove existing ChromaDB directory\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If inputs are invalid\n",
    "        TypeError: If documents or chunk_sizes are not lists\n",
    "        PermissionError: If directory cannot be cleared\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    if not isinstance(documents, list):\n",
    "        raise TypeError(\"Documents must be provided as a list\")\n",
    "    \n",
    "    if not all(isinstance(doc, Document) for doc in documents):\n",
    "        raise TypeError(\"All items in documents list must be LlamaIndex Document objects\")\n",
    "    \n",
    "    if not isinstance(chunk_sizes, list):\n",
    "        raise TypeError(\"Chunk sizes must be provided as a list\")\n",
    "    \n",
    "    if not all(isinstance(size, int) and size > 0 for size in chunk_sizes):\n",
    "        raise ValueError(\"All chunk sizes must be positive integers\")\n",
    "    \n",
    "    if not isinstance(chunk_overlap_percentage, int) or chunk_overlap_percentage < 1 or chunk_overlap_percentage > 99:\n",
    "        raise ValueError(\"Chunk overlap percentage must be an integer between 1 and 99\")\n",
    "    \n",
    "    if not embedding_model:\n",
    "        raise ValueError(\"Embedding model name must be provided\")\n",
    "\n",
    "    # Clear existing ChromaDB if requested\n",
    "    if clear_old_db:\n",
    "        clear_directory_with_retry(persist_directory)\n",
    "\n",
    "    # Initialize embeddings\n",
    "    embedding = OllamaEmbeddings(model=embedding_model)\n",
    "\n",
    "    # Process each chunk size\n",
    "    for chunk_size in chunk_sizes:\n",
    "        # Calculate chunk overlap based on percentage\n",
    "        chunk_overlap = int(chunk_size * (chunk_overlap_percentage / 100))\n",
    "        \n",
    "        if chunk_overlap >= chunk_size:\n",
    "            raise ValueError(f\"Calculated chunk overlap ({chunk_overlap}) must be less than chunk size ({chunk_size})\")\n",
    "        \n",
    "        collection_name = f\"{collection_name_prefix}{chunk_size}\"\n",
    "        \n",
    "        # Check if collection already exists\n",
    "        vectorstore = None\n",
    "        if not clear_old_db and os.path.exists(persist_directory):\n",
    "            try:\n",
    "                vectorstore = Chroma(\n",
    "                    collection_name=collection_name,\n",
    "                    embedding_function=embedding,\n",
    "                    persist_directory=persist_directory\n",
    "                )\n",
    "                # If collection exists and clear_old_db is False, skip\n",
    "                if vectorstore._collection.count() > 0:\n",
    "                    print(f\"Skipping chunk size {chunk_size}: Collection already exists\")\n",
    "                    vectorstore = None  # Explicitly release the connection\n",
    "                    continue\n",
    "            except Exception:\n",
    "                pass  # Collection doesn't exist, proceed with creation\n",
    "\n",
    "        # Generate nodes\n",
    "        nodes = generate_nodes(\n",
    "            documents=documents,\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "\n",
    "        print(f\"Generated {len(nodes)} nodes for chunk size {chunk_size} \")\n",
    "\n",
    "        # Convert nodes to LangChain documents\n",
    "        lc_docs = nodes_to_langchain_docs(\n",
    "            nodes=nodes,\n",
    "            chunk_size=chunk_size,\n",
    "            keep_node_metadata=keep_node_metadata\n",
    "        )\n",
    "\n",
    "        print(f\"Converted {len(lc_docs)} nodes to LangChain documents for chunk size {chunk_size}\")\n",
    "\n",
    "        os.makedirs(persist_directory, exist_ok=True)\n",
    "        # Initialize Chroma vector store\n",
    "        vectorstore = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embedding,\n",
    "            persist_directory=persist_directory\n",
    "        )\n",
    "\n",
    "        vectorstore.persist()\n",
    "\n",
    "        print(f\"Initialized Chroma vector store for chunk size {chunk_size}\")\n",
    "\n",
    "        # Add documents to vector store in batches\n",
    "        total_docs = len(lc_docs)\n",
    "        for batch_start in range(0, total_docs, max_batch_size):\n",
    "            print(f\"Adding batch {batch_start//max_batch_size + 1}\")\n",
    "            batch_end = min(batch_start + max_batch_size, total_docs)\n",
    "            batch = lc_docs[batch_start:batch_end]\n",
    "            try:\n",
    "                print(f\"Try adding {len(batch)} batche of documents\")\n",
    "                vectorstore.add_documents(batch)\n",
    "                print(f\"Added batch {batch_start//max_batch_size + 1} \"\n",
    "                      f\"({len(batch)} documents) for chunk size {chunk_size}\")\n",
    "                vectorstore.persist()\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding batch {batch_start//max_batch_size + 1} \"\n",
    "                      f\"for chunk size {chunk_size}: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "        vectorstore.persist()\n",
    "\n",
    "        print(f\"Populated vector store for chunk size {chunk_size} with {len(lc_docs)} documents \"\n",
    "              f\"(overlap={chunk_overlap_percentage}% -> {chunk_overlap} tokens)\")\n",
    "\n",
    "        # Explicitly release the vectorstore connection\n",
    "        vectorstore = None\n",
    "\n",
    "# # Example usage\n",
    "# # Sample documents\n",
    "# sample_text = \"This is a sample document for testing. \" * 50\n",
    "# documents = [Document(text=sample_text)]\n",
    "\n",
    "# try:\n",
    "#     populate_vector_store(\n",
    "#         documents=documents,\n",
    "#         chunk_sizes=[128, 256, 512, 1024],\n",
    "#         embedding_model=\"all-minilm\",\n",
    "#         collection_name_prefix=\"rag_docs_chunk_\",\n",
    "#         persist_directory=\"chroma_db2\",\n",
    "#         chunk_overlap_percentage=20,\n",
    "#         keep_node_metadata=True,\n",
    "#         clear_old_db=False,\n",
    "#         max_batch_size=5000\n",
    "#     )\n",
    "# except (ValueError, TypeError) as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe1a7ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared existing ChromaDB at ./financebench_db4\n",
      "Created 30293 chunks with chunk_size=512 and chunk_overlap=102\n",
      "Generated 30293 nodes for chunk size 512 \n",
      "Converted 30293 nodes to LangChain documents (keep_node_metadata=True)\n",
      "Converted 30293 nodes to LangChain documents for chunk size 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62638/4213557773.py:140: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n",
      "/tmp/ipykernel_62638/4213557773.py:146: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Chroma vector store for chunk size 512\n",
      "Adding batch 1\n",
      "Try adding 500 batche of documents\n",
      "Added batch 1 (500 documents) for chunk size 512\n",
      "Adding batch 2\n",
      "Try adding 500 batche of documents\n",
      "Added batch 2 (500 documents) for chunk size 512\n",
      "Adding batch 3\n",
      "Try adding 500 batche of documents\n",
      "Added batch 3 (500 documents) for chunk size 512\n",
      "Adding batch 4\n",
      "Try adding 500 batche of documents\n",
      "Added batch 4 (500 documents) for chunk size 512\n",
      "Adding batch 5\n",
      "Try adding 500 batche of documents\n",
      "Added batch 5 (500 documents) for chunk size 512\n",
      "Adding batch 6\n",
      "Try adding 500 batche of documents\n",
      "Added batch 6 (500 documents) for chunk size 512\n",
      "Adding batch 7\n",
      "Try adding 500 batche of documents\n",
      "Added batch 7 (500 documents) for chunk size 512\n",
      "Adding batch 8\n",
      "Try adding 500 batche of documents\n",
      "Added batch 8 (500 documents) for chunk size 512\n",
      "Adding batch 9\n",
      "Try adding 500 batche of documents\n",
      "Added batch 9 (500 documents) for chunk size 512\n",
      "Adding batch 10\n",
      "Try adding 500 batche of documents\n",
      "Added batch 10 (500 documents) for chunk size 512\n",
      "Adding batch 11\n",
      "Try adding 500 batche of documents\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Generate real vectore store from one of the datasets\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mpopulate_vector_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinancebench_docs_chunk_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./financebench_db4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_overlap_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_overlap_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_node_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclear_old_db\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 158\u001b[39m, in \u001b[36mpopulate_vector_store\u001b[39m\u001b[34m(documents, chunk_sizes, embedding_model, collection_name_prefix, persist_directory, chunk_overlap_percentage, keep_node_metadata, clear_old_db, max_batch_size)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    157\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTry adding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m batche of documents\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAdded batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_start//max_batch_size\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents) for chunk size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    161\u001b[39m     vectorstore.persist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:288\u001b[39m, in \u001b[36mVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m     texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    287\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m msg = (\n\u001b[32m    290\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    292\u001b[39m )\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:277\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    281\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/langchain_ollama/embeddings.py:265\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    264\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed search docs.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     embedded_docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded_docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/ollama/_client.py:357\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, model, input, truncate, options, keep_alive)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    350\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    351\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    356\u001b[39m ) -> EmbedResponse:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbedResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/ollama/_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/ollama/_client.py:118\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    117\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     r.raise_for_status()\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Thesis-RAG/finance-rag/labs/financebench-playground/myenv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "embedding_model = \"nomic-embed-text\"\n",
    "# chunk_sizes = [128, 256, 512, 1024]\n",
    "chunk_sizes = [512]\n",
    "chunk_overlap_percentage = 20\n",
    "\n",
    "# Generate real vectore store from one of the datasets\n",
    "try:\n",
    "    populate_vector_store(\n",
    "        documents=documents,\n",
    "        chunk_sizes=chunk_sizes,\n",
    "        embedding_model=embedding_model,\n",
    "        collection_name_prefix=\"financebench_docs_chunk_\",\n",
    "        persist_directory=\"./financebench_db4\",\n",
    "        chunk_overlap_percentage=chunk_overlap_percentage,\n",
    "        keep_node_metadata=True,\n",
    "        clear_old_db=True,\n",
    "        max_batch_size=500\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
