{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3a7f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "✓ OpenAI API key loaded\n",
      "✓ VoyageAI API key loaded\n",
      "✓ Ollama URL: http://localhost:11434\n",
      "✓ Configuration set\n",
      "  Vector DB Directory: ../../vector_databases\n",
      "  Output Directory: ../../evaluation_results/mrr_embeddings\n",
      "Loading FinanceBench dataset...\n",
      "✓ Loaded 150 queries\n",
      "\n",
      "Sample query:\n",
      "  ID: financebench_id_03029\n",
      "  Company: 3M\n",
      "  Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "  Doc: 3M_2018_10K\n",
      "  Evidence items: 1\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FinanceBench Evaluation: MRR Analysis\n",
    "# Comparing Embedding Models and Chunk Sizes\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # FinanceBench RAG Evaluation\n",
    "# \n",
    "# This notebook evaluates different embedding models and chunk sizes using\n",
    "# Mean Reciprocal Rank (MRR) on the FinanceBench dataset.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.1 Imports\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Progress\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Data\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Vector stores\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.2 Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
    "VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"✓ OpenAI API key loaded\")\n",
    "else:\n",
    "    print(\"⚠ OpenAI API key not found (only needed if using OpenAI embeddings)\")\n",
    "\n",
    "if VOYAGE_API_KEY:\n",
    "    print(\"✓ VoyageAI API key loaded\")\n",
    "else:\n",
    "    print(\"⚠ VoyageAI API key not found (only needed if using VoyageAI embeddings)\")\n",
    "\n",
    "print(f\"✓ Ollama URL: {OLLAMA_BASE_URL}\")\n",
    "\n",
    "# %%\n",
    "# Paths\n",
    "VECTOR_DB_BASE_DIR = \"../../vector_databases\"\n",
    "OUTPUT_DIR = \"../../evaluation_results/mrr_embeddings\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Dataset\n",
    "DATASET_NAME = \"PatronusAI/financebench\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "\n",
    "# Collection settings\n",
    "COLLECTION_PREFIX = \"financebench_docs_chunk_\"\n",
    "\n",
    "print(\"✓ Configuration set\")\n",
    "print(f\"  Vector DB Directory: {VECTOR_DB_BASE_DIR}\")\n",
    "print(f\"  Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.3 Load Dataset\n",
    "\n",
    "# %%\n",
    "print(\"Loading FinanceBench dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT)\n",
    "print(f\"✓ Loaded {len(dataset)} queries\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample query:\")\n",
    "sample = dataset[0]\n",
    "print(f\"  ID: {sample['financebench_id']}\")\n",
    "print(f\"  Company: {sample['company']}\")\n",
    "print(f\"  Question: {sample['question'][:100]}...\")\n",
    "print(f\"  Doc: {sample['doc_name']}\")\n",
    "print(f\"  Evidence items: {len(sample['evidence'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3167cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 2: Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.1 Metadata Extraction\n",
    "\n",
    "# %%\n",
    "def extract_doc_name_from_path(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract document name from file path.\n",
    "    \n",
    "    Example: \"../../financebench/documents/GENERALMILLS_2019_10K.pdf\" \n",
    "             -> \"GENERALMILLS_2019_10K\"\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    doc_name = filename.replace('.pdf', '')\n",
    "    return doc_name\n",
    "\n",
    "\n",
    "def extract_metadata_from_retrieved_doc(doc) -> Dict:\n",
    "    \"\"\"Extract relevant metadata from retrieved document.\"\"\"\n",
    "    file_path = doc.metadata.get('file_path', '')\n",
    "    doc_name = extract_doc_name_from_path(file_path)\n",
    "    page_num = doc.metadata.get('source', -1)\n",
    "    \n",
    "    # Ensure page_num is an integer\n",
    "    if isinstance(page_num, str):\n",
    "        page_num = int(page_num)\n",
    "    \n",
    "    return {\n",
    "        'doc_name': doc_name,\n",
    "        'page_number': page_num\n",
    "    }\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.2 Vector Store Loading\n",
    "\n",
    "# %%\n",
    "def get_embedding_function(provider: str, model: str):\n",
    "    \"\"\"Get embedding function.\"\"\"\n",
    "    if provider == \"ollama\":\n",
    "        return OllamaEmbeddings(model=model)\n",
    "    elif provider == \"openai\":\n",
    "        return OpenAIEmbeddings(model=model)\n",
    "    elif provider == \"voyage\":\n",
    "        return VoyageAIEmbeddings(model=model, api_key=VOYAGE_API_KEY)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider}\")\n",
    "\n",
    "\n",
    "def load_vectorstore(\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    base_dir: str = VECTOR_DB_BASE_DIR,\n",
    "    collection_prefix: str = COLLECTION_PREFIX\n",
    ") -> Chroma:\n",
    "    \"\"\"Load a vector store.\"\"\"\n",
    "    model_id = f\"{provider}_{model.replace('/', '_')}\"\n",
    "    db_path = os.path.join(base_dir, model_id)\n",
    "    collection_name = f\"{collection_prefix}{chunk_size}\"\n",
    "    \n",
    "    emb_fn = get_embedding_function(provider, model)\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=emb_fn,\n",
    "        persist_directory=db_path\n",
    "    )\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.3 Evidence Matching\n",
    "\n",
    "# %%\n",
    "def check_match(\n",
    "    retrieved_doc: Dict, \n",
    "    evidence_list: List[Dict],\n",
    "    chunk_size: int = 512,\n",
    "    use_page_tolerance: bool = True\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if retrieved document matches any evidence.\n",
    "    \n",
    "    Uses chunk-size-aware page tolerance:\n",
    "    - Chunks can span multiple pages\n",
    "    - Only matches if retrieved page is BEFORE or AT evidence page (within tolerance)\n",
    "    - Retrieved page after evidence page = no match\n",
    "    \n",
    "    Page tolerance calculation (when use_page_tolerance=True):\n",
    "    - chunk_size <= 512: tolerance = 0 (exact match)\n",
    "    - chunk_size 513-1024: tolerance = 1\n",
    "    - chunk_size 1025-2048: tolerance = 2\n",
    "    - chunk_size > 2048: tolerance = 3\n",
    "    \n",
    "    Args:\n",
    "        retrieved_doc: {doc_name, page_number} (1-indexed)\n",
    "        evidence_list: List of evidence dicts from FinanceBench (0-indexed, will be converted)\n",
    "        chunk_size: Chunk size used for this retrieval\n",
    "        use_page_tolerance: If True, use chunk-size-aware tolerance. If False, exact match only.\n",
    "        \n",
    "    Returns:\n",
    "        True if match found\n",
    "    \"\"\"\n",
    "    retrieved_doc_name = retrieved_doc['doc_name']\n",
    "    retrieved_page = retrieved_doc['page_number']\n",
    "    \n",
    "    # Calculate page tolerance based on chunk size\n",
    "    if use_page_tolerance:\n",
    "        if chunk_size <= 512:\n",
    "            page_tolerance = 0\n",
    "        elif chunk_size <= 1024:\n",
    "            page_tolerance = 1\n",
    "        elif chunk_size <= 2048:\n",
    "            page_tolerance = 2\n",
    "        else:\n",
    "            page_tolerance = 3\n",
    "    else:\n",
    "        page_tolerance = 0  # Exact match only\n",
    "    \n",
    "    for evidence in evidence_list:\n",
    "        evidence_doc_name = evidence['doc_name']\n",
    "        evidence_page = evidence['evidence_page_num'] + 1  # Convert 0-indexed to 1-indexed\n",
    "        \n",
    "        # Check document name match\n",
    "        if retrieved_doc_name != evidence_doc_name:\n",
    "            continue\n",
    "        \n",
    "        # Check page match with tolerance\n",
    "        # Only match if retrieved page is BEFORE or AT evidence page\n",
    "        if retrieved_page <= evidence_page <= retrieved_page + page_tolerance:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.4 MRR Calculation (Modular)\n",
    "\n",
    "# %%\n",
    "def calculate_mrr_for_query(\n",
    "    retrieved_docs: List[Dict], \n",
    "    evidence_list: List[Dict],\n",
    "    chunk_size: int = 512,\n",
    "    use_page_tolerance: bool = True\n",
    ") -> Tuple[float, int]:\n",
    "    \"\"\"\n",
    "    Calculate MRR for a single query.\n",
    "    \n",
    "    Args:\n",
    "        retrieved_docs: List of {doc_name, page_number}\n",
    "        evidence_list: Ground truth evidence\n",
    "        chunk_size: Chunk size used (for page tolerance)\n",
    "        use_page_tolerance: If True, use chunk-size-aware tolerance. If False, exact match only.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (mrr_score, rank)\n",
    "        - mrr_score: 1/rank if found, 0 if not found\n",
    "        - rank: Position of first match (1-indexed), -1 if not found\n",
    "    \"\"\"\n",
    "    for rank, retrieved_doc in enumerate(retrieved_docs, start=1):\n",
    "        if check_match(retrieved_doc, evidence_list, chunk_size, use_page_tolerance):\n",
    "            mrr_score = 1.0 / rank\n",
    "            return mrr_score, rank\n",
    "    \n",
    "    # No match found\n",
    "    return 0.0, -1\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.5 Retrieval Functions\n",
    "\n",
    "# %%\n",
    "def retrieve_global(\n",
    "    vectorstore: Chroma,\n",
    "    query: str,\n",
    "    k: int\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieve documents globally (search all documents).\n",
    "    \n",
    "    Returns:\n",
    "        List of {doc_name, page_number, rank}\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    retrieved = []\n",
    "    for rank, doc in enumerate(results, start=1):\n",
    "        metadata = extract_metadata_from_retrieved_doc(doc)\n",
    "        metadata['rank'] = rank\n",
    "        retrieved.append(metadata)\n",
    "    return retrieved\n",
    "\n",
    "\n",
    "def retrieve_single_doc(\n",
    "    vectorstore: Chroma,\n",
    "    query: str,\n",
    "    target_doc_name: str,\n",
    "    k: int\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieve documents filtered to single document.\n",
    "    \n",
    "    Since ChromaDB doesn't support $contains, we retrieve more documents\n",
    "    and filter them post-retrieval.\n",
    "    \n",
    "    Returns:\n",
    "        List of {doc_name, page_number, rank}\n",
    "    \"\"\"\n",
    "    # Retrieve more documents than needed (k * 10) to ensure we get enough from target doc\n",
    "    # Then filter to only the target document\n",
    "    \n",
    "    fetch_k = min(k * 10, 100)  # Fetch up to 10x k, max 100\n",
    "    \n",
    "    results = vectorstore.similarity_search(query, k=fetch_k)\n",
    "    \n",
    "    # Filter to only documents from target doc\n",
    "    filtered = []\n",
    "    for doc in results:\n",
    "        metadata = extract_metadata_from_retrieved_doc(doc)\n",
    "        if metadata['doc_name'] == target_doc_name:\n",
    "            filtered.append(metadata)\n",
    "            if len(filtered) >= k:\n",
    "                break\n",
    "    \n",
    "    # Add rank after filtering\n",
    "    for rank, doc_meta in enumerate(filtered[:k], start=1):\n",
    "        doc_meta['rank'] = rank\n",
    "    \n",
    "    # Return top k from target document\n",
    "    return filtered[:k]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.6 File Management\n",
    "\n",
    "# %%\n",
    "def get_output_filename(provider: str, model: str, chunk_size: int, k: int, mode: str) -> str:\n",
    "    \"\"\"Generate output filename.\"\"\"\n",
    "    model_clean = model.replace('/', '_')\n",
    "    filename = f\"{provider}_{model_clean}_chunk{chunk_size}_k{k}_{mode}.json\"\n",
    "    return filename\n",
    "\n",
    "\n",
    "def check_if_results_exist(provider: str, model: str, chunk_size: int, k: int, mode: str, output_dir: str) -> bool:\n",
    "    \"\"\"Check if results JSON already exists.\"\"\"\n",
    "    filename = get_output_filename(provider, model, chunk_size, k, mode)\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    return os.path.exists(filepath)\n",
    "\n",
    "\n",
    "def save_results(results: List[Dict], provider: str, model: str, chunk_size: int, k: int, mode: str, output_dir: str):\n",
    "    \"\"\"Save results to JSON file.\"\"\"\n",
    "    filename = get_output_filename(provider, model, chunk_size, k, mode)\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "# %%\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e962333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 3: Evaluation Loop\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.1 Single Evaluation Run\n",
    "\n",
    "# %%\n",
    "def evaluate_single_configuration(\n",
    "    dataset,\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    k: int,\n",
    "    mode: str,\n",
    "    use_page_tolerance: bool = True,\n",
    "    output_dir: str = OUTPUT_DIR\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate a single configuration (provider, model, chunk_size, k, mode).\n",
    "    \n",
    "    Args:\n",
    "        dataset: FinanceBench dataset\n",
    "        provider: \"ollama\" or \"openai\"\n",
    "        model: Model name\n",
    "        chunk_size: Chunk size\n",
    "        k: Number of documents to retrieve\n",
    "        mode: \"global\" or \"singledoc\"\n",
    "        use_page_tolerance: If True, use chunk-size-aware page tolerance. If False, exact match only.\n",
    "        output_dir: Output directory\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATING: {provider}/{model}, chunk={chunk_size}, k={k}, mode={mode}\")\n",
    "    print(f\"Page Tolerance: {'ENABLED' if use_page_tolerance else 'DISABLED (exact match)'}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check if already exists\n",
    "    if check_if_results_exist(provider, model, chunk_size, k, mode, output_dir):\n",
    "        print(\"✓ Results already exist - SKIPPING\")\n",
    "        return {'status': 'skipped'}\n",
    "    \n",
    "    # Load vectorstore\n",
    "    print(\"Loading vectorstore...\")\n",
    "    try:\n",
    "        vectorstore = load_vectorstore(provider, model, chunk_size)\n",
    "        doc_count = vectorstore._collection.count()\n",
    "        print(f\"✓ Loaded ({doc_count:,} documents)\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load vectorstore: {e}\")\n",
    "        return {'status': 'failed', 'error': str(e)}\n",
    "    \n",
    "    # Process all queries\n",
    "    results = []\n",
    "    mrr_scores = []\n",
    "    \n",
    "    print(f\"\\nProcessing {len(dataset)} queries...\")\n",
    "    \n",
    "    for record in tqdm(dataset, desc=\"Queries\"):\n",
    "        query_id = record['financebench_id']\n",
    "        query = record['question']\n",
    "        evidence = record['evidence']\n",
    "        doc_name = record['doc_name']\n",
    "        \n",
    "        # Retrieve documents\n",
    "        try:\n",
    "            if mode == \"global\":\n",
    "                retrieved_docs = retrieve_global(vectorstore, query, k)\n",
    "            elif mode == \"singledoc\":\n",
    "                retrieved_docs = retrieve_single_doc(vectorstore, query, doc_name, k)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode: {mode}\")\n",
    "            \n",
    "            # Calculate MRR\n",
    "            mrr_score, rank = calculate_mrr_for_query(retrieved_docs, evidence, chunk_size, use_page_tolerance)\n",
    "            mrr_scores.append(mrr_score)\n",
    "            \n",
    "            # Store result (convert evidence to 1-indexed for consistency)\n",
    "            result = {\n",
    "                'query_id': query_id,\n",
    "                'query': query,\n",
    "                'expected_doc': doc_name,\n",
    "                'expected_evidence': [\n",
    "                    {\n",
    "                        'doc_name': ev['doc_name'],\n",
    "                        'page_number': ev['evidence_page_num'] + 1  # Convert to 1-indexed\n",
    "                    }\n",
    "                    for ev in evidence\n",
    "                ],\n",
    "                'retrieved_docs': retrieved_docs,\n",
    "                'mrr_score': mrr_score,\n",
    "                'rank': rank\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ Error processing query {query_id}: {e}\")\n",
    "            results.append({\n",
    "                'query_id': query_id,\n",
    "                'query': query,\n",
    "                'error': str(e),\n",
    "                'mrr_score': 0.0,\n",
    "                'rank': -1\n",
    "            })\n",
    "            mrr_scores.append(0.0)\n",
    "    \n",
    "    # Calculate average MRR\n",
    "    avg_mrr = sum(mrr_scores) / len(mrr_scores) if mrr_scores else 0.0\n",
    "    \n",
    "    # Add summary\n",
    "    results.append({\n",
    "        'summary': {\n",
    "            'provider': provider,\n",
    "            'model': model,\n",
    "            'chunk_size': chunk_size,\n",
    "            'k': k,\n",
    "            'mode': mode,\n",
    "            'use_page_tolerance': use_page_tolerance,\n",
    "            'total_queries': len(dataset),\n",
    "            'average_mrr': avg_mrr\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    # Save results\n",
    "    save_results(results, provider, model, chunk_size, k, mode, output_dir)\n",
    "    \n",
    "    print(f\"\\n✓ Average MRR: {avg_mrr:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'status': 'completed',\n",
    "        'average_mrr': avg_mrr,\n",
    "        'total_queries': len(dataset)\n",
    "    }\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.2 Batch Evaluation\n",
    "\n",
    "# %%\n",
    "def evaluate_multiple_configurations(\n",
    "    dataset,\n",
    "    configurations: List[Dict],\n",
    "    k_values: List[int],\n",
    "    modes: List[str],\n",
    "    use_page_tolerance: bool = True,\n",
    "    output_dir: str = OUTPUT_DIR\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate multiple configurations.\n",
    "    \n",
    "    Args:\n",
    "        dataset: FinanceBench dataset\n",
    "        configurations: List of {provider, model, chunk_sizes}\n",
    "        k_values: List of k values to test\n",
    "        modes: List of modes [\"global\", \"singledoc\"]\n",
    "        use_page_tolerance: If True, use chunk-size-aware page tolerance. If False, exact match only.\n",
    "        output_dir: Output directory\n",
    "        \n",
    "    Returns:\n",
    "        Summary of all evaluations\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BATCH EVALUATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Configurations: {len(configurations)}\")\n",
    "    print(f\"K values: {k_values}\")\n",
    "    print(f\"Modes: {modes}\")\n",
    "    print(f\"Page Tolerance: {'ENABLED' if use_page_tolerance else 'DISABLED (exact match)'}\")\n",
    "    \n",
    "    # Calculate total runs\n",
    "    total_runs = 0\n",
    "    for config in configurations:\n",
    "        total_runs += len(config['chunk_sizes']) * len(k_values) * len(modes)\n",
    "    \n",
    "    print(f\"Total evaluation runs: {total_runs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Track results\n",
    "    all_results = []\n",
    "    completed = 0\n",
    "    skipped = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Iterate through all combinations\n",
    "    for config in configurations:\n",
    "        provider = config['provider']\n",
    "        model = config['model']\n",
    "        chunk_sizes = config['chunk_sizes']\n",
    "        \n",
    "        for chunk_size in chunk_sizes:\n",
    "            for k in k_values:\n",
    "                for mode in modes:\n",
    "                    result = evaluate_single_configuration(\n",
    "                        dataset=dataset,\n",
    "                        provider=provider,\n",
    "                        model=model,\n",
    "                        chunk_size=chunk_size,\n",
    "                        k=k,\n",
    "                        mode=mode,\n",
    "                        use_page_tolerance=use_page_tolerance,\n",
    "                        output_dir=output_dir\n",
    "                    )\n",
    "                    \n",
    "                    all_results.append({\n",
    "                        'provider': provider,\n",
    "                        'model': model,\n",
    "                        'chunk_size': chunk_size,\n",
    "                        'k': k,\n",
    "                        'mode': mode,\n",
    "                        'result': result\n",
    "                    })\n",
    "                    \n",
    "                    if result['status'] == 'completed':\n",
    "                        completed += 1\n",
    "                    elif result['status'] == 'skipped':\n",
    "                        skipped += 1\n",
    "                    else:\n",
    "                        failed += 1\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BATCH EVALUATION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total runs: {total_runs}\")\n",
    "    print(f\"Completed: {completed}\")\n",
    "    print(f\"Skipped: {skipped}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return {\n",
    "        'total_runs': total_runs,\n",
    "        'completed': completed,\n",
    "        'skipped': skipped,\n",
    "        'failed': failed,\n",
    "        'results': all_results\n",
    "    }\n",
    "\n",
    "# %%\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a114f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Test Retrieval Function\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Test Retrieval with Sample Text\n",
    "# \n",
    "# Use this to verify embeddings are working correctly by testing with \n",
    "# known text from your documents.\n",
    "\n",
    "# %%\n",
    "def test_retrieval(\n",
    "    query_text: str,\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    k: int = 10,\n",
    "    mode: str = \"global\",\n",
    "    target_doc_name: str = None,\n",
    "    use_page_tolerance: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Test retrieval with a sample query.\n",
    "    \n",
    "    Args:\n",
    "        query_text: Text to search for (copy from actual document)\n",
    "        provider: \"ollama\" or \"openai\"\n",
    "        model: Model name\n",
    "        chunk_size: Chunk size to test\n",
    "        k: Number of results\n",
    "        mode: \"global\" or \"singledoc\"\n",
    "        target_doc_name: Required if mode is \"singledoc\"\n",
    "        use_page_tolerance: If True, use chunk-size-aware tolerance\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"TEST RETRIEVAL\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Provider: {provider}\")\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Chunk size: {chunk_size}\")\n",
    "    print(f\"Mode: {mode}\")\n",
    "    print(f\"K: {k}\")\n",
    "    print(f\"Page Tolerance: {'ENABLED' if use_page_tolerance else 'DISABLED'}\")\n",
    "    print(f\"\\nQuery (first 200 chars):\")\n",
    "    print(f\"{query_text[:200]}...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load vectorstore\n",
    "    try:\n",
    "        vectorstore = load_vectorstore(provider, model, chunk_size)\n",
    "        print(f\"✓ Vectorstore loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Retrieve\n",
    "    try:\n",
    "        if mode == \"global\":\n",
    "            results = retrieve_global(vectorstore, query_text, k)\n",
    "        elif mode == \"singledoc\":\n",
    "            if not target_doc_name:\n",
    "                print(\"✗ target_doc_name required for singledoc mode\")\n",
    "                return\n",
    "            results = retrieve_single_doc(vectorstore, query_text, target_doc_name, k)\n",
    "        else:\n",
    "            print(f\"✗ Unknown mode: {mode}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n✓ Retrieved {len(results)} documents\")\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for doc_meta in results:\n",
    "            print(f\"\\nRank {doc_meta['rank']}: {doc_meta['doc_name']}, Page {doc_meta['page_number']}\")\n",
    "        \n",
    "        # Check if top result seems correct\n",
    "        if results:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"TOP RESULT ANALYSIS\")\n",
    "            print(\"=\"*60)\n",
    "            top = results[0]\n",
    "            print(f\"Document: {top['doc_name']}\")\n",
    "            print(f\"Page: {top['page_number']}\")\n",
    "            print(f\"Rank: {top['rank']}\")\n",
    "            \n",
    "            # Try to get the actual content\n",
    "            try:\n",
    "                full_results = vectorstore.similarity_search(query_text, k=1)\n",
    "                if full_results:\n",
    "                    content = full_results[0].page_content\n",
    "                    print(f\"\\nTop result content (first 300 chars):\")\n",
    "                    print(f\"{content[:300]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not fetch content: {e}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Retrieval failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "601c3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST RETRIEVAL\n",
      "============================================================\n",
      "Provider: ollama\n",
      "Model: nomic-embed-text\n",
      "Chunk size: 512\n",
      "Mode: singledoc\n",
      "K: 10\n",
      "Page Tolerance: ENABLED\n",
      "\n",
      "Query (first 200 chars):\n",
      "\n",
      "The management of General Mills, Inc. is responsible for the fairness and accuracy of the consolidated financial statements. The statements have been\n",
      "prepared in accordance with accounting principles...\n",
      "============================================================\n",
      "✓ Vectorstore loaded\n",
      "\n",
      "✓ Retrieved 10 documents\n",
      "\n",
      "============================================================\n",
      "RESULTS\n",
      "============================================================\n",
      "\n",
      "Rank 1: GENERALMILLS_2019_10K, Page 50\n",
      "\n",
      "Rank 2: GENERALMILLS_2019_10K, Page 110\n",
      "\n",
      "Rank 3: GENERALMILLS_2019_10K, Page 51\n",
      "\n",
      "Rank 4: GENERALMILLS_2019_10K, Page 136\n",
      "\n",
      "Rank 5: GENERALMILLS_2019_10K, Page 52\n",
      "\n",
      "Rank 6: GENERALMILLS_2019_10K, Page 51\n",
      "\n",
      "Rank 7: GENERALMILLS_2019_10K, Page 58\n",
      "\n",
      "Rank 8: GENERALMILLS_2019_10K, Page 110\n",
      "\n",
      "Rank 9: GENERALMILLS_2019_10K, Page 139\n",
      "\n",
      "Rank 10: GENERALMILLS_2019_10K, Page 140\n",
      "\n",
      "============================================================\n",
      "TOP RESULT ANALYSIS\n",
      "============================================================\n",
      "Document: GENERALMILLS_2019_10K\n",
      "Page: 50\n",
      "Rank: 1\n",
      "\n",
      "Top result content (first 300 chars):\n",
      "45 \n",
      " \n",
      "ITEM 8 - Financial Statements and Supplementary Data  \n",
      " \n",
      "REPORT OF MANAGEMENT RESPONSIBILITIES \n",
      " \n",
      "The management of General Mills, Inc. is responsible for the fairness and accuracy of the consolidated financial statements. The \n",
      "statements have been prepared in accordance with accounting princi...\n",
      "============================================================\n",
      "TEST RETRIEVAL\n",
      "============================================================\n",
      "Provider: ollama\n",
      "Model: nomic-embed-text\n",
      "Chunk size: 256\n",
      "Mode: singledoc\n",
      "K: 10\n",
      "Page Tolerance: ENABLED\n",
      "\n",
      "Query (first 200 chars):\n",
      "\n",
      "SG&A, measured as a percent of sales, increased in 2022 when compared to the same period last year. SG&A was impacted by increased special item costs for significant\n",
      "litigation primarily related to s...\n",
      "============================================================\n",
      "✓ Vectorstore loaded\n",
      "\n",
      "✓ Retrieved 10 documents\n",
      "\n",
      "============================================================\n",
      "RESULTS\n",
      "============================================================\n",
      "\n",
      "Rank 1: 3M_2022_10K, Page 27\n",
      "\n",
      "Rank 2: 3M_2022_10K, Page 27\n",
      "\n",
      "Rank 3: 3M_2022_10K, Page 30\n",
      "\n",
      "Rank 4: 3M_2022_10K, Page 39\n",
      "\n",
      "Rank 5: 3M_2022_10K, Page 29\n",
      "\n",
      "Rank 6: 3M_2022_10K, Page 24\n",
      "\n",
      "Rank 7: 3M_2022_10K, Page 31\n",
      "\n",
      "Rank 8: 3M_2022_10K, Page 22\n",
      "\n",
      "Rank 9: 3M_2022_10K, Page 65\n",
      "\n",
      "Rank 10: 3M_2022_10K, Page 20\n",
      "\n",
      "============================================================\n",
      "TOP RESULT ANALYSIS\n",
      "============================================================\n",
      "Document: 3M_2022_10K\n",
      "Page: 27\n",
      "Rank: 1\n",
      "\n",
      "Top result content (first 300 chars):\n",
      "Selling, General and Administrative Expenses:\n",
      "SG&A, measured as a percent of sales, increased in 2022 when compared to the same period last year. SG&A was impacted by increased special item costs for significant\n",
      "litigation primarily related to steps toward resolving Combat Arms Earplugs litigation (...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'doc_name': '3M_2022_10K', 'page_number': 27, 'rank': 1},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 27, 'rank': 2},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 30, 'rank': 3},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 39, 'rank': 4},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 29, 'rank': 5},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 24, 'rank': 6},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 31, 'rank': 7},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 22, 'rank': 8},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 65, 'rank': 9},\n",
       " {'doc_name': '3M_2022_10K', 'page_number': 20, 'rank': 10}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Example Usage\n",
    "\n",
    "# %%\n",
    "# Example #1: GENERALMILLS 2019 10K - Page 50/140\n",
    "sample_query1 = \"\"\"\n",
    "The management of General Mills, Inc. is responsible for the fairness and accuracy of the consolidated financial statements. The statements have been\n",
    "prepared in accordance with accounting principles that are generally accepted in the United States, using management’s best estimates and judgments where\n",
    "appropriate. The financial information throughout this Annual Report on Form 10-K is consistent with our consolidated financial statements.\n",
    "Management has established a system of internal controls that provides reasonable assurance that assets are adequately safeguarded and transactions are\n",
    "recorded accurately in all material respects, in accordance with management’s authorization. We maintain a strong audit program that independently\n",
    "evaluates the adequacy and effectiveness of internal controls. Our internal controls provide for appropriate separation of duties and responsibilities, and\n",
    "there are documented policies regarding use of our assets and proper financial reporting. These formally stated and regularly communicated policies\n",
    "demand highly ethical conduct from all employees.\n",
    "The Audit Committee of the Board of Directors meets regularly with management, internal auditors, and our independent registered public accounting firm\n",
    "to review internal control, auditing, and financial reporting matters. The independent registered public accounting firm, internal auditors, and employees\n",
    "have full and free access to the Audit Committee at any time.\n",
    "The Audit Committee reviewed and approved the Company’s annual financial statements. The Audit Committee recommended, and the Board of Directors\n",
    "approved, that the consolidated financial statements be included in the Annual Report. The Audit Committee also appointed KPMG LLP to serve as the\n",
    "Company’s independent registered public accounting firm for fiscal 2020\n",
    "\"\"\"\n",
    "\n",
    "test_retrieval(\n",
    "    query_text=sample_query1,\n",
    "    provider=\"ollama\",\n",
    "    model=\"nomic-embed-text\",\n",
    "    chunk_size=512,\n",
    "    k=10,\n",
    "    mode= \"singledoc\", # \"global\", \"singledoc\"\n",
    "    use_page_tolerance= True,\n",
    "    target_doc_name= \"GENERALMILLS_2019_10K\" # no need if mode is \"global\"\n",
    ")\n",
    "\n",
    "sample_query2 = \"\"\"\n",
    "SG&A, measured as a percent of sales, increased in 2022 when compared to the same period last year. SG&A was impacted by increased special item costs for significant\\nlitigation primarily related to steps toward resolving Combat Arms Earplugs litigation (discussed in Note 16) resulting in a 2022 second quarter pre-tax charge of approximately\\n$1.2 billion, certain impairment costs related to exiting PFAS manufacturing (see Note 15), costs related to exiting Russia (see Note 15), divestiture-related\n",
    "\"\"\"\n",
    "\n",
    "test_retrieval(\n",
    "    query_text=sample_query2,\n",
    "    provider=\"ollama\",\n",
    "    model=\"nomic-embed-text\",\n",
    "    chunk_size=256,\n",
    "    k=10,\n",
    "    mode= \"singledoc\", # \"global\", \"singledoc\"\n",
    "    use_page_tolerance= True,\n",
    "    target_doc_name= \"3M_2022_10K\" # no need if mode is \"global\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Example: Test single-doc mode\n",
    "# test_retrieval(\n",
    "#     query_text=\"Your sample text here\",\n",
    "#     provider=\"ollama\",\n",
    "#     model=\"nomic-embed-text\",\n",
    "#     chunk_size=512,\n",
    "#     k=10,\n",
    "#     mode=\"singledoc\",\n",
    "#     target_doc_name=\"3M_2018_10K\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f096ca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION PLAN\n",
      "============================================================\n",
      "\n",
      "ollama/bge-m3\n",
      "  Chunk sizes: [256, 512, 1024, 2048]\n",
      "  Evaluation runs: 8\n",
      "  Output files:\n",
      "    - ollama_bge-m3_chunk256_k20_global.json [EXISTS]\n",
      "    - ollama_bge-m3_chunk256_k20_singledoc.json [EXISTS]\n",
      "    - ollama_bge-m3_chunk512_k20_global.json [EXISTS]\n",
      "    - ollama_bge-m3_chunk512_k20_singledoc.json [EXISTS]\n",
      "    - ollama_bge-m3_chunk1024_k20_global.json [EXISTS]\n",
      "    - ollama_bge-m3_chunk1024_k20_singledoc.json [EXISTS]\n",
      "    - ollama_bge-m3_chunk2048_k20_global.json [EXISTS]\n",
      "    - ollama_bge-m3_chunk2048_k20_singledoc.json [EXISTS]\n",
      "\n",
      "ollama/nomic-embed-text\n",
      "  Chunk sizes: [256, 512, 1024, 2048]\n",
      "  Evaluation runs: 8\n",
      "  Output files:\n",
      "    - ollama_nomic-embed-text_chunk256_k20_global.json [EXISTS]\n",
      "    - ollama_nomic-embed-text_chunk256_k20_singledoc.json [EXISTS]\n",
      "    - ollama_nomic-embed-text_chunk512_k20_global.json [EXISTS]\n",
      "    - ollama_nomic-embed-text_chunk512_k20_singledoc.json [EXISTS]\n",
      "    - ollama_nomic-embed-text_chunk1024_k20_global.json [EXISTS]\n",
      "    - ollama_nomic-embed-text_chunk1024_k20_singledoc.json [EXISTS]\n",
      "    - ollama_nomic-embed-text_chunk2048_k20_global.json [EXISTS]\n",
      "    - ollama_nomic-embed-text_chunk2048_k20_singledoc.json [EXISTS]\n",
      "\n",
      "openai/text-embedding-3-small\n",
      "  Chunk sizes: [256, 512, 1024, 2048]\n",
      "  Evaluation runs: 8\n",
      "  Output files:\n",
      "    - openai_text-embedding-3-small_chunk256_k20_global.json [EXISTS]\n",
      "    - openai_text-embedding-3-small_chunk256_k20_singledoc.json [EXISTS]\n",
      "    - openai_text-embedding-3-small_chunk512_k20_global.json [EXISTS]\n",
      "    - openai_text-embedding-3-small_chunk512_k20_singledoc.json [EXISTS]\n",
      "    - openai_text-embedding-3-small_chunk1024_k20_global.json [EXISTS]\n",
      "    - openai_text-embedding-3-small_chunk1024_k20_singledoc.json [EXISTS]\n",
      "    - openai_text-embedding-3-small_chunk2048_k20_global.json [EXISTS]\n",
      "    - openai_text-embedding-3-small_chunk2048_k20_singledoc.json [EXISTS]\n",
      "\n",
      "openai/text-embedding-3-large\n",
      "  Chunk sizes: [512, 1024]\n",
      "  Evaluation runs: 4\n",
      "  Output files:\n",
      "    - openai_text-embedding-3-large_chunk512_k20_global.json [EXISTS]\n",
      "    - openai_text-embedding-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "    - openai_text-embedding-3-large_chunk1024_k20_global.json [EXISTS]\n",
      "    - openai_text-embedding-3-large_chunk1024_k20_singledoc.json [EXISTS]\n",
      "\n",
      "voyage/voyage-3-large\n",
      "  Chunk sizes: [512, 1024, 2048]\n",
      "  Evaluation runs: 6\n",
      "  Output files:\n",
      "    - voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "    - voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "    - voyage_voyage-3-large_chunk1024_k20_global.json [EXISTS]\n",
      "    - voyage_voyage-3-large_chunk1024_k20_singledoc.json [EXISTS]\n",
      "    - voyage_voyage-3-large_chunk2048_k20_global.json [EXISTS]\n",
      "    - voyage_voyage-3-large_chunk2048_k20_singledoc.json [EXISTS]\n",
      "\n",
      "voyage/voyage-finance-2\n",
      "  Chunk sizes: [512, 1024]\n",
      "  Evaluation runs: 4\n",
      "  Output files:\n",
      "    - voyage_voyage-finance-2_chunk512_k20_global.json [TO CREATE]\n",
      "    - voyage_voyage-finance-2_chunk512_k20_singledoc.json [TO CREATE]\n",
      "    - voyage_voyage-finance-2_chunk1024_k20_global.json [EXISTS]\n",
      "    - voyage_voyage-finance-2_chunk1024_k20_singledoc.json [EXISTS]\n",
      "\n",
      "============================================================\n",
      "Total evaluation runs: 38\n",
      "Output directory: ../../evaluation_results/mrr_embeddings\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "BATCH EVALUATION\n",
      "============================================================\n",
      "Configurations: 6\n",
      "K values: [20]\n",
      "Modes: ['global', 'singledoc']\n",
      "Page Tolerance: ENABLED\n",
      "Total evaluation runs: 38\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=256, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=256, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=512, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=512, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=1024, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=1024, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=2048, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/bge-m3, chunk=2048, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=256, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=256, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=512, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=512, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=1024, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=1024, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=2048, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ollama/nomic-embed-text, chunk=2048, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=256, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=256, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=512, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=512, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=1024, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=1024, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=2048, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-small, chunk=2048, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-large, chunk=512, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-large, chunk=512, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-large, chunk=1024, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: openai/text-embedding-3-large, chunk=1024, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large, chunk=512, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large, chunk=512, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large, chunk=1024, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large, chunk=1024, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large, chunk=2048, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large, chunk=2048, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-finance-2, chunk=512, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "Loading vectorstore...\n",
      "✓ Loaded (28,634 documents)\n",
      "\n",
      "Processing 150 queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dafb373f918442cbe8971aa239050c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Queries:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "\n",
      "✓ Average MRR: 0.4016\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-finance-2, chunk=512, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "Loading vectorstore...\n",
      "✓ Loaded (28,634 documents)\n",
      "\n",
      "Processing 150 queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf843ae844b84707bef29a356665d598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Queries:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "\n",
      "✓ Average MRR: 0.4646\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-finance-2, chunk=1024, k=20, mode=global\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-finance-2, chunk=1024, k=20, mode=singledoc\n",
      "Page Tolerance: ENABLED\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "BATCH EVALUATION SUMMARY\n",
      "============================================================\n",
      "Total runs: 38\n",
      "Completed: 2\n",
      "Skipped: 36\n",
      "Failed: 0\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DETAILED RESULTS\n",
      "============================================================\n",
      "\n",
      "voyage/voyage-finance-2, chunk=512, k=20, mode=global\n",
      "  Average MRR: 0.4016\n",
      "\n",
      "voyage/voyage-finance-2, chunk=512, k=20, mode=singledoc\n",
      "  Average MRR: 0.4646\n",
      "\n",
      "============================================================\n",
      "GENERATED FILES\n",
      "============================================================\n",
      "\n",
      "Total JSON files: 38\n",
      "\n",
      "  ollama_bge-m3_chunk1024_k20_global.json (377.2 KB)\n",
      "  ollama_bge-m3_chunk1024_k20_singledoc.json (258.3 KB)\n",
      "  ollama_bge-m3_chunk2048_k20_global.json (378.1 KB)\n",
      "  ollama_bge-m3_chunk2048_k20_singledoc.json (239.2 KB)\n",
      "  ollama_bge-m3_chunk256_k20_global.json (376.3 KB)\n",
      "  ollama_bge-m3_chunk256_k20_singledoc.json (317.2 KB)\n",
      "  ollama_bge-m3_chunk512_k20_global.json (376.6 KB)\n",
      "  ollama_bge-m3_chunk512_k20_singledoc.json (320.4 KB)\n",
      "  ollama_nomic-embed-text_chunk1024_k20_global.json (375.8 KB)\n",
      "  ollama_nomic-embed-text_chunk1024_k20_singledoc.json (250.2 KB)\n",
      "  ollama_nomic-embed-text_chunk2048_k20_global.json (376.5 KB)\n",
      "  ollama_nomic-embed-text_chunk2048_k20_singledoc.json (252.8 KB)\n",
      "  ollama_nomic-embed-text_chunk256_k20_global.json (375.8 KB)\n",
      "  ollama_nomic-embed-text_chunk256_k20_singledoc.json (278.9 KB)\n",
      "  ollama_nomic-embed-text_chunk512_k20_global.json (375.9 KB)\n",
      "  ollama_nomic-embed-text_chunk512_k20_singledoc.json (274.2 KB)\n",
      "  openai_text-embedding-3-large_chunk1024_k20_global.json (377.7 KB)\n",
      "  openai_text-embedding-3-large_chunk1024_k20_singledoc.json (339.5 KB)\n",
      "  openai_text-embedding-3-large_chunk512_k20_global.json (377.2 KB)\n",
      "  openai_text-embedding-3-large_chunk512_k20_singledoc.json (340.2 KB)\n",
      "  openai_text-embedding-3-small_chunk1024_k20_global.json (377.3 KB)\n",
      "  openai_text-embedding-3-small_chunk1024_k20_singledoc.json (342.2 KB)\n",
      "  openai_text-embedding-3-small_chunk2048_k20_global.json (377.5 KB)\n",
      "  openai_text-embedding-3-small_chunk2048_k20_singledoc.json (344.8 KB)\n",
      "  openai_text-embedding-3-small_chunk256_k20_global.json (377.7 KB)\n",
      "  openai_text-embedding-3-small_chunk256_k20_singledoc.json (328.7 KB)\n",
      "  openai_text-embedding-3-small_chunk512_k20_global.json (377.2 KB)\n",
      "  openai_text-embedding-3-small_chunk512_k20_singledoc.json (340.3 KB)\n",
      "  voyage_voyage-3-large_chunk1024_k20_global.json (377.8 KB)\n",
      "  voyage_voyage-3-large_chunk1024_k20_singledoc.json (343.6 KB)\n",
      "  voyage_voyage-3-large_chunk2048_k20_global.json (377.9 KB)\n",
      "  voyage_voyage-3-large_chunk2048_k20_singledoc.json (293.3 KB)\n",
      "  voyage_voyage-3-large_chunk512_k20_global.json (377.2 KB)\n",
      "  voyage_voyage-3-large_chunk512_k20_singledoc.json (300.6 KB)\n",
      "  voyage_voyage-finance-2_chunk1024_k20_global.json (377.0 KB)\n",
      "  voyage_voyage-finance-2_chunk1024_k20_singledoc.json (303.7 KB)\n",
      "  voyage_voyage-finance-2_chunk512_k20_global.json (377.3 KB)\n",
      "  voyage_voyage-finance-2_chunk512_k20_singledoc.json (355.4 KB)\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Page Tolerance was: ENABLED\n",
      "To run with different tolerance setting:\n",
      "  1. Change USE_PAGE_TOLERANCE in section 4.2\n",
      "  2. Delete existing JSON files (or they'll be skipped)\n",
      "  3. Re-run section 4.4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 4: Configuration and Execution\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.1 Define Configurations to Test\n",
    "\n",
    "# %%\n",
    "# Define which embedding models and chunk sizes to evaluate\n",
    "configurations = [\n",
    "    {\n",
    "        'provider': 'ollama',\n",
    "        'model': 'bge-m3',\n",
    "        'chunk_sizes': [256, 512, 1024, 2048]\n",
    "    },\n",
    "    {\n",
    "        'provider': 'ollama',\n",
    "        'model': 'nomic-embed-text',\n",
    "        'chunk_sizes': [256, 512, 1024, 2048]\n",
    "    },\n",
    "    {\n",
    "        'provider': 'openai',\n",
    "        'model': 'text-embedding-3-small',\n",
    "        'chunk_sizes': [256, 512, 1024, 2048]\n",
    "    },\n",
    "    {\n",
    "        'provider': 'openai',\n",
    "        'model': 'text-embedding-3-large',\n",
    "        'chunk_sizes': [512, 1024]\n",
    "    },\n",
    "    {\n",
    "        'provider': 'voyage',\n",
    "        'model': 'voyage-3-large',\n",
    "        'chunk_sizes': [512, 1024, 2048]\n",
    "    },\n",
    "    {\n",
    "        'provider': 'voyage',\n",
    "        'model': 'voyage-finance-2',\n",
    "        'chunk_sizes': [512, 1024]\n",
    "    },\n",
    "]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.2 Define Evaluation Parameters\n",
    "\n",
    "# %%\n",
    "# K values to test (number of documents to retrieve)\n",
    "k_values = [20]\n",
    "\n",
    "# Modes to test\n",
    "modes = ['global', 'singledoc']\n",
    "\n",
    "# Page tolerance setting\n",
    "# - True: Use chunk-size-aware page tolerance (lenient matching for large chunks)\n",
    "# - False: Exact page match only (strict evaluation)\n",
    "USE_PAGE_TOLERANCE = True\n",
    "\n",
    "# %%\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATION PLAN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_runs = 0\n",
    "for config in configurations:\n",
    "    provider = config['provider']\n",
    "    model = config['model']\n",
    "    chunk_sizes = config['chunk_sizes']\n",
    "    \n",
    "    print(f\"\\n{provider}/{model}\")\n",
    "    print(f\"  Chunk sizes: {chunk_sizes}\")\n",
    "    \n",
    "    runs_for_config = len(chunk_sizes) * len(k_values) * len(modes)\n",
    "    total_runs += runs_for_config\n",
    "    \n",
    "    print(f\"  Evaluation runs: {runs_for_config}\")\n",
    "    \n",
    "    # Show output filenames that will be generated\n",
    "    print(f\"  Output files:\")\n",
    "    for chunk_size in chunk_sizes:\n",
    "        for k in k_values:\n",
    "            for mode in modes:\n",
    "                filename = get_output_filename(provider, model, chunk_size, k, mode)\n",
    "                exists = check_if_results_exist(provider, model, chunk_size, k, mode, OUTPUT_DIR)\n",
    "                status = \"EXISTS\" if exists else \"TO CREATE\"\n",
    "                print(f\"    - {filename} [{status}]\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total evaluation runs: {total_runs}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Page Tolerance: {'ENABLED' if USE_PAGE_TOLERANCE else 'DISABLED'}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.4 Execute Evaluation\n",
    "\n",
    "# %%\n",
    "# Run batch evaluation\n",
    "summary = evaluate_multiple_configurations(\n",
    "    dataset=dataset,\n",
    "    configurations=configurations,\n",
    "    k_values=k_values,\n",
    "    modes=modes,\n",
    "    use_page_tolerance=USE_PAGE_TOLERANCE,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.5 View Results Summary\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for result in summary['results']:\n",
    "    if result['result']['status'] == 'completed':\n",
    "        print(f\"\\n{result['provider']}/{result['model']}, \"\n",
    "              f\"chunk={result['chunk_size']}, \"\n",
    "              f\"k={result['k']}, \"\n",
    "              f\"mode={result['mode']}\")\n",
    "        print(f\"  Average MRR: {result['result']['average_mrr']:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.6 List Generated Files\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATED FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "json_files = sorted(output_path.glob(\"*.json\"))\n",
    "\n",
    "print(f\"\\nTotal JSON files: {len(json_files)}\\n\")\n",
    "\n",
    "for filepath in json_files:\n",
    "    file_size = filepath.stat().st_size / 1024  # KB\n",
    "    print(f\"  {filepath.name} ({file_size:.1f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPage Tolerance was: {'ENABLED' if USE_PAGE_TOLERANCE else 'DISABLED'}\")\n",
    "print(f\"To run with different tolerance setting:\")\n",
    "print(f\"  1. Change USE_PAGE_TOLERANCE in section 4.2\")\n",
    "print(f\"  2. Delete existing JSON files (or they'll be skipped)\")\n",
    "print(f\"  3. Re-run section 4.4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
