{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48892aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n",
      "✓ OpenAI API key loaded\n",
      "✓ Ollama URL: http://localhost:11434\n",
      "✓ Configuration set\n",
      "  LLM Provider: ollama\n",
      "  LLM Model: llama3:8b\n",
      "  Output Directory: ../../expanded_queries\n",
      "  Dry Run: Disabled\n",
      "✓ Output directory ready: ../../expanded_queries\n",
      "⚠ Make sure Ollama is running at http://localhost:11434\n",
      "⚠ Make sure model 'llama3:8b' is pulled: ollama pull llama3:8b\n",
      "\n",
      "============================================================\n",
      "✓ STEP 1 COMPLETE - Setup & Configuration Ready\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Review configuration above\n",
      "  2. Modify LLM_PROVIDER or LLM_MODEL if needed\n",
      "  3. Proceed to Step 2: Template Definitions\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Query Expansion Creator for FinanceBench\n",
    "# ============================================================================\n",
    "# \n",
    "# This notebook generates expanded versions of FinanceBench queries using\n",
    "# various query expansion techniques (HyDE, query refinement, term expansion,\n",
    "# chain-of-thought, and domain adaptation).\n",
    "#\n",
    "# The expanded queries are saved as JSON files to be used in retrieval\n",
    "# evaluation experiments.\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # Query Expansion Creator\n",
    "# \n",
    "# ## Overview\n",
    "# This notebook implements multiple query expansion techniques for financial QA:\n",
    "# - **HyDE**: Generate hypothetical documents/answers\n",
    "# - **Query Refinement**: Clarify and formalize queries\n",
    "# - **Term Expansion**: Expand abbreviations and add synonyms\n",
    "# - **Chain-of-Thought**: Make implicit context explicit\n",
    "# - **Domain Adaptation**: Rephrase using financial/10-K language\n",
    "#\n",
    "# ## Output\n",
    "# Each expansion method produces a JSON file containing:\n",
    "# - Original queries from FinanceBench\n",
    "# - Expanded query versions\n",
    "# - Metadata (model, template, timestamps)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.1 Import Required Libraries\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# LangChain components\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.2 Load Environment Variables\n",
    "\n",
    "# %%\n",
    "# Load .env file from project root\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API keys\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
    "\n",
    "# Verify availability\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"✓ OpenAI API key loaded\")\n",
    "else:\n",
    "    print(\"⚠ OpenAI API key not found (required if using OpenAI provider)\")\n",
    "\n",
    "print(f\"✓ Ollama URL: {OLLAMA_BASE_URL}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.3 Configuration Constants\n",
    "\n",
    "# %%\n",
    "# ============================================================================\n",
    "# CONFIGURATION SECTION\n",
    "# ============================================================================\n",
    "\n",
    "# LLM Provider Configuration\n",
    "# Choose: \"openai\" or \"ollama\"\n",
    "# LLM_PROVIDER = \"openai\"  # Change to \"ollama\" for local models\n",
    "LLM_PROVIDER = \"ollama\"  # Change to \"ollama\" for local models\n",
    "\n",
    "# Model Selection\n",
    "# OpenAI options: \"gpt-4\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"\n",
    "# Ollama options: \"llama2\", \"mistral\", etc.\n",
    "# LLM_MODEL = \"gpt-4\"\n",
    "LLM_MODEL = \"llama3:8b\"\n",
    "\n",
    "# Paths\n",
    "OUTPUT_DIR = \"../../expanded_queries\"\n",
    "DATASET_NAME = \"PatronusAI/financebench\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "\n",
    "# Processing Parameters\n",
    "CALL_DELAY = 1  # Seconds between each LLM call (rate limiting)\n",
    "RETRY_DELAY = 30  # Seconds to wait before retry after failure\n",
    "MAX_RETRIES = 3  # Maximum number of retry attempts\n",
    "\n",
    "# Dry Run Configuration\n",
    "DRY_RUN_ENABLED = False  # Set True to test with sample queries\n",
    "DRY_RUN_SAMPLE_SIZE = 5  # Number of queries to test in dry run\n",
    "\n",
    "# Validation Parameters\n",
    "VALIDATION_CONFIG = {\n",
    "    \"min_length\": 10,  # Minimum characters for expanded query\n",
    "    \"max_length\": 1500,  # Maximum characters for expanded query\n",
    "    \"must_differ_from_original\": True,  # Expanded must differ from original\n",
    "    \"similarity_threshold\": 0.95  # Reject if >95% similar to original\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration set\")\n",
    "print(f\"  LLM Provider: {LLM_PROVIDER}\")\n",
    "print(f\"  LLM Model: {LLM_MODEL}\")\n",
    "print(f\"  Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Dry Run: {'Enabled' if DRY_RUN_ENABLED else 'Disabled'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.4 Create Output Directory\n",
    "\n",
    "# %%\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"✓ Output directory ready: {OUTPUT_DIR}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.5 Verify Configuration\n",
    "\n",
    "# %%\n",
    "# Verify that the selected provider has necessary credentials\n",
    "if LLM_PROVIDER == \"openai\" and not OPENAI_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"OpenAI provider selected but OPENAI_API_KEY not found in environment. \"\n",
    "        \"Please add it to your .env file or switch to 'ollama' provider.\"\n",
    "    )\n",
    "\n",
    "if LLM_PROVIDER == \"ollama\":\n",
    "    print(f\"⚠ Make sure Ollama is running at {OLLAMA_BASE_URL}\")\n",
    "    print(f\"⚠ Make sure model '{LLM_MODEL}' is pulled: ollama pull {LLM_MODEL}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 1 COMPLETE - Setup & Configuration Ready\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Review configuration above\")\n",
    "print(\"  2. Modify LLM_PROVIDER or LLM_MODEL if needed\")\n",
    "print(\"  3. Proceed to Step 2: Template Definitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74daef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined 13 expansion templates\n",
      "\n",
      "Template types:\n",
      "  - hyde_basic\n",
      "  - hyde_detailed\n",
      "  - hyde_financial_terminology\n",
      "  - query_refinement_clarification\n",
      "  - query_refinement_formal\n",
      "  - query_refinement_keyword_focused\n",
      "  - term_expansion_abbreviation\n",
      "  - term_expansion_synonym\n",
      "  - term_expansion_context_addition\n",
      "  - chain_of_thought_step_by_step\n",
      "  - chain_of_thought_explicit_context\n",
      "  - domain_adaptation_accounting_perspective\n",
      "  - domain_adaptation_10k_language\n",
      "✓ Created 13 LangChain PromptTemplate objects\n",
      "============================================================\n",
      "TEMPLATE FORMATTING TEST\n",
      "============================================================\n",
      "\n",
      "Test Query: What is the FY2018 capital expenditure amount (in USD millions) for 3M?\n",
      "\n",
      "Example Template: hyde_basic\n",
      "------------------------------------------------------------\n",
      "Given the following financial question, generate a concise hypothetical answer that would likely appear in company financial documents (10-K, 10-Q, earnings calls, or other SEC filings).\n",
      "\n",
      "Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M?\n",
      "\n",
      "Hypothetical Answer:\n",
      "------------------------------------------------------------\n",
      "\n",
      "✓ Template formatting works correctly\n",
      "✓ All templates ready to use\n",
      "\n",
      "============================================================\n",
      "TEMPLATE SUMMARY BY TYPE\n",
      "============================================================\n",
      "\n",
      "CHAIN OF:\n",
      "  ✓ chain_of_thought_step_by_step\n",
      "  ✓ chain_of_thought_explicit_context\n",
      "\n",
      "DOMAIN ADAPTATION:\n",
      "  ✓ domain_adaptation_accounting_perspective\n",
      "  ✓ domain_adaptation_10k_language\n",
      "\n",
      "HYDE BASIC:\n",
      "  ✓ hyde_basic\n",
      "\n",
      "HYDE DETAILED:\n",
      "  ✓ hyde_detailed\n",
      "\n",
      "HYDE FINANCIAL:\n",
      "  ✓ hyde_financial_terminology\n",
      "\n",
      "QUERY REFINEMENT:\n",
      "  ✓ query_refinement_clarification\n",
      "  ✓ query_refinement_formal\n",
      "  ✓ query_refinement_keyword_focused\n",
      "\n",
      "TERM EXPANSION:\n",
      "  ✓ term_expansion_abbreviation\n",
      "  ✓ term_expansion_synonym\n",
      "  ✓ term_expansion_context_addition\n",
      "\n",
      "============================================================\n",
      "✓ STEP 2 COMPLETE - All Templates Defined\n",
      "============================================================\n",
      "\n",
      "Template statistics:\n",
      "  Total templates: 13\n",
      "  Expansion types: 7\n",
      "\n",
      "Templates are designed to work with:\n",
      "  ✓ 10-K annual reports\n",
      "  ✓ 10-Q quarterly reports\n",
      "  ✓ Earnings call transcripts\n",
      "  ✓ Other SEC filings (8-K, etc.)\n",
      "\n",
      "Templates are stored in:\n",
      "  - TEMPLATES (dict): Raw template strings\n",
      "  - PROMPT_TEMPLATES (dict): LangChain PromptTemplate objects\n",
      "\n",
      "Next: Proceed to Step 3: Configuration Structure\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 2: Template Definitions\n",
    "# ============================================================================\n",
    "# \n",
    "# This section defines all query expansion templates using LangChain's\n",
    "# PromptTemplate. Each template is designed for a specific expansion\n",
    "# technique and can be easily modified without touching the core logic.\n",
    "#\n",
    "# Templates are designed to work with various FinanceBench document types:\n",
    "# - 10-K annual reports\n",
    "# - 10-Q quarterly reports\n",
    "# - Earnings call transcripts\n",
    "# - Other SEC filings\n",
    "#\n",
    "# Templates are organized by expansion type:\n",
    "# - HyDE (Hypothetical Document Expansion)\n",
    "# - Query Refinement\n",
    "# - Term Expansion\n",
    "# - Chain-of-Thought\n",
    "# - Domain Adaptation\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.1 Define All Expansion Templates\n",
    "# \n",
    "# Each template uses `{query}` as the placeholder for the original question.\n",
    "# The LLM will replace this with the actual FinanceBench question.\n",
    "\n",
    "# %%\n",
    "# ============================================================================\n",
    "# TEMPLATE DEFINITIONS\n",
    "# ============================================================================\n",
    "\n",
    "TEMPLATES = {\n",
    "    # ------------------------------------------------------------------------\n",
    "    # HyDE (Hypothetical Document Expansion)\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"hyde_basic\": \"\"\"Given the following financial question, generate a concise hypothetical answer that would likely appear in company financial documents (10-K, 10-Q, earnings calls, or other SEC filings).\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Hypothetical Answer:\"\"\",\n",
    "\n",
    "    \"hyde_detailed\": \"\"\"You are analyzing a company's financial documents (annual reports, quarterly filings, earnings call transcripts). Given the following question, write a detailed hypothetical paragraph that would contain the answer, including relevant context and financial terminology.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Hypothetical Paragraph:\"\"\",\n",
    "\n",
    "    \"hyde_financial_terminology\": \"\"\"Given the following financial question, generate a hypothetical answer using proper accounting and financial terminology as it would appear in SEC filings (10-K, 10-Q, 8-K) or earnings call transcripts.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Hypothetical Answer with Financial Terminology:\"\"\",\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Query Refinement\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"query_refinement_clarification\": \"\"\"Rephrase the following financial question to make it more explicit and unambiguous. Keep all key information but make implicit details explicit (such as fiscal year format, reporting period, specific financial statement sections, document types, etc.).\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Clarified Question:\"\"\",\n",
    "\n",
    "    \"query_refinement_formal\": \"\"\"Convert the following question into formal financial/accounting language as it would appear in analyst reports, SEC filings, or earnings call discussions. Maintain the question format.\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Formal Question:\"\"\",\n",
    "\n",
    "    \"query_refinement_keyword_focused\": \"\"\"Rewrite the following question emphasizing the key financial terms, metrics, and document-specific terminology (annual report, quarterly filing, earnings call, etc.). Make sure important financial keywords are explicit and prominent.\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Keyword-Focused Question:\"\"\",\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Term Expansion\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"term_expansion_abbreviation\": \"\"\"Expand all financial abbreviations, acronyms, and shortened terms in the following question while maintaining its original meaning and structure.\n",
    "\n",
    "Examples:\n",
    "- \"EPS\" → \"earnings per share\"\n",
    "- \"R&D\" → \"research and development\"\n",
    "- \"COGS\" → \"cost of goods sold\"\n",
    "- \"FY\" → \"fiscal year\"\n",
    "- \"YoY\" → \"year over year\"\n",
    "- \"QoQ\" → \"quarter over quarter\"\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Expanded Question:\"\"\",\n",
    "\n",
    "    \"term_expansion_synonym\": \"\"\"Rewrite the following question by adding financial synonyms and alternative terms in parentheses where appropriate. This helps capture documents that might use different terminology across annual reports, quarterly filings, and earnings discussions.\n",
    "\n",
    "Examples:\n",
    "- \"revenue\" → \"revenue (sales, net sales, total revenue)\"\n",
    "- \"profit\" → \"profit (net income, earnings, net profit)\"\n",
    "- \"expenses\" → \"expenses (costs, expenditures, operating expenses)\"\n",
    "- \"guidance\" → \"guidance (outlook, forecast, projections)\"\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Question with Synonyms:\"\"\",\n",
    "\n",
    "    \"term_expansion_context_addition\": \"\"\"Add implicit financial context to the following question by mentioning the likely source documents (10-K, 10-Q, earnings calls, press releases) or financial statements where the answer would be found.\n",
    "\n",
    "Examples:\n",
    "- Add phrases like: \"in the financial statements\", \"according to the 10-K/10-Q filing\", \"reported in the annual/quarterly report\", \"disclosed in the earnings call\", \"stated in the income statement/balance sheet\"\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Question with Context:\"\"\",\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Chain-of-Thought\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"chain_of_thought_step_by_step\": \"\"\"Rewrite the following financial question by breaking down what information is being requested into clear, explicit steps or components. Consider whether the answer would come from annual reports, quarterly reports, or earnings discussions.\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Step-by-Step Question:\"\"\",\n",
    "\n",
    "    \"chain_of_thought_explicit_context\": \"\"\"Rewrite the following question making all implicit information explicit, such as:\n",
    "- Time periods (fiscal year, quarter, specific dates, reporting period)\n",
    "- Document sources (10-K annual report, 10-Q quarterly report, earnings call transcript, SEC filing)\n",
    "- Financial statement sections (balance sheet, income statement, cash flow statement, MD&A)\n",
    "- Calculation methods or definitions\n",
    "- Reporting standards (GAAP, non-GAAP)\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Explicit Question:\"\"\",\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Domain Adaptation\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"domain_adaptation_accounting_perspective\": \"\"\"Rewrite the following question from an accounting or auditing perspective, using language that accountants and financial auditors would use when reviewing annual reports, quarterly filings, and financial statements.\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "Accounting Perspective Question:\"\"\",\n",
    "\n",
    "    \"domain_adaptation_10k_language\": \"\"\"Rewrite the following question using the exact language patterns, structure, and terminology typically found in SEC financial disclosures including 10-K annual reports, 10-Q quarterly reports, 8-K current reports, and earnings call transcripts.\n",
    "\n",
    "Original Question: {query}\n",
    "\n",
    "SEC Filing Style Question:\"\"\"\n",
    "}\n",
    "\n",
    "print(f\"✓ Defined {len(TEMPLATES)} expansion templates\")\n",
    "print(\"\\nTemplate types:\")\n",
    "for template_key in TEMPLATES.keys():\n",
    "    print(f\"  - {template_key}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.2 Create LangChain PromptTemplate Objects\n",
    "\n",
    "# %%\n",
    "# Convert string templates to LangChain PromptTemplate objects\n",
    "PROMPT_TEMPLATES = {}\n",
    "\n",
    "for template_name, template_string in TEMPLATES.items():\n",
    "    PROMPT_TEMPLATES[template_name] = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=template_string\n",
    "    )\n",
    "\n",
    "print(f\"✓ Created {len(PROMPT_TEMPLATES)} LangChain PromptTemplate objects\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.3 Test Template Formatting (Optional)\n",
    "\n",
    "# %%\n",
    "# Test that templates format correctly with a sample query\n",
    "test_query = \"What is the FY2018 capital expenditure amount (in USD millions) for 3M?\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEMPLATE FORMATTING TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTest Query: {test_query}\\n\")\n",
    "\n",
    "# Show one example template formatting\n",
    "example_template_name = \"hyde_basic\"\n",
    "example_prompt = PROMPT_TEMPLATES[example_template_name]\n",
    "formatted_prompt = example_prompt.format(query=test_query)\n",
    "\n",
    "print(f\"Example Template: {example_template_name}\")\n",
    "print(\"-\" * 60)\n",
    "print(formatted_prompt)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n✓ Template formatting works correctly\")\n",
    "print(\"✓ All templates ready to use\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.4 Template Summary\n",
    "\n",
    "# %%\n",
    "# Display summary of all templates organized by type\n",
    "from collections import defaultdict\n",
    "\n",
    "template_by_type = defaultdict(list)\n",
    "\n",
    "for template_name in TEMPLATES.keys():\n",
    "    # Extract type from template name (e.g., \"hyde_basic\" -> \"hyde\")\n",
    "    parts = template_name.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        expansion_type = '_'.join(parts[:2])  # e.g., \"hyde\", \"query_refinement\"\n",
    "        subtype = '_'.join(parts[2:]) if len(parts) > 2 else parts[1]\n",
    "    else:\n",
    "        expansion_type = parts[0]\n",
    "        subtype = \"default\"\n",
    "    \n",
    "    template_by_type[expansion_type].append(template_name)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEMPLATE SUMMARY BY TYPE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for exp_type, templates in sorted(template_by_type.items()):\n",
    "    print(f\"\\n{exp_type.upper().replace('_', ' ')}:\")\n",
    "    for template in templates:\n",
    "        print(f\"  ✓ {template}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 2 COMPLETE - All Templates Defined\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTemplate statistics:\")\n",
    "print(f\"  Total templates: {len(TEMPLATES)}\")\n",
    "print(f\"  Expansion types: {len(template_by_type)}\")\n",
    "print(\"\\nTemplates are designed to work with:\")\n",
    "print(\"  ✓ 10-K annual reports\")\n",
    "print(\"  ✓ 10-Q quarterly reports\")\n",
    "print(\"  ✓ Earnings call transcripts\")\n",
    "print(\"  ✓ Other SEC filings (8-K, etc.)\")\n",
    "print(\"\\nTemplates are stored in:\")\n",
    "print(\"  - TEMPLATES (dict): Raw template strings\")\n",
    "print(\"  - PROMPT_TEMPLATES (dict): LangChain PromptTemplate objects\")\n",
    "print(\"\\nNext: Proceed to Step 3: Configuration Structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bfbc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined 13 expansion configurations\n",
      "✓ All configurations reference valid templates\n",
      "✓ Selected 13 configurations to run\n",
      "\n",
      "Selected configurations:\n",
      "  - hyde_basic (temp=0.7)\n",
      "  - hyde_detailed (temp=0.8)\n",
      "  - hyde_financial_terminology (temp=0.7)\n",
      "  - query_refinement_clarification (temp=0.3)\n",
      "  - query_refinement_formal (temp=0.3)\n",
      "  - query_refinement_keyword_focused (temp=0.4)\n",
      "  - term_expansion_abbreviation (temp=0.3)\n",
      "  - term_expansion_synonym (temp=0.5)\n",
      "  - term_expansion_context_addition (temp=0.4)\n",
      "  - chain_of_thought_step_by_step (temp=0.5)\n",
      "  - chain_of_thought_explicit_context (temp=0.4)\n",
      "  - domain_adaptation_accounting_perspective (temp=0.4)\n",
      "  - domain_adaptation_10k_language (temp=0.4)\n",
      "✓ All selected configurations are valid\n",
      "\n",
      "============================================================\n",
      "OUTPUT FILE STATUS\n",
      "============================================================\n",
      "\n",
      "⚙️  Configs to process: 13\n",
      "  - expanded_queries_hyde_basic.json\n",
      "  - expanded_queries_hyde_detailed.json\n",
      "  - expanded_queries_hyde_financial_terminology.json\n",
      "  - expanded_queries_query_refinement_clarification.json\n",
      "  - expanded_queries_query_refinement_formal.json\n",
      "  - expanded_queries_query_refinement_keyword_focused.json\n",
      "  - expanded_queries_term_expansion_abbreviation.json\n",
      "  - expanded_queries_term_expansion_synonym.json\n",
      "  - expanded_queries_term_expansion_context_addition.json\n",
      "  - expanded_queries_chain_of_thought_step_by_step.json\n",
      "  - expanded_queries_chain_of_thought_explicit_context.json\n",
      "  - expanded_queries_domain_adaptation_accounting_perspective.json\n",
      "  - expanded_queries_domain_adaptation_10k_language.json\n",
      "\n",
      "============================================================\n",
      "CONFIGURATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Configurations by type:\n",
      "  chain_of_thought: 2\n",
      "  domain_adaptation: 2\n",
      "  hyde: 3\n",
      "  query_refinement: 3\n",
      "  term_expansion: 3\n",
      "\n",
      "Total configurations:\n",
      "  Selected to run: 13\n",
      "  Already complete: 0\n",
      "  Need processing: 13\n",
      "\n",
      "============================================================\n",
      "✓ STEP 3 COMPLETE - Configuration Structure Ready\n",
      "============================================================\n",
      "\n",
      "Next: Proceed to Step 4: Core Functions\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 3: Configuration Structure\n",
    "# ============================================================================\n",
    "# \n",
    "# This section defines the configuration structure for all expansion methods.\n",
    "# Each configuration specifies:\n",
    "# - expansion_type: High-level category (hyde, query_refinement, etc.)\n",
    "# - expansion_sub_type: Specific variant within the type\n",
    "# - template_key: Which template to use from PROMPT_TEMPLATES\n",
    "# - temperature: LLM temperature for this expansion method\n",
    "#\n",
    "# The CONFIGS_TO_RUN list allows you to easily select which expansions\n",
    "# to execute by commenting/uncommenting entries.\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.1 Define All Expansion Configurations\n",
    "# \n",
    "# Each configuration maps to one template and specifies its parameters.\n",
    "\n",
    "# %%\n",
    "# ============================================================================\n",
    "# ALL EXPANSION CONFIGURATIONS\n",
    "# ============================================================================\n",
    "\n",
    "ALL_EXPANSION_CONFIGS = {\n",
    "    # ------------------------------------------------------------------------\n",
    "    # HyDE (Hypothetical Document Expansion)\n",
    "    # Higher temperature for creative hypothesis generation\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"hyde_basic\": {\n",
    "        \"expansion_type\": \"hyde\",\n",
    "        \"expansion_sub_type\": \"basic\",\n",
    "        \"template_key\": \"hyde_basic\",\n",
    "        \"temperature\": 0.7\n",
    "    },\n",
    "    \n",
    "    \"hyde_detailed\": {\n",
    "        \"expansion_type\": \"hyde\",\n",
    "        \"expansion_sub_type\": \"detailed\",\n",
    "        \"template_key\": \"hyde_detailed\",\n",
    "        \"temperature\": 0.8\n",
    "    },\n",
    "    \n",
    "    \"hyde_financial_terminology\": {\n",
    "        \"expansion_type\": \"hyde\",\n",
    "        \"expansion_sub_type\": \"financial_terminology\",\n",
    "        \"template_key\": \"hyde_financial_terminology\",\n",
    "        \"temperature\": 0.7\n",
    "    },\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # Query Refinement\n",
    "    # Lower temperature for precise rephrasing\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"query_refinement_clarification\": {\n",
    "        \"expansion_type\": \"query_refinement\",\n",
    "        \"expansion_sub_type\": \"clarification\",\n",
    "        \"template_key\": \"query_refinement_clarification\",\n",
    "        \"temperature\": 0.3\n",
    "    },\n",
    "    \n",
    "    \"query_refinement_formal\": {\n",
    "        \"expansion_type\": \"query_refinement\",\n",
    "        \"expansion_sub_type\": \"formal\",\n",
    "        \"template_key\": \"query_refinement_formal\",\n",
    "        \"temperature\": 0.3\n",
    "    },\n",
    "    \n",
    "    \"query_refinement_keyword_focused\": {\n",
    "        \"expansion_type\": \"query_refinement\",\n",
    "        \"expansion_sub_type\": \"keyword_focused\",\n",
    "        \"template_key\": \"query_refinement_keyword_focused\",\n",
    "        \"temperature\": 0.4\n",
    "    },\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # Term Expansion\n",
    "    # Medium temperature for balanced expansion\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"term_expansion_abbreviation\": {\n",
    "        \"expansion_type\": \"term_expansion\",\n",
    "        \"expansion_sub_type\": \"abbreviation\",\n",
    "        \"template_key\": \"term_expansion_abbreviation\",\n",
    "        \"temperature\": 0.3\n",
    "    },\n",
    "    \n",
    "    \"term_expansion_synonym\": {\n",
    "        \"expansion_type\": \"term_expansion\",\n",
    "        \"expansion_sub_type\": \"synonym\",\n",
    "        \"template_key\": \"term_expansion_synonym\",\n",
    "        \"temperature\": 0.5\n",
    "    },\n",
    "    \n",
    "    \"term_expansion_context_addition\": {\n",
    "        \"expansion_type\": \"term_expansion\",\n",
    "        \"expansion_sub_type\": \"context_addition\",\n",
    "        \"template_key\": \"term_expansion_context_addition\",\n",
    "        \"temperature\": 0.4\n",
    "    },\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # Chain-of-Thought\n",
    "    # Medium temperature for thoughtful elaboration\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"chain_of_thought_step_by_step\": {\n",
    "        \"expansion_type\": \"chain_of_thought\",\n",
    "        \"expansion_sub_type\": \"step_by_step\",\n",
    "        \"template_key\": \"chain_of_thought_step_by_step\",\n",
    "        \"temperature\": 0.5\n",
    "    },\n",
    "    \n",
    "    \"chain_of_thought_explicit_context\": {\n",
    "        \"expansion_type\": \"chain_of_thought\",\n",
    "        \"expansion_sub_type\": \"explicit_context\",\n",
    "        \"template_key\": \"chain_of_thought_explicit_context\",\n",
    "        \"temperature\": 0.4\n",
    "    },\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # Domain Adaptation\n",
    "    # Lower temperature for consistent domain-specific language\n",
    "    # ------------------------------------------------------------------------\n",
    "    \"domain_adaptation_accounting_perspective\": {\n",
    "        \"expansion_type\": \"domain_adaptation\",\n",
    "        \"expansion_sub_type\": \"accounting_perspective\",\n",
    "        \"template_key\": \"domain_adaptation_accounting_perspective\",\n",
    "        \"temperature\": 0.4\n",
    "    },\n",
    "    \n",
    "    \"domain_adaptation_10k_language\": {\n",
    "        \"expansion_type\": \"domain_adaptation\",\n",
    "        \"expansion_sub_type\": \"10k_language\",\n",
    "        \"template_key\": \"domain_adaptation_10k_language\",\n",
    "        \"temperature\": 0.4\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"✓ Defined {len(ALL_EXPANSION_CONFIGS)} expansion configurations\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.2 Validate Configuration Consistency\n",
    "\n",
    "# %%\n",
    "# Validate that all template_keys exist in PROMPT_TEMPLATES\n",
    "validation_errors = []\n",
    "\n",
    "for config_name, config in ALL_EXPANSION_CONFIGS.items():\n",
    "    template_key = config[\"template_key\"]\n",
    "    if template_key not in PROMPT_TEMPLATES:\n",
    "        validation_errors.append(f\"Config '{config_name}' references missing template '{template_key}'\")\n",
    "\n",
    "if validation_errors:\n",
    "    print(\"❌ Configuration validation errors:\")\n",
    "    for error in validation_errors:\n",
    "        print(f\"  - {error}\")\n",
    "    raise ValueError(\"Configuration validation failed. Fix the errors above.\")\n",
    "else:\n",
    "    print(\"✓ All configurations reference valid templates\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.3 Select Configurations to Run\n",
    "# \n",
    "# **IMPORTANT: This is where you control which expansions to execute.**\n",
    "# \n",
    "# Comment out any expansion methods you don't want to run.\n",
    "# The system will also skip any configs that already have output files.\n",
    "\n",
    "# %%\n",
    "# ============================================================================\n",
    "# CONFIGURATION SELECTION\n",
    "# ============================================================================\n",
    "# \n",
    "# Uncomment the expansion methods you want to run.\n",
    "# The system will automatically skip configs whose output files already exist.\n",
    "# ============================================================================\n",
    "\n",
    "CONFIGS_TO_RUN = [\n",
    "    # HyDE expansions\n",
    "    \"hyde_basic\",\n",
    "    \"hyde_detailed\",\n",
    "    \"hyde_financial_terminology\",\n",
    "    \n",
    "    # Query refinement\n",
    "    \"query_refinement_clarification\",\n",
    "    \"query_refinement_formal\",\n",
    "    \"query_refinement_keyword_focused\",\n",
    "    \n",
    "    # Term expansion\n",
    "    \"term_expansion_abbreviation\",\n",
    "    \"term_expansion_synonym\",\n",
    "    \"term_expansion_context_addition\",\n",
    "    \n",
    "    # Chain-of-thought\n",
    "    \"chain_of_thought_step_by_step\",\n",
    "    \"chain_of_thought_explicit_context\",\n",
    "    \n",
    "    # Domain adaptation\n",
    "    \"domain_adaptation_accounting_perspective\",\n",
    "    \"domain_adaptation_10k_language\",\n",
    "]\n",
    "\n",
    "print(f\"✓ Selected {len(CONFIGS_TO_RUN)} configurations to run\")\n",
    "print(\"\\nSelected configurations:\")\n",
    "for config_name in CONFIGS_TO_RUN:\n",
    "    config = ALL_EXPANSION_CONFIGS[config_name]\n",
    "    print(f\"  - {config_name} (temp={config['temperature']})\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.4 Verify Selected Configurations\n",
    "\n",
    "# %%\n",
    "# Check that all selected configs exist\n",
    "invalid_configs = [c for c in CONFIGS_TO_RUN if c not in ALL_EXPANSION_CONFIGS]\n",
    "\n",
    "if invalid_configs:\n",
    "    print(\"❌ Invalid configuration names in CONFIGS_TO_RUN:\")\n",
    "    for config in invalid_configs:\n",
    "        print(f\"  - {config}\")\n",
    "    raise ValueError(\"Some selected configurations don't exist. Check CONFIGS_TO_RUN.\")\n",
    "else:\n",
    "    print(\"✓ All selected configurations are valid\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.5 Check for Existing Output Files\n",
    "\n",
    "# %%\n",
    "# Check which configs already have output files\n",
    "configs_with_existing_files = []\n",
    "configs_to_process = []\n",
    "\n",
    "for config_name in CONFIGS_TO_RUN:\n",
    "    config = ALL_EXPANSION_CONFIGS[config_name]\n",
    "    exp_type = config[\"expansion_type\"]\n",
    "    exp_subtype = config[\"expansion_sub_type\"]\n",
    "    \n",
    "    output_filename = f\"expanded_queries_{exp_type}_{exp_subtype}.json\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        configs_with_existing_files.append(config_name)\n",
    "    else:\n",
    "        configs_to_process.append(config_name)\n",
    "\n",
    "# Display status\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OUTPUT FILE STATUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if configs_with_existing_files:\n",
    "    print(f\"\\n✓ Files already exist (will skip): {len(configs_with_existing_files)}\")\n",
    "    for config_name in configs_with_existing_files:\n",
    "        config = ALL_EXPANSION_CONFIGS[config_name]\n",
    "        filename = f\"expanded_queries_{config['expansion_type']}_{config['expansion_sub_type']}.json\"\n",
    "        print(f\"  - {filename}\")\n",
    "\n",
    "if configs_to_process:\n",
    "    print(f\"\\n⚙️  Configs to process: {len(configs_to_process)}\")\n",
    "    for config_name in configs_to_process:\n",
    "        config = ALL_EXPANSION_CONFIGS[config_name]\n",
    "        filename = f\"expanded_queries_{config['expansion_type']}_{config['expansion_sub_type']}.json\"\n",
    "        print(f\"  - {filename}\")\n",
    "else:\n",
    "    print(\"\\n✓ All selected configurations already have output files\")\n",
    "    print(\"  No processing needed (unless you delete existing files)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.6 Configuration Summary\n",
    "\n",
    "# %%\n",
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Count by expansion type\n",
    "type_counts = defaultdict(int)\n",
    "for config_name in CONFIGS_TO_RUN:\n",
    "    config = ALL_EXPANSION_CONFIGS[config_name]\n",
    "    type_counts[config[\"expansion_type\"]] += 1\n",
    "\n",
    "print(\"\\nConfigurations by type:\")\n",
    "for exp_type, count in sorted(type_counts.items()):\n",
    "    print(f\"  {exp_type}: {count}\")\n",
    "\n",
    "print(f\"\\nTotal configurations:\")\n",
    "print(f\"  Selected to run: {len(CONFIGS_TO_RUN)}\")\n",
    "print(f\"  Already complete: {len(configs_with_existing_files)}\")\n",
    "print(f\"  Need processing: {len(configs_to_process)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 3 COMPLETE - Configuration Structure Ready\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext: Proceed to Step 4: Core Functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0587c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ get_llm_client() defined\n",
      "✓ validate_expansion() defined\n",
      "✓ expand_single_query() defined\n",
      "✓ save_expansion_results() defined\n",
      "✓ load_expansion_results() defined\n",
      "\n",
      "✓ LLM client test passed: ollama/llama3:8b\n",
      "\n",
      "============================================================\n",
      "VALIDATION TESTS\n",
      "============================================================\n",
      "✓ Valid expansion: Valid\n",
      "✓ Empty expansion: Expanded query is empty\n",
      "✓ Too short: Expanded query too short (3 chars, minimum 10)\n",
      "✓ Identical to original: Expanded query is identical to original\n",
      "✓ Too long: Expanded query too long (1700 chars, maximum 1500)\n",
      "\n",
      "============================================================\n",
      "✓ STEP 4 COMPLETE - Core Functions Ready\n",
      "============================================================\n",
      "\n",
      "Implemented functions:\n",
      "  ✓ get_llm_client() - Initialize LLM with provider/model\n",
      "  ✓ validate_expansion() - Check expansion quality\n",
      "  ✓ expand_single_query() - Expand with retry logic\n",
      "  ✓ save_expansion_results() - Save to JSON with metadata\n",
      "  ✓ load_expansion_results() - Load and validate JSON\n",
      "\n",
      "Next: Proceed to Step 5: Dataset Loading\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 4: Core Functions\n",
    "# ============================================================================\n",
    "# \n",
    "# This section implements the core functions for query expansion:\n",
    "# 1. LLM client initialization (OpenAI/Ollama)\n",
    "# 2. Query expansion with retry logic and delays\n",
    "# 3. Response validation\n",
    "# 4. JSON file operations\n",
    "#\n",
    "# Key features:\n",
    "# - Automatic retry on failures (with 30s wait)\n",
    "# - Rate limiting (1s delay between calls)\n",
    "# - Validation (non-empty, differs from original, length checks)\n",
    "# - Clean error handling\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.1 LLM Client Initialization\n",
    "\n",
    "# %%\n",
    "def get_llm_client(provider: str, model: str, temperature: float):\n",
    "    \"\"\"\n",
    "    Initialize and return appropriate LLM client based on provider.\n",
    "    \n",
    "    Args:\n",
    "        provider: \"openai\" or \"ollama\"\n",
    "        model: Model name/identifier\n",
    "        temperature: Sampling temperature (0.0 = deterministic, 1.0 = creative)\n",
    "        \n",
    "    Returns:\n",
    "        LangChain LLM client (ChatOpenAI or ChatOllama)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If provider is not supported\n",
    "    \"\"\"\n",
    "    if provider == \"openai\":\n",
    "        return ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "    elif provider == \"ollama\":\n",
    "        return ChatOllama(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            base_url=OLLAMA_BASE_URL\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported LLM provider: {provider}. Use 'openai' or 'ollama'.\")\n",
    "\n",
    "print(\"✓ get_llm_client() defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.2 Response Validation\n",
    "\n",
    "# %%\n",
    "def validate_expansion(\n",
    "    original_query: str,\n",
    "    expanded_query: str,\n",
    "    config: Dict = None\n",
    ") -> tuple[bool, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Validate that the expanded query meets quality criteria.\n",
    "    \n",
    "    Args:\n",
    "        original_query: The original question from FinanceBench\n",
    "        expanded_query: The LLM-generated expanded version\n",
    "        config: Validation configuration (uses VALIDATION_CONFIG if None)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (is_valid, error_message)\n",
    "        - (True, None) if valid\n",
    "        - (False, error_message) if invalid\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = VALIDATION_CONFIG\n",
    "    \n",
    "    # Check 1: Non-empty\n",
    "    if not expanded_query or not expanded_query.strip():\n",
    "        return False, \"Expanded query is empty\"\n",
    "    \n",
    "    expanded_query = expanded_query.strip()\n",
    "    \n",
    "    # Check 2: Minimum length\n",
    "    if len(expanded_query) < config[\"min_length\"]:\n",
    "        return False, f\"Expanded query too short ({len(expanded_query)} chars, minimum {config['min_length']})\"\n",
    "    \n",
    "    # Check 3: Maximum length\n",
    "    if len(expanded_query) > config[\"max_length\"]:\n",
    "        return False, f\"Expanded query too long ({len(expanded_query)} chars, maximum {config['max_length']})\"\n",
    "    \n",
    "    # Check 4: Must differ from original\n",
    "    if config[\"must_differ_from_original\"]:\n",
    "        # Exact match check (case-insensitive)\n",
    "        if expanded_query.lower() == original_query.lower():\n",
    "            return False, \"Expanded query is identical to original\"\n",
    "        \n",
    "        # Simple token-based similarity check\n",
    "        # Split into words and compare\n",
    "        original_tokens = set(original_query.lower().split())\n",
    "        expanded_tokens = set(expanded_query.lower().split())\n",
    "        \n",
    "        # Calculate Jaccard similarity (intersection / union)\n",
    "        if len(expanded_tokens) > 0:\n",
    "            intersection = len(original_tokens & expanded_tokens)\n",
    "            union = len(original_tokens | expanded_tokens)\n",
    "            jaccard_similarity = intersection / union if union > 0 else 0\n",
    "            \n",
    "            # Only reject if extremely similar (almost no new words added)\n",
    "            if jaccard_similarity > config[\"similarity_threshold\"]:\n",
    "                return False, f\"Expanded query too similar to original (similarity: {jaccard_similarity:.2f})\"\n",
    "    \n",
    "    # All checks passed\n",
    "    return True, None\n",
    "\n",
    "print(\"✓ validate_expansion() defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.3 Single Query Expansion with Retry Logic\n",
    "\n",
    "# %%\n",
    "def expand_single_query(\n",
    "    chain: LLMChain,\n",
    "    query: str,\n",
    "    original_query: str,\n",
    "    max_retries: int = MAX_RETRIES,\n",
    "    retry_delay: int = RETRY_DELAY,\n",
    "    call_delay: int = CALL_DELAY\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Expand a single query using the LLM chain with retry logic.\n",
    "    \n",
    "    Args:\n",
    "        chain: LangChain LLMChain (prompt + LLM)\n",
    "        query: The query to expand\n",
    "        original_query: Original query for validation\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        retry_delay: Seconds to wait before retry after failure\n",
    "        call_delay: Seconds to wait after successful call (rate limiting)\n",
    "        \n",
    "    Returns:\n",
    "        Expanded query string\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If all retries exhausted or validation fails\n",
    "    \"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Call LLM\n",
    "            response = chain.run(query=query)\n",
    "            expanded = response.strip()\n",
    "            \n",
    "            # Validate response\n",
    "            is_valid, error_msg = validate_expansion(original_query, expanded)\n",
    "            \n",
    "            if not is_valid:\n",
    "                raise ValueError(f\"Validation failed: {error_msg}\")\n",
    "            \n",
    "            # Success - add delay for rate limiting\n",
    "            time.sleep(call_delay)\n",
    "            \n",
    "            return expanded\n",
    "            \n",
    "        except Exception as e:\n",
    "            last_error = e\n",
    "            \n",
    "            if attempt < max_retries - 1:  # Not the last attempt\n",
    "                print(f\"    ⚠️  Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                print(f\"    ⏳ Waiting {retry_delay}s before retry...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:  # Last attempt failed\n",
    "                print(f\"    ❌ All {max_retries} attempts failed\")\n",
    "    \n",
    "    # All retries exhausted\n",
    "    raise Exception(f\"Failed to expand query after {max_retries} attempts. Last error: {str(last_error)}\")\n",
    "\n",
    "print(\"✓ expand_single_query() defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.4 Save Results to JSON\n",
    "\n",
    "# %%\n",
    "def save_expansion_results(\n",
    "    results: List[Dict],\n",
    "    expansion_type: str,\n",
    "    expansion_sub_type: str,\n",
    "    template: str,\n",
    "    llm_provider: str,\n",
    "    llm_model: str,\n",
    "    temperature: float,\n",
    "    output_dir: str = OUTPUT_DIR\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Save expanded queries to JSON file with metadata.\n",
    "    \n",
    "    Args:\n",
    "        results: List of query dictionaries with expansion results\n",
    "        expansion_type: High-level expansion category\n",
    "        expansion_sub_type: Specific variant within the type\n",
    "        template: The prompt template used\n",
    "        llm_provider: \"openai\" or \"ollama\"\n",
    "        llm_model: Model identifier\n",
    "        temperature: Temperature used for generation\n",
    "        output_dir: Directory to save JSON file\n",
    "        \n",
    "    Returns:\n",
    "        Path to saved JSON file\n",
    "    \"\"\"\n",
    "    # Prepare metadata\n",
    "    metadata = {\n",
    "        \"expansion_type\": expansion_type,\n",
    "        \"expansion_sub_type\": expansion_sub_type,\n",
    "        \"llm_provider\": llm_provider,\n",
    "        \"llm_model\": llm_model,\n",
    "        \"template\": template,\n",
    "        \"temperature\": temperature,\n",
    "        \"creation_date\": datetime.now().isoformat(),\n",
    "        \"total_queries\": len(results)\n",
    "    }\n",
    "    \n",
    "    # Prepare output structure\n",
    "    output_data = {\n",
    "        \"metadata\": metadata,\n",
    "        \"queries\": results\n",
    "    }\n",
    "    \n",
    "    # Generate filename\n",
    "    filename = f\"expanded_queries_{expansion_type}_{expansion_sub_type}.json\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "print(\"✓ save_expansion_results() defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.5 Load and Validate JSON\n",
    "\n",
    "# %%\n",
    "def load_expansion_results(filepath: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load and validate expansion results from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to JSON file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metadata and queries\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If file doesn't exist\n",
    "        json.JSONDecodeError: If file is not valid JSON\n",
    "        ValueError: If JSON structure is invalid\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Validate structure\n",
    "    if \"metadata\" not in data or \"queries\" not in data:\n",
    "        raise ValueError(\"Invalid JSON structure: missing 'metadata' or 'queries'\")\n",
    "    \n",
    "    required_metadata = [\"expansion_type\", \"expansion_sub_type\", \"llm_provider\", \n",
    "                         \"llm_model\", \"template\", \"temperature\", \"total_queries\"]\n",
    "    \n",
    "    for field in required_metadata:\n",
    "        if field not in data[\"metadata\"]:\n",
    "            raise ValueError(f\"Invalid JSON structure: missing metadata field '{field}'\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"✓ load_expansion_results() defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.6 Test Core Functions (Optional)\n",
    "\n",
    "# %%\n",
    "# Test LLM client initialization\n",
    "try:\n",
    "    test_llm = get_llm_client(LLM_PROVIDER, LLM_MODEL, 0.7)\n",
    "    print(f\"\\n✓ LLM client test passed: {LLM_PROVIDER}/{LLM_MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ LLM client test failed: {e}\")\n",
    "\n",
    "# Test validation function\n",
    "test_cases = [\n",
    "    (\"What is revenue?\", \"What is the total revenue?\", True, \"Valid expansion\"),\n",
    "    (\"What is revenue?\", \"\", False, \"Empty expansion\"),\n",
    "    (\"What is revenue?\", \"Rev\", False, \"Too short\"),\n",
    "    (\"What is revenue?\", \"What is revenue?\", False, \"Identical to original\"),\n",
    "    (\"What is revenue?\", \"X\" * 1700, False, \"Too long\"),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION TESTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for original, expanded, expected_valid, description in test_cases:\n",
    "    is_valid, error_msg = validate_expansion(original, expanded)\n",
    "    status = \"✓\" if is_valid == expected_valid else \"❌\"\n",
    "    print(f\"{status} {description}: {'Valid' if is_valid else error_msg}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 4 COMPLETE - Core Functions Ready\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nImplemented functions:\")\n",
    "print(\"  ✓ get_llm_client() - Initialize LLM with provider/model\")\n",
    "print(\"  ✓ validate_expansion() - Check expansion quality\")\n",
    "print(\"  ✓ expand_single_query() - Expand with retry logic\")\n",
    "print(\"  ✓ save_expansion_results() - Save to JSON with metadata\")\n",
    "print(\"  ✓ load_expansion_results() - Load and validate JSON\")\n",
    "print(\"\\nNext: Proceed to Step 5: Dataset Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c9fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FinanceBench dataset...\n",
      "  Dataset: PatronusAI/financebench\n",
      "  Split: train\n",
      "✓ Loaded 150 queries from FinanceBench\n",
      "\n",
      "============================================================\n",
      "SAMPLE DATASET ENTRY\n",
      "============================================================\n",
      "\n",
      "Available fields:\n",
      "  financebench_id: financebench_id_03029\n",
      "  company: 3M\n",
      "  doc_name: 3M_2018_10K\n",
      "  question_type: metrics-generated\n",
      "  question_reasoning: Information extraction\n",
      "  domain_question_num: None\n",
      "  question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "  answer: $1577.00\n",
      "  justification: The metric capital expenditures was directly extracted from the company 10K. The line item name, as ...\n",
      "  dataset_subset_label: OPEN_SOURCE\n",
      "  evidence: [{'evidence_text': 'Table of Contents \\n3M Company and Subsidiaries\\nConsolidated Statement of Cash Flow s\\nYears ended December 31\\n \\n(Millions)\\n \\n2018\\n \\n2017\\n \\n2016\\n \\nCash Flows from Operating Activities\\n \\n \\n \\n \\n \\n \\n \\nNet income including noncontrolling interest\\n \\n$\\n5,363 \\n$\\n4,869 \\n$\\n5,058 \\nAdjustments to reconcile net income including noncontrolling interest to net cash\\nprovided by operating activities\\n \\n \\n \\n \\n \\n \\n \\nDepreciation and amortization\\n \\n \\n1,488 \\n \\n1,544 \\n \\n1,474 \\nCompany pension and postretirement contributions\\n \\n \\n(370) \\n \\n(967) \\n \\n(383) \\nCompany pension and postretirement expense\\n \\n \\n410 \\n \\n334 \\n \\n250 \\nStock-based compensation expense\\n \\n \\n302 \\n \\n324 \\n \\n298 \\nGain on sale of businesses\\n \\n \\n(545) \\n \\n(586) \\n \\n(111) \\nDeferred income taxes\\n \\n \\n(57) \\n \\n107 \\n \\n 7 \\nChanges in assets and liabilities\\n \\n \\n \\n \\n \\n \\n \\nAccounts receivable\\n \\n \\n(305) \\n \\n(245) \\n \\n(313) \\nInventories\\n \\n \\n(509) \\n \\n(387) \\n \\n57 \\nAccounts payable\\n \\n \\n408 \\n \\n24 \\n \\n148 \\nAccrued income taxes (current and long-term)\\n \\n \\n134 \\n \\n967 \\n \\n101 \\nOther net\\n \\n \\n120 \\n \\n256 \\n \\n76 \\nNet cash provided by (used in) operating activities\\n \\n \\n6,439 \\n \\n6,240 \\n \\n6,662 \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Investing Activities\\n \\n \\n \\n \\n \\n \\n \\nPurchases of property, plant and equipment (PP&E)\\n \\n \\n(1,577) \\n \\n(1,373) \\n \\n(1,420) \\nProceeds from sale of PP&E and other assets\\n \\n \\n262 \\n \\n49 \\n \\n58 \\nAcquisitions, net of cash acquired\\n \\n \\n13 \\n \\n(2,023) \\n \\n(16) \\nPurchases of marketable securities and investments\\n \\n \\n(1,828) \\n \\n(2,152) \\n \\n(1,410) \\nProceeds from maturities and sale of marketable securities and investments\\n \\n \\n2,497 \\n \\n1,354 \\n \\n1,247 \\nProceeds from sale of businesses, net of cash sold\\n \\n \\n846 \\n \\n1,065 \\n \\n142 \\nOther net\\n \\n \\n 9 \\n \\n(6) \\n \\n(4) \\nNet cash provided by (used in) investing activities\\n \\n \\n222 \\n \\n(3,086) \\n \\n(1,403) \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Financing Activities\\n \\n \\n \\n \\n \\n \\n \\nChange in short-term debt net\\n \\n \\n(284) \\n \\n578 \\n \\n(797) \\nRepayment of debt (maturities greater than 90 days)\\n \\n \\n(1,034) \\n \\n(962) \\n \\n(992) \\nProceeds from debt (maturities greater than 90 days)\\n \\n \\n2,251 \\n \\n1,987 \\n \\n2,832 \\nPurchases of treasury stock\\n \\n \\n(4,870) \\n \\n(2,068) \\n \\n(3,753) \\nProceeds from issuance of treasury stock pursuant to stock option and benefit plans\\n \\n \\n485 \\n \\n734 \\n \\n804 \\nDividends paid to shareholders\\n \\n \\n(3,193) \\n \\n(2,803) \\n \\n(2,678) \\nOther net\\n \\n \\n(56) \\n \\n(121) \\n \\n(42) \\nNet cash provided by (used in) financing activities\\n \\n \\n(6,701) \\n \\n(2,655) \\n \\n(4,626) \\n \\n \\n \\n \\n \\n \\n \\n \\nEffect of exchange rate changes on cash and cash equivalents\\n \\n \\n(160) \\n \\n156 \\n \\n(33) \\n \\n \\n \\n \\n \\n \\n \\n \\nNet increase (decrease) in cash and cash equivalents\\n \\n \\n(200) \\n \\n655 \\n \\n600 \\nCash and cash equivalents at beginning of year\\n \\n \\n3,053 \\n \\n2,398 \\n \\n1,798 \\nCash and cash equivalents at end of period\\n \\n$\\n2,853 \\n$\\n3,053 \\n$\\n2,398 \\n \\nThe accompanying Notes to Consolidated Financial Statements are an integral part of this statement.\\n \\n60', 'doc_name': '3M_2018_10K', 'evidence_page_num': 59, 'evidence_text_full_page': 'Table of Contents \\n3M Company and Subsidiaries\\nConsolidated Statement of Cash Flow s\\nYears ended December 31\\n \\n(Millions)\\n \\n2018\\n \\n2017\\n \\n2016\\n \\nCash Flows from Operating Activities\\n \\n \\n \\n \\n \\n \\n \\nNet income including noncontrolling interest\\n \\n$\\n5,363 \\n$\\n4,869 \\n$\\n5,058 \\nAdjustments to reconcile net income including noncontrolling interest to net cash\\nprovided by operating activities\\n \\n \\n \\n \\n \\n \\n \\nDepreciation and amortization\\n \\n \\n1,488 \\n \\n1,544 \\n \\n1,474 \\nCompany pension and postretirement contributions\\n \\n \\n(370) \\n \\n(967) \\n \\n(383) \\nCompany pension and postretirement expense\\n \\n \\n410 \\n \\n334 \\n \\n250 \\nStock-based compensation expense\\n \\n \\n302 \\n \\n324 \\n \\n298 \\nGain on sale of businesses\\n \\n \\n(545) \\n \\n(586) \\n \\n(111) \\nDeferred income taxes\\n \\n \\n(57) \\n \\n107 \\n \\n 7 \\nChanges in assets and liabilities\\n \\n \\n \\n \\n \\n \\n \\nAccounts receivable\\n \\n \\n(305) \\n \\n(245) \\n \\n(313) \\nInventories\\n \\n \\n(509) \\n \\n(387) \\n \\n57 \\nAccounts payable\\n \\n \\n408 \\n \\n24 \\n \\n148 \\nAccrued income taxes (current and long-term)\\n \\n \\n134 \\n \\n967 \\n \\n101 \\nOther net\\n \\n \\n120 \\n \\n256 \\n \\n76 \\nNet cash provided by (used in) operating activities\\n \\n \\n6,439 \\n \\n6,240 \\n \\n6,662 \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Investing Activities\\n \\n \\n \\n \\n \\n \\n \\nPurchases of property, plant and equipment (PP&E)\\n \\n \\n(1,577) \\n \\n(1,373) \\n \\n(1,420) \\nProceeds from sale of PP&E and other assets\\n \\n \\n262 \\n \\n49 \\n \\n58 \\nAcquisitions, net of cash acquired\\n \\n \\n13 \\n \\n(2,023) \\n \\n(16) \\nPurchases of marketable securities and investments\\n \\n \\n(1,828) \\n \\n(2,152) \\n \\n(1,410) \\nProceeds from maturities and sale of marketable securities and investments\\n \\n \\n2,497 \\n \\n1,354 \\n \\n1,247 \\nProceeds from sale of businesses, net of cash sold\\n \\n \\n846 \\n \\n1,065 \\n \\n142 \\nOther net\\n \\n \\n 9 \\n \\n(6) \\n \\n(4) \\nNet cash provided by (used in) investing activities\\n \\n \\n222 \\n \\n(3,086) \\n \\n(1,403) \\n \\n \\n \\n \\n \\n \\n \\n \\nCash Flows from Financing Activities\\n \\n \\n \\n \\n \\n \\n \\nChange in short-term debt net\\n \\n \\n(284) \\n \\n578 \\n \\n(797) \\nRepayment of debt (maturities greater than 90 days)\\n \\n \\n(1,034) \\n \\n(962) \\n \\n(992) \\nProceeds from debt (maturities greater than 90 days)\\n \\n \\n2,251 \\n \\n1,987 \\n \\n2,832 \\nPurchases of treasury stock\\n \\n \\n(4,870) \\n \\n(2,068) \\n \\n(3,753) \\nProceeds from issuance of treasury stock pursuant to stock option and benefit plans\\n \\n \\n485 \\n \\n734 \\n \\n804 \\nDividends paid to shareholders\\n \\n \\n(3,193) \\n \\n(2,803) \\n \\n(2,678) \\nOther net\\n \\n \\n(56) \\n \\n(121) \\n \\n(42) \\nNet cash provided by (used in) financing activities\\n \\n \\n(6,701) \\n \\n(2,655) \\n \\n(4,626) \\n \\n \\n \\n \\n \\n \\n \\n \\nEffect of exchange rate changes on cash and cash equivalents\\n \\n \\n(160) \\n \\n156 \\n \\n(33) \\n \\n \\n \\n \\n \\n \\n \\n \\nNet increase (decrease) in cash and cash equivalents\\n \\n \\n(200) \\n \\n655 \\n \\n600 \\nCash and cash equivalents at beginning of year\\n \\n \\n3,053 \\n \\n2,398 \\n \\n1,798 \\nCash and cash equivalents at end of period\\n \\n$\\n2,853 \\n$\\n3,053 \\n$\\n2,398 \\n \\nThe accompanying Notes to Consolidated Financial Statements are an integral part of this statement.\\n \\n60\\n \\n'}]\n",
      "  gics_sector: Industrials\n",
      "  doc_type: 10k\n",
      "  doc_period: 2018\n",
      "  doc_link: https://investors.3m.com/financials/sec-filings/content/0001558370-19-000470/0001558370-19-000470.pd...\n",
      "✓ Extracted data from 150 queries\n",
      "\n",
      "============================================================\n",
      "DATA VALIDATION\n",
      "============================================================\n",
      "✓ All 150 IDs are unique\n",
      "✓ No empty queries\n",
      "✓ All queries have doc_name\n",
      "\n",
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "\n",
      "Query lengths (characters):\n",
      "  Min: 44\n",
      "  Max: 592\n",
      "  Mean: 161.1\n",
      "  Median: 139\n",
      "\n",
      "Document type distribution:\n",
      "  10-K: 112 (74.7%)\n",
      "  10-Q: 15 (10.0%)\n",
      "  Earnings Call: 14 (9.3%)\n",
      "  Other: 9 (6.0%)\n",
      "\n",
      "Top 10 companies:\n",
      "  PEPSICO: 11 queries\n",
      "  AMCOR: 9 queries\n",
      "  JOHNSON: 9 queries\n",
      "  3M: 8 queries\n",
      "  AMD: 8 queries\n",
      "  BESTBUY: 8 queries\n",
      "  BOEING: 8 queries\n",
      "  AMERICANEXPRESS: 7 queries\n",
      "  MGMRESORTS: 7 queries\n",
      "  ULTABEAUTY: 6 queries\n",
      "\n",
      "============================================================\n",
      "SAMPLE QUERIES\n",
      "============================================================\n",
      "\n",
      "[Sample 1]\n",
      "  ID: financebench_id_01928\n",
      "  Doc: AMCOR_2023Q4_EARNINGS\n",
      "  Query: What Was AMCOR's Adjusted Non GAAP EBITDA for FY 2023\n",
      "\n",
      "[Sample 2]\n",
      "  ID: financebench_id_00941\n",
      "  Doc: 3M_2023Q2_10Q\n",
      "  Query: Which debt securities are registered to trade on a national securities exchange under 3M's name as of Q2 of 2023?\n",
      "\n",
      "[Sample 3]\n",
      "  ID: financebench_id_10130\n",
      "  Doc: CORNING_2020_10K\n",
      "  Query: Based on the information provided primarily in the balance sheet and the statement of income, what is FY2020 days payable outstanding (DPO) for Corning? DPO is defined as: 365 * (average accounts payable between FY2019 and FY2020) / (FY2020 COGS + change in inventory between FY2019 and FY2020). Round your answer to two decimal places.\n",
      "\n",
      "[Sample 4]\n",
      "  ID: financebench_id_00678\n",
      "  Doc: BOEING_2022_10K\n",
      "  Query: Does Boeing have an improving gross margin profile as of FY2022? If gross margin is not a useful metric for a company like this, then state that and explain why.\n",
      "\n",
      "[Sample 5]\n",
      "  ID: financebench_id_03838\n",
      "  Doc: BLOCK_2020_10K\n",
      "  Query: What is the FY2019 - FY2020 total revenue growth rate for Block (formerly known as Square)? Answer in units of percents and round to one decimal place. Approach the question asked by assuming the standpoint of an investment banking analyst who only has access to the statement of income.\n",
      "\n",
      "============================================================\n",
      "✓ STEP 5 COMPLETE - Dataset Ready\n",
      "============================================================\n",
      "\n",
      "Dataset summary:\n",
      "  Total queries: 150\n",
      "  Stored in variable: FINANCEBENCH_QUERIES\n",
      "  Ready for expansion processing\n",
      "\n",
      "Each query contains:\n",
      "  ✓ financebench_id\n",
      "  ✓ original_query\n",
      "  ✓ doc_name\n",
      "\n",
      "Next: Proceed to Step 6: Processing Function\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 5: Dataset Loading\n",
    "# ============================================================================\n",
    "# \n",
    "# This section loads the FinanceBench dataset from HuggingFace and prepares\n",
    "# it for query expansion processing.\n",
    "#\n",
    "# FinanceBench contains 150 expert-crafted financial questions with:\n",
    "# - Question text\n",
    "# - Expected document (10-K, 10-Q, earnings calls, etc.)\n",
    "# - Evidence page numbers\n",
    "# - Gold standard answers\n",
    "# - Company information\n",
    "#\n",
    "# We extract the necessary fields for our expansion task:\n",
    "# - financebench_id: Unique identifier\n",
    "# - question: Original query text\n",
    "# - doc_name: Source document name (for metadata)\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.1 Load FinanceBench Dataset\n",
    "\n",
    "# %%\n",
    "print(\"Loading FinanceBench dataset...\")\n",
    "print(f\"  Dataset: {DATASET_NAME}\")\n",
    "print(f\"  Split: {DATASET_SPLIT}\")\n",
    "\n",
    "# Load dataset from HuggingFace\n",
    "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT)\n",
    "\n",
    "print(f\"✓ Loaded {len(dataset)} queries from FinanceBench\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.2 Inspect Dataset Structure\n",
    "\n",
    "# %%\n",
    "# Display sample entry to understand structure\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE DATASET ENTRY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample = dataset[0]\n",
    "print(\"\\nAvailable fields:\")\n",
    "for key in sample.keys():\n",
    "    value = sample[key]\n",
    "    # Truncate long values for display\n",
    "    if isinstance(value, str) and len(value) > 100:\n",
    "        display_value = value[:100] + \"...\"\n",
    "    else:\n",
    "        display_value = value\n",
    "    print(f\"  {key}: {display_value}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.3 Extract Required Fields\n",
    "\n",
    "# %%\n",
    "def extract_query_data(dataset_entry: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract required fields from a FinanceBench dataset entry.\n",
    "    \n",
    "    Args:\n",
    "        dataset_entry: Single entry from FinanceBench dataset\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extracted fields:\n",
    "        - financebench_id: Unique identifier\n",
    "        - original_query: The question text\n",
    "        - doc_name: Source document name\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"financebench_id\": dataset_entry[\"financebench_id\"],\n",
    "        \"original_query\": dataset_entry[\"question\"],\n",
    "        \"doc_name\": dataset_entry[\"doc_name\"]\n",
    "    }\n",
    "\n",
    "# Process all dataset entries\n",
    "financebench_queries = []\n",
    "\n",
    "for entry in dataset:\n",
    "    query_data = extract_query_data(entry)\n",
    "    financebench_queries.append(query_data)\n",
    "\n",
    "print(f\"✓ Extracted data from {len(financebench_queries)} queries\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.4 Validate Extracted Data\n",
    "\n",
    "# %%\n",
    "# Validation checks\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for duplicates\n",
    "ids = [q[\"financebench_id\"] for q in financebench_queries]\n",
    "if len(ids) != len(set(ids)):\n",
    "    print(\"⚠️  Warning: Duplicate IDs found in dataset\")\n",
    "else:\n",
    "    print(f\"✓ All {len(ids)} IDs are unique\")\n",
    "\n",
    "# Check for empty queries\n",
    "empty_queries = [q for q in financebench_queries if not q[\"original_query\"].strip()]\n",
    "if empty_queries:\n",
    "    print(f\"⚠️  Warning: {len(empty_queries)} empty queries found\")\n",
    "else:\n",
    "    print(f\"✓ No empty queries\")\n",
    "\n",
    "# Check for missing doc_names\n",
    "missing_docs = [q for q in financebench_queries if not q[\"doc_name\"]]\n",
    "if missing_docs:\n",
    "    print(f\"⚠️  Warning: {len(missing_docs)} queries missing doc_name\")\n",
    "else:\n",
    "    print(f\"✓ All queries have doc_name\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.5 Display Statistics\n",
    "\n",
    "# %%\n",
    "# Calculate statistics\n",
    "from collections import Counter\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Query length statistics\n",
    "query_lengths = [len(q[\"original_query\"]) for q in financebench_queries]\n",
    "print(f\"\\nQuery lengths (characters):\")\n",
    "print(f\"  Min: {min(query_lengths)}\")\n",
    "print(f\"  Max: {max(query_lengths)}\")\n",
    "print(f\"  Mean: {sum(query_lengths) / len(query_lengths):.1f}\")\n",
    "print(f\"  Median: {sorted(query_lengths)[len(query_lengths)//2]}\")\n",
    "\n",
    "# Document type distribution\n",
    "doc_names = [q[\"doc_name\"] for q in financebench_queries]\n",
    "# Extract document type (e.g., \"APPLE_2019_10K\" -> \"10K\")\n",
    "doc_types = []\n",
    "for doc in doc_names:\n",
    "    if \"_10K\" in doc:\n",
    "        doc_types.append(\"10-K\")\n",
    "    elif \"_10Q\" in doc:\n",
    "        doc_types.append(\"10-Q\")\n",
    "    elif \"earnings\" in doc.lower() or \"call\" in doc.lower():\n",
    "        doc_types.append(\"Earnings Call\")\n",
    "    else:\n",
    "        doc_types.append(\"Other\")\n",
    "\n",
    "doc_type_counts = Counter(doc_types)\n",
    "print(f\"\\nDocument type distribution:\")\n",
    "for doc_type, count in sorted(doc_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = (count / len(doc_types)) * 100\n",
    "    print(f\"  {doc_type}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Company distribution (top 10)\n",
    "companies = [doc.split('_')[0] for doc in doc_names]\n",
    "company_counts = Counter(companies)\n",
    "print(f\"\\nTop 10 companies:\")\n",
    "for company, count in company_counts.most_common(10):\n",
    "    print(f\"  {company}: {count} queries\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.6 Sample Queries Display\n",
    "\n",
    "# %%\n",
    "# Display sample queries\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE QUERIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "sample_indices = random.sample(range(len(financebench_queries)), min(5, len(financebench_queries)))\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    query = financebench_queries[idx]\n",
    "    print(f\"\\n[Sample {i}]\")\n",
    "    print(f\"  ID: {query['financebench_id']}\")\n",
    "    print(f\"  Doc: {query['doc_name']}\")\n",
    "    print(f\"  Query: {query['original_query']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.7 Prepare for Processing\n",
    "\n",
    "# %%\n",
    "# Store in global variable for easy access in next steps\n",
    "FINANCEBENCH_QUERIES = financebench_queries\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 5 COMPLETE - Dataset Ready\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"  Total queries: {len(FINANCEBENCH_QUERIES)}\")\n",
    "print(f\"  Stored in variable: FINANCEBENCH_QUERIES\")\n",
    "print(f\"  Ready for expansion processing\")\n",
    "print(\"\\nEach query contains:\")\n",
    "print(\"  ✓ financebench_id\")\n",
    "print(\"  ✓ original_query\")\n",
    "print(\"  ✓ doc_name\")\n",
    "print(\"\\nNext: Proceed to Step 6: Processing Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e818acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ process_expansion_config() defined\n",
      "✓ process_all_configs() defined\n",
      "\n",
      "============================================================\n",
      "✓ STEP 6 COMPLETE - Processing Functions Ready\n",
      "============================================================\n",
      "\n",
      "Implemented functions:\n",
      "  ✓ process_expansion_config() - Process single expansion method\n",
      "  ✓ process_all_configs() - Batch process multiple methods\n",
      "\n",
      "Ready for execution!\n",
      "\n",
      "Next: Proceed to Step 7: Execution\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 6: Processing Function\n",
    "# ============================================================================\n",
    "# \n",
    "# This section implements the main processing function that:\n",
    "# 1. Takes a configuration (expansion type/subtype)\n",
    "# 2. Processes all 150 FinanceBench queries (or dry run sample)\n",
    "# 3. Applies the expansion with retry logic and delays\n",
    "# 4. Saves results to JSON file\n",
    "#\n",
    "# Supports:\n",
    "# - Dry run mode (test on N queries)\n",
    "# - Progress tracking with tqdm\n",
    "# - Automatic file skipping if output exists\n",
    "# - Error handling with immediate failure (as requested)\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.1 Main Processing Function\n",
    "\n",
    "# %%\n",
    "def process_expansion_config(\n",
    "    config_name: str,\n",
    "    config: Dict,\n",
    "    queries: List[Dict],\n",
    "    dry_run: bool = False,\n",
    "    dry_run_size: int = DRY_RUN_SAMPLE_SIZE,\n",
    "    output_dir: str = OUTPUT_DIR\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Process all queries for a single expansion configuration.\n",
    "    \n",
    "    Args:\n",
    "        config_name: Name of the configuration (e.g., \"hyde_basic\")\n",
    "        config: Configuration dictionary with type, subtype, template_key, temperature\n",
    "        queries: List of query dictionaries from FinanceBench\n",
    "        dry_run: If True, only process first N queries for testing\n",
    "        dry_run_size: Number of queries to process in dry run\n",
    "        output_dir: Directory to save output JSON\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with processing statistics\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If any query expansion fails (fails immediately as requested)\n",
    "    \"\"\"\n",
    "    # Extract config details\n",
    "    expansion_type = config[\"expansion_type\"]\n",
    "    expansion_sub_type = config[\"expansion_sub_type\"]\n",
    "    template_key = config[\"template_key\"]\n",
    "    temperature = config[\"temperature\"]\n",
    "    \n",
    "    # Check if output file already exists\n",
    "    output_filename = f\"expanded_queries_{expansion_type}_{expansion_sub_type}.json\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    if os.path.exists(output_path) and not dry_run:\n",
    "        print(f\"⏭️  File already exists: {output_filename}\")\n",
    "        print(f\"   Skipping {config_name}\")\n",
    "        return {\n",
    "            \"status\": \"skipped\",\n",
    "            \"reason\": \"output_file_exists\",\n",
    "            \"output_path\": output_path\n",
    "        }\n",
    "    \n",
    "    # Prepare for processing\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"PROCESSING: {config_name}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Expansion Type: {expansion_type}\")\n",
    "    print(f\"  Expansion Sub-Type: {expansion_sub_type}\")\n",
    "    print(f\"  Template: {template_key}\")\n",
    "    print(f\"  Temperature: {temperature}\")\n",
    "    print(f\"  LLM: {LLM_PROVIDER}/{LLM_MODEL}\")\n",
    "    \n",
    "    if dry_run:\n",
    "        print(f\"  Mode: DRY RUN (processing {dry_run_size} queries)\")\n",
    "        queries_to_process = queries[:dry_run_size]\n",
    "    else:\n",
    "        print(f\"  Mode: FULL RUN (processing {len(queries)} queries)\")\n",
    "        queries_to_process = queries\n",
    "    \n",
    "    # Initialize LLM and chain\n",
    "    print(\"\\n  Initializing LLM...\")\n",
    "    llm = get_llm_client(LLM_PROVIDER, LLM_MODEL, temperature)\n",
    "    prompt_template = PROMPT_TEMPLATES[template_key]\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    print(\"  ✓ LLM chain ready\")\n",
    "    \n",
    "    # Process queries\n",
    "    print(f\"\\n  Processing {len(queries_to_process)} queries...\")\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(queries_to_process, desc=f\"  {config_name}\", unit=\"query\")\n",
    "    \n",
    "    for query_data in pbar:\n",
    "        try:\n",
    "            # Extract query info\n",
    "            financebench_id = query_data[\"financebench_id\"]\n",
    "            original_query = query_data[\"original_query\"]\n",
    "            doc_name = query_data[\"doc_name\"]\n",
    "            \n",
    "            # Expand query\n",
    "            expanded_query = expand_single_query(\n",
    "                chain=chain,\n",
    "                query=original_query,\n",
    "                original_query=original_query\n",
    "            )\n",
    "            \n",
    "            # Store result\n",
    "            result = {\n",
    "                \"financebench_id\": financebench_id,\n",
    "                \"original_query\": original_query,\n",
    "                \"expanded_query\": expanded_query,\n",
    "                \"doc_name\": doc_name\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fail immediately as requested (Option A from earlier discussion)\n",
    "            print(f\"\\n\\n❌ ERROR processing query: {financebench_id}\")\n",
    "            print(f\"   Original query: {original_query}\")\n",
    "            print(f\"   Error: {str(e)}\")\n",
    "            print(f\"\\n⛔ Processing stopped. Fix the issue and re-run.\")\n",
    "            raise e\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    elapsed_time = time.time() - start_time\n",
    "    avg_time_per_query = elapsed_time / len(results) if results else 0\n",
    "    \n",
    "    print(f\"\\n  ✓ Processed {len(results)} queries successfully\")\n",
    "    print(f\"  ⏱️  Total time: {elapsed_time:.1f}s\")\n",
    "    print(f\"  ⏱️  Average per query: {avg_time_per_query:.2f}s\")\n",
    "    \n",
    "    # Save results (skip if dry run)\n",
    "    if dry_run:\n",
    "        print(f\"\\n  ℹ️  DRY RUN - Results not saved\")\n",
    "        print(f\"  ℹ️  Set DRY_RUN_ENABLED=False to save results\")\n",
    "        \n",
    "        # Display sample expansions\n",
    "        print(f\"\\n  Sample expansions:\")\n",
    "        for i, result in enumerate(results[:3], 1):\n",
    "            print(f\"\\n  [{i}] Original:\")\n",
    "            print(f\"      {result['original_query'][:100]}...\")\n",
    "            print(f\"      Expanded:\")\n",
    "            print(f\"      {result['expanded_query'][:100]}...\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"dry_run_complete\",\n",
    "            \"queries_processed\": len(results),\n",
    "            \"avg_time_per_query\": avg_time_per_query\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\\n  Saving results...\")\n",
    "        \n",
    "        # Get template string for metadata\n",
    "        template_string = TEMPLATES[template_key]\n",
    "        \n",
    "        # Save to JSON\n",
    "        saved_path = save_expansion_results(\n",
    "            results=results,\n",
    "            expansion_type=expansion_type,\n",
    "            expansion_sub_type=expansion_sub_type,\n",
    "            template=template_string,\n",
    "            llm_provider=LLM_PROVIDER,\n",
    "            llm_model=LLM_MODEL,\n",
    "            temperature=temperature,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        \n",
    "        print(f\"  ✓ Saved to: {saved_path}\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"completed\",\n",
    "            \"queries_processed\": len(results),\n",
    "            \"output_path\": saved_path,\n",
    "            \"avg_time_per_query\": avg_time_per_query,\n",
    "            \"total_time\": elapsed_time\n",
    "        }\n",
    "\n",
    "print(\"✓ process_expansion_config() defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.2 Batch Processing Function\n",
    "\n",
    "# %%\n",
    "def process_all_configs(\n",
    "    configs_to_run: List[str],\n",
    "    all_configs: Dict,\n",
    "    queries: List[Dict],\n",
    "    dry_run: bool = DRY_RUN_ENABLED,\n",
    "    output_dir: str = OUTPUT_DIR\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Process multiple expansion configurations in batch.\n",
    "    \n",
    "    Args:\n",
    "        configs_to_run: List of configuration names to process\n",
    "        all_configs: Dictionary of all available configurations\n",
    "        queries: List of query dictionaries from FinanceBench\n",
    "        dry_run: If True, run in dry run mode for all configs\n",
    "        output_dir: Directory to save output files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with summary statistics for all configs\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BATCH PROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Configurations to process: {len(configs_to_run)}\")\n",
    "    print(f\"  Total queries per config: {len(queries)}\")\n",
    "    print(f\"  Dry run mode: {'YES' if dry_run else 'NO'}\")\n",
    "    print(f\"  Output directory: {output_dir}\")\n",
    "    \n",
    "    # Track results\n",
    "    results_summary = {\n",
    "        \"total_configs\": len(configs_to_run),\n",
    "        \"completed\": 0,\n",
    "        \"skipped\": 0,\n",
    "        \"failed\": 0,\n",
    "        \"details\": []\n",
    "    }\n",
    "    \n",
    "    # Process each config\n",
    "    for i, config_name in enumerate(configs_to_run, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Configuration {i}/{len(configs_to_run)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        config = all_configs[config_name]\n",
    "        \n",
    "        try:\n",
    "            result = process_expansion_config(\n",
    "                config_name=config_name,\n",
    "                config=config,\n",
    "                queries=queries,\n",
    "                dry_run=dry_run,\n",
    "                output_dir=output_dir\n",
    "            )\n",
    "            \n",
    "            # Update summary\n",
    "            if result[\"status\"] == \"completed\":\n",
    "                results_summary[\"completed\"] += 1\n",
    "            elif result[\"status\"] == \"skipped\":\n",
    "                results_summary[\"skipped\"] += 1\n",
    "            elif result[\"status\"] == \"dry_run_complete\":\n",
    "                results_summary[\"completed\"] += 1\n",
    "            \n",
    "            results_summary[\"details\"].append({\n",
    "                \"config_name\": config_name,\n",
    "                \"result\": result\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Failed to process {config_name}\")\n",
    "            print(f\"   Error: {str(e)}\")\n",
    "            results_summary[\"failed\"] += 1\n",
    "            \n",
    "            # Stop processing on failure (as requested)\n",
    "            print(f\"\\n⛔ Batch processing stopped due to error\")\n",
    "            break\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Total configs: {results_summary['total_configs']}\")\n",
    "    print(f\"  ✓ Completed: {results_summary['completed']}\")\n",
    "    print(f\"  ⏭️  Skipped: {results_summary['skipped']}\")\n",
    "    print(f\"  ❌ Failed: {results_summary['failed']}\")\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "print(\"✓ process_all_configs() defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.3 Test with Single Config (Optional)\n",
    "\n",
    "# %%\n",
    "# Uncomment to test with a single configuration in dry run mode\n",
    "\"\"\"\n",
    "print(\"Testing with single configuration...\")\n",
    "\n",
    "test_config_name = \"hyde_basic\"\n",
    "test_config = ALL_EXPANSION_CONFIGS[test_config_name]\n",
    "\n",
    "test_result = process_expansion_config(\n",
    "    config_name=test_config_name,\n",
    "    config=test_config,\n",
    "    queries=FINANCEBENCH_QUERIES,\n",
    "    dry_run=True,  # Test mode\n",
    "    dry_run_size=3  # Only 3 queries\n",
    ")\n",
    "\n",
    "print(\"\\nTest result:\")\n",
    "print(test_result)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 6 COMPLETE - Processing Functions Ready\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nImplemented functions:\")\n",
    "print(\"  ✓ process_expansion_config() - Process single expansion method\")\n",
    "print(\"  ✓ process_all_configs() - Batch process multiple methods\")\n",
    "print(\"\\nReady for execution!\")\n",
    "print(\"\\nNext: Proceed to Step 7: Execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbee83c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PRE-EXECUTION CHECKLIST\n",
      "============================================================\n",
      "\n",
      "1. LLM Configuration:\n",
      "   Provider: openai\n",
      "   Model: gpt-4o\n",
      "   ✓ Configured\n",
      "\n",
      "2. API Keys:\n",
      "   ✓ OpenAI API key loaded\n",
      "\n",
      "3. Output Directory:\n",
      "   Path: ../../expanded_queries\n",
      "   ✓ Directory exists\n",
      "\n",
      "4. Configurations to Process:\n",
      "   Total selected: 1\n",
      "   Will process: 1\n",
      "   Will skip (existing): 0\n",
      "\n",
      "   Configs to process:\n",
      "     - hyde_basic\n",
      "\n",
      "5. Dataset:\n",
      "   Queries loaded: 150\n",
      "   ✓ Ready\n",
      "\n",
      "6. Execution Mode:\n",
      "   Mode: FULL EXECUTION\n",
      "   Processing: All 150 queries\n",
      "   ✓ Results will be saved to JSON files\n",
      "\n",
      "============================================================\n",
      "✓ Pre-execution checks complete\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DRY RUN EXECUTION\n",
      "============================================================\n",
      "\n",
      "This will test the first configuration with a few sample queries.\n",
      "Review the output before proceeding to full execution.\n",
      "\n",
      "Testing configuration: hyde_basic\n",
      "Sample size: 5 queries\n",
      "\n",
      "\n",
      "============================================================\n",
      "PROCESSING: hyde_basic\n",
      "============================================================\n",
      "  Expansion Type: hyde\n",
      "  Expansion Sub-Type: basic\n",
      "  Template: hyde_basic\n",
      "  Temperature: 0.7\n",
      "  LLM: openai/gpt-4o\n",
      "  Mode: DRY RUN (processing 5 queries)\n",
      "\n",
      "  Initializing LLM...\n",
      "  ✓ LLM chain ready\n",
      "\n",
      "  Processing 5 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/175ptt0d6knb0gg0lg2h4n2h0000gp/T/ipykernel_61869/954716824.py:87: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e6957633944f9790a5ccf71514a8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  hyde_basic:   0%|          | 0/5 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/175ptt0d6knb0gg0lg2h4n2h0000gp/T/ipykernel_61869/688783123.py:153: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(query=query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ✓ Processed 5 queries successfully\n",
      "  ⏱️  Total time: 25.9s\n",
      "  ⏱️  Average per query: 5.18s\n",
      "\n",
      "  ℹ️  DRY RUN - Results not saved\n",
      "  ℹ️  Set DRY_RUN_ENABLED=False to save results\n",
      "\n",
      "  Sample expansions:\n",
      "\n",
      "  [1] Original:\n",
      "      What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "      Expanded:\n",
      "      In FY2018, 3M's capital expenditures amounted to approximately $1,603 million, as detailed in the ca...\n",
      "\n",
      "  [2] Original:\n",
      "      Assume that you are a public equities analyst. Answer the following question by primarily using info...\n",
      "      Expanded:\n",
      "      As of the year-end FY2018, the net property, plant, and equipment (PP&E) for 3M Company is reported ...\n",
      "\n",
      "  [3] Original:\n",
      "      Is 3M a capital-intensive business based on FY2022 data?...\n",
      "      Expanded:\n",
      "      Yes, 3M is considered a capital-intensive business based on FY2022 data. The company reported signif...\n",
      "\n",
      "============================================================\n",
      "DRY RUN COMPLETE\n",
      "============================================================\n",
      "\n",
      "✓ Review the sample expansions above\n",
      "✓ If they look good, proceed to full execution (Section 7.3)\n",
      "✓ If not, adjust templates or temperature and re-run\n",
      "\n",
      "============================================================\n",
      "FULL EXECUTION - STARTING\n",
      "============================================================\n",
      "\n",
      "⚠️  This will process all selected configurations.\n",
      "⚠️  Make sure you have reviewed the dry run results.\n",
      "\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING\n",
      "============================================================\n",
      "  Configurations to process: 1\n",
      "  Total queries per config: 150\n",
      "  Dry run mode: NO\n",
      "  Output directory: ../../expanded_queries\n",
      "\n",
      "============================================================\n",
      "Configuration 1/1\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING: hyde_basic\n",
      "============================================================\n",
      "  Expansion Type: hyde\n",
      "  Expansion Sub-Type: basic\n",
      "  Template: hyde_basic\n",
      "  Temperature: 0.7\n",
      "  LLM: openai/gpt-4o\n",
      "  Mode: FULL RUN (processing 150 queries)\n",
      "\n",
      "  Initializing LLM...\n",
      "  ✓ LLM chain ready\n",
      "\n",
      "  Processing 150 queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e376c7cb33e45c399c6c52a2807dd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  hyde_basic:   0%|          | 0/150 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ✓ Processed 150 queries successfully\n",
      "  ⏱️  Total time: 612.3s\n",
      "  ⏱️  Average per query: 4.08s\n",
      "\n",
      "  Saving results...\n",
      "  ✓ Saved to: ../../expanded_queries/expanded_queries_hyde_basic.json\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING SUMMARY\n",
      "============================================================\n",
      "  Total configs: 1\n",
      "  ✓ Completed: 1\n",
      "  ⏭️  Skipped: 0\n",
      "  ❌ Failed: 0\n",
      "\n",
      "============================================================\n",
      "FULL EXECUTION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Results summary:\n",
      "  Total configs: 1\n",
      "  ✓ Completed: 1\n",
      "  ⏭️  Skipped: 0\n",
      "  ❌ Failed: 0\n",
      "\n",
      "Generated files:\n",
      "  ✓ expanded_queries_hyde_basic.json (118.3 KB)\n",
      "  ✓ expanded_queries_hyde_basic_llama3.json (138.8 KB)\n",
      "\n",
      "============================================================\n",
      "✓ ALL PROCESSING COMPLETE\n",
      "============================================================\n",
      "\n",
      "⚠️  Full execution code is commented out\n",
      "   Uncomment the code block above to run full execution\n",
      "\n",
      "⚠️  Verification code is commented out\n",
      "   Uncomment after running full execution to verify files\n",
      "\n",
      "============================================================\n",
      "INSPECTING: expanded_queries_hyde_basic.json\n",
      "============================================================\n",
      "\n",
      "Metadata:\n",
      "  Expansion Type: hyde\n",
      "  Expansion Sub-Type: basic\n",
      "  LLM: openai/gpt-4o\n",
      "  Temperature: 0.7\n",
      "  Total Queries: 150\n",
      "  Created: 2025-10-23T22:22:53.762816\n",
      "\n",
      "Sample Expansions (showing 5):\n",
      "\n",
      "[Sample 1]\n",
      "  ID: financebench_id_03029\n",
      "  Doc: 3M_2018_10K\n",
      "  Original:\n",
      "    What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the question by relying on the details shown in the cash flow statement.\n",
      "  Expanded:\n",
      "    In FY2018, 3M reported capital expenditures of approximately $1,603 million, as detailed in the cash flow statement under investing activities. This investment reflects our continued commitment to innovation and growth across our diverse portfolio of products and services.\n",
      "\n",
      "[Sample 2]\n",
      "  ID: financebench_id_04672\n",
      "  Doc: 3M_2018_10K\n",
      "  Original:\n",
      "    Assume that you are a public equities analyst. Answer the following question by primarily using information that is shown in the balance sheet: what is the year end FY2018 net PPNE for 3M? Answer in USD billions.\n",
      "  Expanded:\n",
      "    As of the fiscal year-end 2018, 3M Company reported net Property, Plant, and Equipment (PP&E) of approximately $8.6 billion. This figure is derived from the balance sheet and reflects the company's investment in its physical assets, net of accumulated depreciation.\n",
      "\n",
      "[Sample 3]\n",
      "  ID: financebench_id_00499\n",
      "  Doc: 3M_2022_10K\n",
      "  Original:\n",
      "    Is 3M a capital-intensive business based on FY2022 data?\n",
      "  Expanded:\n",
      "    Yes, 3M is considered a capital-intensive business based on FY2022 data. The company has substantial investments in property, plant, and equipment to support its diversified manufacturing operations. In FY2022, 3M reported significant capital expenditures aimed at expanding production capacities and maintaining its extensive infrastructure. These investments are essential to sustain its innovation-driven product lines and to meet regulatory compliance across various sectors. As a result, 3M's capital intensity is reflected in its ongoing commitment to maintaining and upgrading its asset base to drive long-term growth.\n",
      "\n",
      "[Sample 4]\n",
      "  ID: financebench_id_01226\n",
      "  Doc: 3M_2022_10K\n",
      "  Original:\n",
      "    What drove operating margin change as of FY2022 for 3M? If operating margin is not a useful metric for a company like this, then please state that and explain why.\n",
      "  Expanded:\n",
      "    In FY2022, 3M's operating margin was primarily impacted by a combination of factors. Increased raw material costs and supply chain disruptions led to higher operational expenses. Additionally, strategic investments in research and development aimed at driving innovation also contributed to cost increases. However, these were partially offset by price increases across key product segments and continued cost management initiatives. Overall, the operating margin reflects the company's efforts to balance short-term challenges with long-term growth objectives.\n",
      "\n",
      "[Sample 5]\n",
      "  ID: financebench_id_01865\n",
      "  Doc: 3M_2022_10K\n",
      "  Original:\n",
      "    If we exclude the impact of M&A, which segment has dragged down 3M's overall growth in 2022?\n",
      "  Expanded:\n",
      "    In 2022, excluding the impact of mergers and acquisitions, the Consumer segment was primarily responsible for dragging down 3M's overall growth. This was largely due to decreased demand in the home improvement and retail channels, as well as supply chain disruptions that impacted product availability. The segment faced additional pressures from increased competition and pricing challenges, further contributing to its underperformance relative to other segments.\n",
      "\n",
      "============================================================\n",
      "\n",
      "⚠️  Inspection code is commented out\n",
      "   Uncomment after running full execution to inspect files\n",
      "\n",
      "============================================================\n",
      "✓ STEP 7 COMPLETE - EXECUTION READY\n",
      "============================================================\n",
      "\n",
      "Execution workflow:\n",
      "  1. ✓ Review pre-execution checklist (7.1)\n",
      "  2. ✓ Run dry run to test (7.2)\n",
      "  3. → Review dry run results\n",
      "  4. → Uncomment and run full execution (7.3)\n",
      "  5. → Verify generated files (7.4)\n",
      "  6. → Inspect sample results (7.5)\n",
      "\n",
      "Current status:\n",
      "  Mode: FULL EXECUTION\n",
      "  → Ready to run Section 7.3 (uncomment code first)\n",
      "\n",
      "Output files will be saved to:\n",
      "  ../../expanded_queries\n",
      "\n",
      "============================================================\n",
      "🎯 QUERY EXPANSION CREATOR - READY TO USE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 7: Execution\n",
    "# ============================================================================\n",
    "# \n",
    "# This is the final step where we execute the query expansion process.\n",
    "# \n",
    "# IMPORTANT: This section is designed to be run in stages:\n",
    "# 1. First, run a DRY RUN to test a single config with a few queries\n",
    "# 2. Review the expansions to ensure they look good\n",
    "# 3. Then run the FULL EXECUTION for all selected configs\n",
    "#\n",
    "# The execution will:\n",
    "# - Process all configs in CONFIGS_TO_RUN\n",
    "# - Skip configs that already have output files\n",
    "# - Stop immediately if any error occurs\n",
    "# - Save results to JSON files in OUTPUT_DIR\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.1 Pre-Execution Checklist\n",
    "# \n",
    "# Before running, verify:\n",
    "# - ✓ LLM provider and model are correctly configured\n",
    "# - ✓ API keys are loaded (if using OpenAI)\n",
    "# - ✓ CONFIGS_TO_RUN contains the configs you want to process\n",
    "# - ✓ Output directory exists and is writable\n",
    "# - ✓ You have reviewed the templates and configurations\n",
    "\n",
    "# LLM Provider Configuration\n",
    "# Choose: \"openai\" or \"ollama\"\n",
    "# LLM_PROVIDER = \"openai\"  # Change to \"ollama\" for local models\n",
    "LLM_PROVIDER = \"openai\"  # Change to \"ollama\" for local models\n",
    "\n",
    "# Model Selection\n",
    "# OpenAI options: \"gpt-4\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"\n",
    "# Ollama options: \"llama2\", \"mistral\", etc.\n",
    "# LLM_MODEL = \"gpt-4\"\n",
    "# LLM_MODEL = \"gpt-4o-mini\"\n",
    "LLM_MODEL = \"gpt-4o\"\n",
    "\n",
    "CONFIGS_TO_RUN = [\n",
    "    # HyDE expansions\n",
    "    \"hyde_basic\",\n",
    "    # \"hyde_detailed\",\n",
    "    # \"hyde_financial_terminology\",\n",
    "    \n",
    "    # # Query refinement\n",
    "    # \"query_refinement_clarification\",\n",
    "    # \"query_refinement_formal\",\n",
    "    # \"query_refinement_keyword_focused\",\n",
    "    \n",
    "    # # Term expansion\n",
    "    # \"term_expansion_abbreviation\",\n",
    "    # \"term_expansion_synonym\",\n",
    "    # \"term_expansion_context_addition\",\n",
    "    \n",
    "    # # Chain-of-thought\n",
    "    # \"chain_of_thought_step_by_step\",\n",
    "    # \"chain_of_thought_explicit_context\",\n",
    "    \n",
    "    # # Domain adaptation\n",
    "    # \"domain_adaptation_accounting_perspective\",\n",
    "    # \"domain_adaptation_10k_language\",\n",
    "]\n",
    "\n",
    "# %%\n",
    "print(\"=\"*60)\n",
    "print(\"PRE-EXECUTION CHECKLIST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check 1: LLM Configuration\n",
    "print(f\"\\n1. LLM Configuration:\")\n",
    "print(f\"   Provider: {LLM_PROVIDER}\")\n",
    "print(f\"   Model: {LLM_MODEL}\")\n",
    "print(f\"   ✓ Configured\")\n",
    "\n",
    "# Check 2: API Keys\n",
    "print(f\"\\n2. API Keys:\")\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    if OPENAI_API_KEY:\n",
    "        print(f\"   ✓ OpenAI API key loaded\")\n",
    "    else:\n",
    "        print(f\"   ❌ OpenAI API key MISSING\")\n",
    "elif LLM_PROVIDER == \"ollama\":\n",
    "    print(f\"   ✓ Ollama (no API key needed)\")\n",
    "    print(f\"   ⚠️  Ensure Ollama is running at {OLLAMA_BASE_URL}\")\n",
    "\n",
    "# Check 3: Output Directory\n",
    "print(f\"\\n3. Output Directory:\")\n",
    "print(f\"   Path: {OUTPUT_DIR}\")\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    print(f\"   ✓ Directory exists\")\n",
    "else:\n",
    "    print(f\"   ℹ️  Will be created automatically\")\n",
    "\n",
    "# Check 4: Configurations\n",
    "print(f\"\\n4. Configurations to Process:\")\n",
    "print(f\"   Total selected: {len(CONFIGS_TO_RUN)}\")\n",
    "\n",
    "# Check which will be processed vs skipped\n",
    "configs_will_process = []\n",
    "configs_will_skip = []\n",
    "\n",
    "for config_name in CONFIGS_TO_RUN:\n",
    "    config = ALL_EXPANSION_CONFIGS[config_name]\n",
    "    output_filename = f\"expanded_queries_{config['expansion_type']}_{config['expansion_sub_type']}.json\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        configs_will_skip.append(config_name)\n",
    "    else:\n",
    "        configs_will_process.append(config_name)\n",
    "\n",
    "print(f\"   Will process: {len(configs_will_process)}\")\n",
    "print(f\"   Will skip (existing): {len(configs_will_skip)}\")\n",
    "\n",
    "if configs_will_process:\n",
    "    print(f\"\\n   Configs to process:\")\n",
    "    for config_name in configs_will_process:\n",
    "        print(f\"     - {config_name}\")\n",
    "\n",
    "if configs_will_skip:\n",
    "    print(f\"\\n   Configs to skip (files exist):\")\n",
    "    for config_name in configs_will_skip:\n",
    "        print(f\"     - {config_name}\")\n",
    "\n",
    "# Check 5: Dataset\n",
    "print(f\"\\n5. Dataset:\")\n",
    "print(f\"   Queries loaded: {len(FINANCEBENCH_QUERIES)}\")\n",
    "print(f\"   ✓ Ready\")\n",
    "\n",
    "# Check 6: Dry Run Status\n",
    "print(f\"\\n6. Execution Mode:\")\n",
    "if DRY_RUN_ENABLED:\n",
    "    print(f\"   Mode: DRY RUN\")\n",
    "    print(f\"   Sample size: {DRY_RUN_SAMPLE_SIZE} queries\")\n",
    "    print(f\"   ℹ️  Results will NOT be saved\")\n",
    "else:\n",
    "    print(f\"   Mode: FULL EXECUTION\")\n",
    "    print(f\"   Processing: All {len(FINANCEBENCH_QUERIES)} queries\")\n",
    "    print(f\"   ✓ Results will be saved to JSON files\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Pre-execution checks complete\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.2 Dry Run Execution (RECOMMENDED FIRST)\n",
    "# \n",
    "# **Run this cell first to test with a single configuration.**\n",
    "# \n",
    "# This will:\n",
    "# - Process only the first config in CONFIGS_TO_RUN\n",
    "# - Use only a few queries (defined by DRY_RUN_SAMPLE_SIZE)\n",
    "# - Display sample expansions\n",
    "# - NOT save to file\n",
    "# \n",
    "# Review the expansions to ensure quality before running full execution.\n",
    "\n",
    "# %%\n",
    "# ============================================================================\n",
    "# DRY RUN - Test with single configuration\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DRY RUN EXECUTION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nThis will test the first configuration with a few sample queries.\")\n",
    "print(\"Review the output before proceeding to full execution.\\n\")\n",
    "\n",
    "# Select first config for testing\n",
    "if CONFIGS_TO_RUN:\n",
    "    test_config_name = CONFIGS_TO_RUN[0]\n",
    "    test_config = ALL_EXPANSION_CONFIGS[test_config_name]\n",
    "    \n",
    "    print(f\"Testing configuration: {test_config_name}\")\n",
    "    print(f\"Sample size: {DRY_RUN_SAMPLE_SIZE} queries\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Run dry run\n",
    "    dry_run_result = process_expansion_config(\n",
    "        config_name=test_config_name,\n",
    "        config=test_config,\n",
    "        queries=FINANCEBENCH_QUERIES,\n",
    "        dry_run=True,\n",
    "        dry_run_size=DRY_RUN_SAMPLE_SIZE\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DRY RUN COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n✓ Review the sample expansions above\")\n",
    "    print(\"✓ If they look good, proceed to full execution (Section 7.3)\")\n",
    "    print(\"✓ If not, adjust templates or temperature and re-run\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️  No configurations selected in CONFIGS_TO_RUN\")\n",
    "    print(\"   Please add configurations to CONFIGS_TO_RUN and try again\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.3 Full Execution\n",
    "# \n",
    "# **⚠️ IMPORTANT: Only run this after reviewing the dry run results!**\n",
    "# \n",
    "# This will:\n",
    "# - Process ALL configs in CONFIGS_TO_RUN\n",
    "# - Process ALL 150 queries for each config\n",
    "# - Save results to JSON files\n",
    "# - Skip configs that already have output files\n",
    "# - Stop immediately if any error occurs\n",
    "# \n",
    "# **Estimated time:**\n",
    "# - ~1-2 seconds per query (with delays)\n",
    "# - ~150-300 seconds (2.5-5 minutes) per config\n",
    "# - Total: ~30-65 minutes for all 13 configs\n",
    "# \n",
    "# **Cost estimate (if using OpenAI):**\n",
    "# - Depends on model and query length\n",
    "# - GPT-4: ~$0.01-0.03 per query\n",
    "# - Total for 150 queries: ~$1.50-4.50 per config\n",
    "# - All 13 configs: ~$20-60\n",
    "\n",
    "# %%\n",
    "# ============================================================================\n",
    "# FULL EXECUTION - Process all configurations\n",
    "# ============================================================================\n",
    "# \n",
    "# UNCOMMENT THE CODE BELOW TO RUN FULL EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FULL EXECUTION - STARTING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n⚠️  This will process all selected configurations.\")\n",
    "print(\"⚠️  Make sure you have reviewed the dry run results.\\n\")\n",
    "\n",
    "# Confirm execution\n",
    "# input(\"Press Enter to start full execution, or Ctrl+C to cancel...\")\n",
    "\n",
    "# Run full execution\n",
    "full_execution_results = process_all_configs(\n",
    "    configs_to_run=CONFIGS_TO_RUN,\n",
    "    all_configs=ALL_EXPANSION_CONFIGS,\n",
    "    queries=FINANCEBENCH_QUERIES,\n",
    "    dry_run=False,  # FULL EXECUTION\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FULL EXECUTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nResults summary:\")\n",
    "print(f\"  Total configs: {full_execution_results['total_configs']}\")\n",
    "print(f\"  ✓ Completed: {full_execution_results['completed']}\")\n",
    "print(f\"  ⏭️  Skipped: {full_execution_results['skipped']}\")\n",
    "print(f\"  ❌ Failed: {full_execution_results['failed']}\")\n",
    "\n",
    "# List generated files\n",
    "print(f\"\\nGenerated files:\")\n",
    "generated_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith('expanded_queries_')]\n",
    "for filename in sorted(generated_files):\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    file_size = os.path.getsize(filepath) / 1024  # KB\n",
    "    print(f\"  ✓ {filename} ({file_size:.1f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ ALL PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "print(\"\\n⚠️  Full execution code is commented out\")\n",
    "print(\"   Uncomment the code block above to run full execution\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.4 Verify Generated Files\n",
    "# \n",
    "# After full execution, run this cell to verify all files were generated correctly.\n",
    "\n",
    "# %%\n",
    "def verify_output_files(output_dir: str = OUTPUT_DIR) -> Dict:\n",
    "    \"\"\"\n",
    "    Verify that all output files are valid and complete.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory containing output JSON files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with verification results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VERIFYING OUTPUT FILES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    verification_results = {\n",
    "        \"total_files\": 0,\n",
    "        \"valid_files\": 0,\n",
    "        \"invalid_files\": [],\n",
    "        \"file_details\": []\n",
    "    }\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = [f for f in os.listdir(output_dir) if f.startswith('expanded_queries_') and f.endswith('.json')]\n",
    "    verification_results[\"total_files\"] = len(json_files)\n",
    "    \n",
    "    print(f\"\\nFound {len(json_files)} output files\\n\")\n",
    "    \n",
    "    for filename in sorted(json_files):\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Load and validate\n",
    "            data = load_expansion_results(filepath)\n",
    "            \n",
    "            # Check query count\n",
    "            num_queries = len(data[\"queries\"])\n",
    "            expected_queries = 150\n",
    "            \n",
    "            # Get metadata\n",
    "            metadata = data[\"metadata\"]\n",
    "            \n",
    "            # Verify\n",
    "            is_valid = num_queries == expected_queries\n",
    "            \n",
    "            if is_valid:\n",
    "                verification_results[\"valid_files\"] += 1\n",
    "                status = \"✓\"\n",
    "            else:\n",
    "                verification_results[\"invalid_files\"].append(filename)\n",
    "                status = \"⚠️\"\n",
    "            \n",
    "            print(f\"{status} {filename}\")\n",
    "            print(f\"   Type: {metadata['expansion_type']}/{metadata['expansion_sub_type']}\")\n",
    "            print(f\"   Queries: {num_queries}/{expected_queries}\")\n",
    "            print(f\"   Model: {metadata['llm_provider']}/{metadata['llm_model']}\")\n",
    "            print(f\"   Temperature: {metadata['temperature']}\")\n",
    "            print(f\"   Created: {metadata['creation_date']}\")\n",
    "            print()\n",
    "            \n",
    "            verification_results[\"file_details\"].append({\n",
    "                \"filename\": filename,\n",
    "                \"valid\": is_valid,\n",
    "                \"num_queries\": num_queries,\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {filename}\")\n",
    "            print(f\"   Error: {str(e)}\")\n",
    "            print()\n",
    "            verification_results[\"invalid_files\"].append(filename)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"=\"*60)\n",
    "    print(\"VERIFICATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Total files: {verification_results['total_files']}\")\n",
    "    print(f\"  ✓ Valid: {verification_results['valid_files']}\")\n",
    "    print(f\"  ⚠️  Invalid: {len(verification_results['invalid_files'])}\")\n",
    "    \n",
    "    if verification_results[\"invalid_files\"]:\n",
    "        print(f\"\\n  Invalid files:\")\n",
    "        for filename in verification_results[\"invalid_files\"]:\n",
    "            print(f\"    - {filename}\")\n",
    "    \n",
    "    return verification_results\n",
    "\n",
    "# Uncomment to verify files after execution\n",
    "\"\"\"\n",
    "verification_results = verify_output_files(OUTPUT_DIR)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n⚠️  Verification code is commented out\")\n",
    "print(\"   Uncomment after running full execution to verify files\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.5 Load and Inspect a Sample File\n",
    "\n",
    "# %%\n",
    "def inspect_sample_file(filename: str, output_dir: str = OUTPUT_DIR, num_samples: int = 3):\n",
    "    \"\"\"\n",
    "    Load and display sample expansions from a generated file.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the JSON file to inspect\n",
    "        output_dir: Directory containing the file\n",
    "        num_samples: Number of sample queries to display\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"INSPECTING: {filename}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        data = load_expansion_results(filepath)\n",
    "        \n",
    "        # Display metadata\n",
    "        metadata = data[\"metadata\"]\n",
    "        print(f\"\\nMetadata:\")\n",
    "        print(f\"  Expansion Type: {metadata['expansion_type']}\")\n",
    "        print(f\"  Expansion Sub-Type: {metadata['expansion_sub_type']}\")\n",
    "        print(f\"  LLM: {metadata['llm_provider']}/{metadata['llm_model']}\")\n",
    "        print(f\"  Temperature: {metadata['temperature']}\")\n",
    "        print(f\"  Total Queries: {metadata['total_queries']}\")\n",
    "        print(f\"  Created: {metadata['creation_date']}\")\n",
    "        \n",
    "        # Display sample queries\n",
    "        queries = data[\"queries\"]\n",
    "        print(f\"\\nSample Expansions (showing {min(num_samples, len(queries))}):\")\n",
    "        \n",
    "        for i, query in enumerate(queries[:num_samples], 1):\n",
    "            print(f\"\\n[Sample {i}]\")\n",
    "            print(f\"  ID: {query['financebench_id']}\")\n",
    "            print(f\"  Doc: {query['doc_name']}\")\n",
    "            print(f\"  Original:\")\n",
    "            print(f\"    {query['original_query']}\")\n",
    "            print(f\"  Expanded:\")\n",
    "            print(f\"    {query['expanded_query']}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n❌ File not found: {filepath}\")\n",
    "        print(\"   Run full execution first to generate files\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error loading file: {str(e)}\")\n",
    "\n",
    "# Uncomment to inspect a sample file\n",
    "\n",
    "# Example: Inspect the hyde_basic results\n",
    "inspect_sample_file(\"expanded_queries_hyde_basic.json\", num_samples=5)\n",
    "\n",
    "\n",
    "print(\"\\n⚠️  Inspection code is commented out\")\n",
    "print(\"   Uncomment after running full execution to inspect files\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.6 Final Summary\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 7 COMPLETE - EXECUTION READY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nExecution workflow:\")\n",
    "print(\"  1. ✓ Review pre-execution checklist (7.1)\")\n",
    "print(\"  2. ✓ Run dry run to test (7.2)\")\n",
    "print(\"  3. → Review dry run results\")\n",
    "print(\"  4. → Uncomment and run full execution (7.3)\")\n",
    "print(\"  5. → Verify generated files (7.4)\")\n",
    "print(\"  6. → Inspect sample results (7.5)\")\n",
    "\n",
    "print(\"\\nCurrent status:\")\n",
    "if DRY_RUN_ENABLED:\n",
    "    print(\"  Mode: DRY RUN\")\n",
    "    print(\"  → Safe to run Section 7.2\")\n",
    "else:\n",
    "    print(\"  Mode: FULL EXECUTION\")\n",
    "    print(\"  → Ready to run Section 7.3 (uncomment code first)\")\n",
    "\n",
    "print(\"\\nOutput files will be saved to:\")\n",
    "print(f\"  {OUTPUT_DIR}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 QUERY EXPANSION CREATOR - READY TO USE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
