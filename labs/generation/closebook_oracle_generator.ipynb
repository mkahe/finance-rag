{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9dd7183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "‚úÖ Output directory ready: ../../generation_set/closedbook_oracle\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: SETUP & DEPENDENCIES\n",
    "# ============================================================================\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# LangChain imports for LLM providers\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# LangChain utilities for prompts and parsing\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Dataset and utility imports\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "OUTPUT_DIR = \"../../generation_set/closedbook_oracle\"\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"‚úÖ Output directory ready: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cc4bc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset: PatronusAI/financebench (train split)\n",
      "   Output directory: ../../generation_set/closedbook_oracle\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: CONFIGURATION VARIABLES\n",
    "# ============================================================================\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET_NAME = \"PatronusAI/financebench\"\n",
    "DATASET_SPLIT = \"train\"  # 150 questions in train split\n",
    "\n",
    "# API Configuration - Load from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
    "\n",
    "# Rate Limiting Configuration\n",
    "CALL_DELAY = 1  # Seconds between each LLM call (rate limiting)\n",
    "RETRY_DELAY = 30  # Seconds to wait before retry after failure\n",
    "MAX_RETRIES = 3  # Maximum number of retry attempts\n",
    "\n",
    "# Global Generation Parameters\n",
    "TEMPERATURE = 0.0  # Deterministic generation for reproducibility\n",
    "\n",
    "# Prompt Templates for Closed-Book Mode\n",
    "CLOSED_BOOK_TEMPLATES = {\n",
    "    \"basic\": {\n",
    "        \"alias\": \"closed_basic\",\n",
    "        \"template\": \"\"\"You are a financial expert. Answer the following question based on your knowledge.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a concise, accurate answer:\"\"\"\n",
    "    },\n",
    "    \"cot\": {\n",
    "        \"alias\": \"closed_cot\",\n",
    "        \"template\": \"\"\"You are a financial expert. Answer the following question based on your knowledge. Think step by step.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Let's approach this step by step:\n",
    "1. First, let me analyze what information is needed\n",
    "2. Then, I'll provide the answer\n",
    "\n",
    "Answer:\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Prompt Templates for Oracle Mode\n",
    "ORACLE_TEMPLATES = {\n",
    "    \"basic\": {\n",
    "        \"alias\": \"oracle_basic\",\n",
    "        \"template\": \"\"\"You are a financial expert. Answer the question based strictly on the provided evidence from financial documents.\n",
    "\n",
    "Evidence:\n",
    "{evidence}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a concise, accurate answer based solely on the evidence above:\"\"\"\n",
    "    },\n",
    "    \"structured\": {\n",
    "        \"alias\": \"oracle_structured\",\n",
    "        \"template\": \"\"\"You are a financial analyst reviewing official financial documents. Use ONLY the provided evidence to answer the question.\n",
    "\n",
    "=== EVIDENCE FROM FINANCIAL DOCUMENTS ===\n",
    "{evidence}\n",
    "\n",
    "=== QUESTION ===\n",
    "{question}\n",
    "\n",
    "=== INSTRUCTIONS ===\n",
    "Provide a precise answer based strictly on the evidence. If the answer requires a number, provide it in the exact format shown in the documents.\n",
    "\n",
    "Answer:\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"   Dataset: {DATASET_NAME} ({DATASET_SPLIT} split)\")\n",
    "print(f\"   Output directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d8f29c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: PatronusAI/financebench (split: train)...\n",
      "‚úÖ Dataset loaded successfully!\n",
      "   Total questions: 150\n",
      "   Dataset features: dict_keys(['financebench_id', 'company', 'doc_name', 'question_type', 'question_reasoning', 'domain_question_num', 'question', 'answer', 'justification', 'dataset_subset_label', 'evidence', 'gics_sector', 'doc_type', 'doc_period', 'doc_link'])\n",
      "\n",
      "================================================================================\n",
      "SAMPLE ENTRY:\n",
      "================================================================================\n",
      "ID: financebench_id_03029\n",
      "Company: 3M\n",
      "Question Type: metrics-generated\n",
      "Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "Answer: $1577.00\n",
      "Number of evidence pieces: 1\n",
      "First evidence preview: Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Flow s\n",
      "Years ended December 31\n",
      " \n",
      "(Millions)\n",
      " \n",
      "2018\n",
      " \n",
      "2017\n",
      " \n",
      "2016\n",
      " \n",
      "Cash ...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: LOAD FINANCEBENCH DATASET\n",
    "# ============================================================================\n",
    "\n",
    "# Load dataset from HuggingFace\n",
    "print(f\"Loading dataset: {DATASET_NAME} (split: {DATASET_SPLIT})...\")\n",
    "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"   Total questions: {len(dataset)}\")\n",
    "print(f\"   Dataset features: {dataset.features.keys()}\")\n",
    "\n",
    "# Display a sample entry to verify structure\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE ENTRY:\")\n",
    "print(\"=\"*80)\n",
    "sample = dataset[0]\n",
    "print(f\"ID: {sample['financebench_id']}\")\n",
    "print(f\"Company: {sample['company']}\")\n",
    "print(f\"Question Type: {sample['question_type']}\")\n",
    "print(f\"Question: {sample['question'][:100]}...\")\n",
    "print(f\"Answer: {sample['answer']}\")\n",
    "print(f\"Number of evidence pieces: {len(sample['evidence'])}\")\n",
    "if len(sample['evidence']) > 0:\n",
    "    print(f\"First evidence preview: {sample['evidence'][0]['evidence_text'][:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "827fb07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain prompt templates created successfully!\n",
      "   Closed-book templates: ['basic', 'cot']\n",
      "   Oracle templates: ['basic', 'structured']\n",
      "\n",
      "================================================================================\n",
      "SAMPLE CLOSED-BOOK TEMPLATE (basic):\n",
      "================================================================================\n",
      "System: You are a financial expert assistant.\n",
      "Human: You are a financial expert. Answer the following question based on your knowledge.\n",
      "\n",
      "Question: What is the revenue of Apple in 2020?\n",
      "\n",
      "Provide a concise, accurate answer:\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: LANGCHAIN PROMPT TEMPLATES\n",
    "# ============================================================================\n",
    "\n",
    "# Convert closed-book templates to LangChain ChatPromptTemplate objects\n",
    "CLOSED_BOOK_LANGCHAIN_TEMPLATES = {}\n",
    "for key, template_info in CLOSED_BOOK_TEMPLATES.items():\n",
    "    CLOSED_BOOK_LANGCHAIN_TEMPLATES[key] = {\n",
    "        \"alias\": template_info[\"alias\"],\n",
    "        \"template\": template_info[\"template\"],\n",
    "        \"langchain_prompt\": ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a financial expert assistant.\"),\n",
    "            (\"human\", template_info[\"template\"])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "# Convert oracle templates to LangChain ChatPromptTemplate objects\n",
    "ORACLE_LANGCHAIN_TEMPLATES = {}\n",
    "for key, template_info in ORACLE_TEMPLATES.items():\n",
    "    ORACLE_LANGCHAIN_TEMPLATES[key] = {\n",
    "        \"alias\": template_info[\"alias\"],\n",
    "        \"template\": template_info[\"template\"],\n",
    "        \"langchain_prompt\": ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a financial expert assistant.\"),\n",
    "            (\"human\", template_info[\"template\"])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ LangChain prompt templates created successfully!\")\n",
    "print(f\"   Closed-book templates: {list(CLOSED_BOOK_LANGCHAIN_TEMPLATES.keys())}\")\n",
    "print(f\"   Oracle templates: {list(ORACLE_LANGCHAIN_TEMPLATES.keys())}\")\n",
    "\n",
    "# Test: Display one template structure\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE CLOSED-BOOK TEMPLATE (basic):\")\n",
    "print(\"=\"*80)\n",
    "print(CLOSED_BOOK_LANGCHAIN_TEMPLATES[\"basic\"][\"langchain_prompt\"].format(\n",
    "    question=\"What is the revenue of Apple in 2020?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1e9924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialization function created successfully!\n",
      "   ‚úÖ Test initialization successful: OpenAI GPT-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: LLM MODEL INITIALIZATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def get_llm(provider: str, model: str, temperature: float):\n",
    "    \"\"\"\n",
    "    Initialize and return a LangChain LLM based on provider.\n",
    "    \n",
    "    Args:\n",
    "        provider: One of 'openai', 'anthropic', 'ollama'\n",
    "        model: Model name (e.g., 'gpt-4o', 'claude-sonnet-4', 'llama3.1:8b')\n",
    "        temperature: Temperature for generation (0.0 for deterministic)\n",
    "    \n",
    "    Returns:\n",
    "        LangChain chat model instance\n",
    "    \"\"\"\n",
    "    if provider == \"openai\":\n",
    "        if not OPENAI_API_KEY:\n",
    "            raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "        return ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            api_key=OPENAI_API_KEY\n",
    "        )\n",
    "    \n",
    "    elif provider == \"anthropic\":\n",
    "        if not ANTHROPIC_API_KEY:\n",
    "            raise ValueError(\"ANTHROPIC_API_KEY not found in environment variables\")\n",
    "        return ChatAnthropic(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            api_key=ANTHROPIC_API_KEY\n",
    "        )\n",
    "    \n",
    "    elif provider == \"ollama\":\n",
    "        return ChatOllama(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            base_url=OLLAMA_BASE_URL\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider}. Supported: openai, anthropic, ollama\")\n",
    "\n",
    "print(\"‚úÖ LLM initialization function created successfully!\")\n",
    "\n",
    "# Test: Initialize a sample LLM (if API key available)\n",
    "try:\n",
    "    test_llm = get_llm(\"openai\", \"gpt-4o-mini\", 0.0)\n",
    "    print(f\"   ‚úÖ Test initialization successful: OpenAI GPT-4o-mini\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö†Ô∏è  Could not initialize test LLM: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57e9efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions created successfully!\n",
      "\n",
      "================================================================================\n",
      "TESTING HELPER FUNCTIONS:\n",
      "================================================================================\n",
      "Sanitize 'gpt-4o' ‚Üí 'gpt-4o'\n",
      "Sanitize 'llama3.1:8b' ‚Üí 'llama3-1_8b'\n",
      "\n",
      "Generated filename: oracle_ollama_llama3-1_8b_0.0_oracle_basic.json\n",
      "File exists: False\n",
      "\n",
      "Formatted evidence (first 200 chars):\n",
      "Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Flow s\n",
      "Years ended December 31\n",
      " \n",
      "(Millions)\n",
      " \n",
      "2018\n",
      " \n",
      "2017\n",
      " \n",
      "2016\n",
      " \n",
      "Cash Flows from Operating Activities\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Net ...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def sanitize_model_name(model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize model name for use in filenames.\n",
    "    Replace special characters with underscores or hyphens.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Original model name (e.g., 'llama3.1:8b', 'gpt-4o')\n",
    "    \n",
    "    Returns:\n",
    "        Sanitized model name (e.g., 'llama3-1_8b', 'gpt-4o')\n",
    "    \"\"\"\n",
    "    # Replace : with _ and . with -\n",
    "    sanitized = model_name.replace(\":\", \"_\").replace(\".\", \"-\")\n",
    "    return sanitized\n",
    "\n",
    "\n",
    "def generate_filename(config: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Generate output filename based on configuration.\n",
    "    Format: {mode}_{provider}_{model}_{temperature}_{template_alias}.json\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Filename string\n",
    "    \"\"\"\n",
    "    mode = config[\"mode\"]\n",
    "    provider = config[\"provider\"]\n",
    "    model = sanitize_model_name(config[\"model\"])\n",
    "    temperature = config[\"temperature\"]\n",
    "    \n",
    "    # Get template alias based on mode\n",
    "    if mode == \"closed_book\":\n",
    "        template_alias = CLOSED_BOOK_TEMPLATES[config[\"template_key\"]][\"alias\"]\n",
    "    else:  # oracle\n",
    "        template_alias = ORACLE_TEMPLATES[config[\"template_key\"]][\"alias\"]\n",
    "    \n",
    "    filename = f\"{mode}_{provider}_{model}_{temperature}_{template_alias}.json\"\n",
    "    return filename\n",
    "\n",
    "\n",
    "def check_file_exists(config: Dict[str, Any]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if output file for this configuration already exists.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "    \n",
    "    Returns:\n",
    "        True if file exists, False otherwise\n",
    "    \"\"\"\n",
    "    filename = generate_filename(config)\n",
    "    filepath = Path(OUTPUT_DIR) / filename\n",
    "    return filepath.exists()\n",
    "\n",
    "\n",
    "def format_evidence(evidence_list: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Format evidence pieces for oracle mode prompts.\n",
    "    Handles single or multiple evidence pieces with clear separation.\n",
    "    \n",
    "    Args:\n",
    "        evidence_list: List of evidence dictionaries from FinanceBench\n",
    "    \n",
    "    Returns:\n",
    "        Formatted evidence string\n",
    "    \"\"\"\n",
    "    if not evidence_list or len(evidence_list) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    # Single evidence piece\n",
    "    if len(evidence_list) == 1:\n",
    "        return evidence_list[0][\"evidence_text\"]\n",
    "    \n",
    "    # Multiple evidence pieces - format with clear separation\n",
    "    formatted_parts = []\n",
    "    for idx, evidence in enumerate(evidence_list, 1):\n",
    "        formatted_parts.append(f\"Evidence {idx}:\\n{evidence['evidence_text']}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_parts)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions created successfully!\")\n",
    "\n",
    "# Test helper functions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING HELPER FUNCTIONS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Sanitize model name\n",
    "test_model_1 = \"gpt-4o\"\n",
    "test_model_2 = \"llama3.1:8b\"\n",
    "print(f\"Sanitize 'gpt-4o' ‚Üí '{sanitize_model_name(test_model_1)}'\")\n",
    "print(f\"Sanitize 'llama3.1:8b' ‚Üí '{sanitize_model_name(test_model_2)}'\")\n",
    "\n",
    "# Test 2: Generate filename\n",
    "test_config = CONFIGURATIONS[0]\n",
    "test_filename = generate_filename(test_config)\n",
    "print(f\"\\nGenerated filename: {test_filename}\")\n",
    "\n",
    "# Test 3: Check file exists\n",
    "file_exists = check_file_exists(test_config)\n",
    "print(f\"File exists: {file_exists}\")\n",
    "\n",
    "# Test 4: Format evidence (using sample from dataset)\n",
    "sample_evidence = dataset[0][\"evidence\"]\n",
    "formatted_evidence = format_evidence(sample_evidence)\n",
    "print(f\"\\nFormatted evidence (first 200 chars):\\n{formatted_evidence[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "196e699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM caller with retry logic created successfully!\n",
      "\n",
      "================================================================================\n",
      "TESTING LLM CALLER:\n",
      "================================================================================\n",
      "‚úÖ Test successful!\n",
      "   Prompt: What is 2+2? Answer with just the number.\n",
      "   Answer: 4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: LLM CALLER WITH RETRY LOGIC\n",
    "# ============================================================================\n",
    "\n",
    "def call_llm_with_retry(\n",
    "    llm,\n",
    "    prompt: str,\n",
    "    max_retries: int = MAX_RETRIES,\n",
    "    retry_delay: int = RETRY_DELAY,\n",
    "    call_delay: float = CALL_DELAY\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call LLM with retry logic and rate limiting.\n",
    "    \n",
    "    Args:\n",
    "        llm: LangChain LLM instance\n",
    "        prompt: Formatted prompt string\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        retry_delay: Seconds to wait before retry after failure\n",
    "        call_delay: Seconds to wait between successful calls (rate limiting)\n",
    "    \n",
    "    Returns:\n",
    "        Generated answer text\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If all retries fail, stops execution\n",
    "    \"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Invoke the LLM\n",
    "            response = llm.invoke(prompt)\n",
    "            \n",
    "            # Extract text content from response\n",
    "            if hasattr(response, 'content'):\n",
    "                answer = response.content\n",
    "            else:\n",
    "                answer = str(response)\n",
    "            \n",
    "            # Rate limiting: wait before next call\n",
    "            time.sleep(call_delay)\n",
    "            \n",
    "            return answer.strip()\n",
    "        \n",
    "        except Exception as e:\n",
    "            last_error = e\n",
    "            print(f\"   ‚ö†Ô∏è  Attempt {attempt + 1}/{max_retries} failed: {str(e)}\")\n",
    "            \n",
    "            # If not the last attempt, wait before retry\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"   ‚è≥ Waiting {retry_delay} seconds before retry...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                # Last attempt failed - stop execution\n",
    "                print(f\"   ‚ùå All {max_retries} attempts failed!\")\n",
    "                raise Exception(f\"LLM call failed after {max_retries} attempts: {str(last_error)}\")\n",
    "    \n",
    "    # Should not reach here, but just in case\n",
    "    raise Exception(f\"LLM call failed: {str(last_error)}\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ LLM caller with retry logic created successfully!\")\n",
    "\n",
    "# Test: Call LLM with a simple prompt (if API key available)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING LLM CALLER:\")\n",
    "print(\"=\"*80)\n",
    "try:\n",
    "    test_llm = get_llm(\"openai\", \"gpt-4o-mini\", 0.0)\n",
    "    test_prompt = \"What is 2+2? Answer with just the number.\"\n",
    "    test_answer = call_llm_with_retry(test_llm, test_prompt)\n",
    "    print(f\"‚úÖ Test successful!\")\n",
    "    print(f\"   Prompt: {test_prompt}\")\n",
    "    print(f\"   Answer: {test_answer}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not test LLM caller: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d8c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processor with LangChain chain created successfully!\n",
      "\n",
      "================================================================================\n",
      "TESTING QUERY PROCESSOR:\n",
      "================================================================================\n",
      "Processing query: financebench_id_03029\n",
      "Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "\n",
      "‚úÖ Test successful!\n",
      "   Ground truth answer: $1577.00\n",
      "   Generated answer: The FY2018 capital expenditure amount for 3M was approximately $1,400 million (or $1.4 billion).\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: QUERY PROCESSOR WITH LANGCHAIN CHAIN\n",
    "# ============================================================================\n",
    "\n",
    "def process_query(\n",
    "    query_data: Dict[str, Any],\n",
    "    config: Dict[str, Any],\n",
    "    llm,\n",
    "    prompt_template: ChatPromptTemplate\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a single query and generate an answer using LangChain chain.\n",
    "    \n",
    "    Args:\n",
    "        query_data: Single query from FinanceBench dataset\n",
    "        config: Configuration dictionary\n",
    "        llm: LangChain LLM instance\n",
    "        prompt_template: LangChain ChatPromptTemplate\n",
    "    \n",
    "    Returns:\n",
    "        Query data with 'generated_answer' field added\n",
    "    \"\"\"\n",
    "    mode = config[\"mode\"]\n",
    "    question = query_data[\"question\"]\n",
    "    \n",
    "    # Build the chain: prompt_template | llm | output_parser\n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "    \n",
    "    # Prepare variables based on mode\n",
    "    if mode == \"closed_book\":\n",
    "        # Closed-book: only question\n",
    "        variables = {\"question\": question}\n",
    "    else:\n",
    "        # Oracle: question + evidence\n",
    "        evidence = query_data.get(\"evidence\", [])\n",
    "        formatted_evidence = format_evidence(evidence)\n",
    "        variables = {\n",
    "            \"question\": question,\n",
    "            \"evidence\": formatted_evidence\n",
    "        }\n",
    "    \n",
    "    # Invoke the chain with retry logic\n",
    "    try:\n",
    "        # Use the chain invoke which internally calls the LLM\n",
    "        generated_answer = chain.invoke(variables)\n",
    "        \n",
    "        # Add delay for rate limiting\n",
    "        time.sleep(CALL_DELAY)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If error occurs, re-raise to stop execution\n",
    "        raise Exception(f\"Failed to process query {query_data.get('financebench_id', 'unknown')}: {str(e)}\")\n",
    "    \n",
    "    # Add generated answer to query data\n",
    "    result = query_data.copy()\n",
    "    result[\"generated_answer\"] = generated_answer.strip()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"‚úÖ Query processor with LangChain chain created successfully!\")\n",
    "\n",
    "# Test: Process a single query\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING QUERY PROCESSOR:\")\n",
    "print(\"=\"*80)\n",
    "try:\n",
    "    # Get test configuration and LLM\n",
    "    test_config = {\n",
    "        \"mode\": \"closed_book\",\n",
    "        \"provider\": \"openai\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"template_key\": \"basic\",\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    "    test_llm = get_llm(test_config[\"provider\"], test_config[\"model\"], test_config[\"temperature\"])\n",
    "    test_prompt_template = CLOSED_BOOK_LANGCHAIN_TEMPLATES[test_config[\"template_key\"]][\"langchain_prompt\"]\n",
    "    \n",
    "    # Process first query from dataset\n",
    "    test_query = dataset[0]\n",
    "    print(f\"Processing query: {test_query['financebench_id']}\")\n",
    "    print(f\"Question: {test_query['question'][:100]}...\")\n",
    "    \n",
    "    result = process_query(test_query, test_config, test_llm, test_prompt_template)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test successful!\")\n",
    "    print(f\"   Ground truth answer: {result['answer']}\")\n",
    "    print(f\"   Generated answer: {result['generated_answer']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not test query processor: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "697ffe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadata builder function created successfully!\n",
      "\n",
      "================================================================================\n",
      "TESTING METADATA BUILDER:\n",
      "================================================================================\n",
      "{\n",
      "  \"mode\": \"oracle\",\n",
      "  \"provider\": \"ollama\",\n",
      "  \"model\": \"llama3.1:8b\",\n",
      "  \"temperature\": 0.0,\n",
      "  \"prompt_template\": \"You are a financial expert. Answer the following question based on your knowledge.\\n\\nQuestion: {question}\\n\\nProvide a concise, accurate answer:\",\n",
      "  \"template_alias\": \"closed_basic\",\n",
      "  \"dataset\": \"PatronusAI/financebench\",\n",
      "  \"dataset_split\": \"train\",\n",
      "  \"total_questions\": 150,\n",
      "  \"generated_at\": \"2025-10-25T15:10:48.955437Z\",\n",
      "  \"call_delay\": 1,\n",
      "  \"max_retries\": 3\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/175ptt0d6knb0gg0lg2h4n2h0000gp/T/ipykernel_79284/1600287816.py:31: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: METADATA BUILDER\n",
    "# ============================================================================\n",
    "\n",
    "def build_metadata(\n",
    "    config: Dict[str, Any],\n",
    "    template_info: Dict[str, Any],\n",
    "    dataset_info: Any\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build metadata object for output JSON file.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "        template_info: Template information (alias and template text)\n",
    "        dataset_info: Dataset object from HuggingFace\n",
    "    \n",
    "    Returns:\n",
    "        Metadata dictionary\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        \"mode\": config[\"mode\"],\n",
    "        \"provider\": config[\"provider\"],\n",
    "        \"model\": config[\"model\"],\n",
    "        \"temperature\": config[\"temperature\"],\n",
    "        \"prompt_template\": template_info[\"template\"],\n",
    "        \"template_alias\": template_info[\"alias\"],\n",
    "        \"dataset\": DATASET_NAME,\n",
    "        \"dataset_split\": DATASET_SPLIT,\n",
    "        \"total_questions\": len(dataset_info),\n",
    "        \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"call_delay\": CALL_DELAY,\n",
    "        \"max_retries\": MAX_RETRIES\n",
    "    }\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "\n",
    "print(\"‚úÖ Metadata builder function created successfully!\")\n",
    "\n",
    "# Test: Build sample metadata\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING METADATA BUILDER:\")\n",
    "print(\"=\"*80)\n",
    "test_config = CONFIGURATIONS[0]\n",
    "test_template_info = CLOSED_BOOK_LANGCHAIN_TEMPLATES[test_config[\"template_key\"]]\n",
    "test_metadata = build_metadata(test_config, test_template_info, dataset)\n",
    "\n",
    "print(json.dumps(test_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "162e0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Main execution loop function created successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 10: MAIN EXECUTION LOOP\n",
    "# ============================================================================\n",
    "\n",
    "def generate_answers_for_config(config: Dict[str, Any], dataset) -> None:\n",
    "    \"\"\"\n",
    "    Process all queries for a given configuration and save results to JSON.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "        dataset: FinanceBench dataset\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If any query fails after retries, stops execution\n",
    "    \"\"\"\n",
    "    # Check if output file already exists\n",
    "    if check_file_exists(config):\n",
    "        filename = generate_filename(config)\n",
    "        print(f\"‚è≠Ô∏è  Skipping {filename} (already exists)\")\n",
    "        return\n",
    "    \n",
    "    # Get mode and template information\n",
    "    mode = config[\"mode\"]\n",
    "    template_key = config[\"template_key\"]\n",
    "    \n",
    "    # Get appropriate template based on mode\n",
    "    if mode == \"closed_book\":\n",
    "        template_info = CLOSED_BOOK_LANGCHAIN_TEMPLATES[template_key]\n",
    "    else:  # oracle\n",
    "        template_info = ORACLE_LANGCHAIN_TEMPLATES[template_key]\n",
    "    \n",
    "    prompt_template = template_info[\"langchain_prompt\"]\n",
    "    \n",
    "    # Initialize LLM\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üöÄ Starting generation for: {generate_filename(config)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"   Mode: {mode}\")\n",
    "    print(f\"   Provider: {config['provider']}\")\n",
    "    print(f\"   Model: {config['model']}\")\n",
    "    print(f\"   Temperature: {config['temperature']}\")\n",
    "    print(f\"   Template: {template_info['alias']}\")\n",
    "    \n",
    "    try:\n",
    "        llm = get_llm(config[\"provider\"], config[\"model\"], config[\"temperature\"])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize LLM: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Build metadata\n",
    "    metadata = build_metadata(config, template_info, dataset)\n",
    "    \n",
    "    # Initialize results structure\n",
    "    results = {\n",
    "        \"metadata\": metadata,\n",
    "        \"queries\": []\n",
    "    }\n",
    "    \n",
    "    # Process all queries with progress bar\n",
    "    print(f\"\\nüìä Processing {len(dataset)} queries...\")\n",
    "    \n",
    "    for idx, query in enumerate(tqdm(dataset, desc=\"Generating answers\")):\n",
    "        try:\n",
    "            # Process query\n",
    "            result = process_query(query, config, llm, prompt_template)\n",
    "            \n",
    "            # Keep only required fields in specific order\n",
    "            query_result = {\n",
    "                \"financebench_id\": result[\"financebench_id\"],\n",
    "                \"question_type\": result[\"question_type\"],\n",
    "                \"question_reasoning\": result[\"question_reasoning\"],\n",
    "                \"question\": result[\"question\"],\n",
    "                \"doc_name\": result[\"doc_name\"],\n",
    "                \"company\": result[\"company\"],\n",
    "                \"answer\": result[\"answer\"],\n",
    "                \"generated_answer\": result[\"generated_answer\"],\n",
    "                \"evidence\": result[\"evidence\"]\n",
    "            }\n",
    "            \n",
    "            results[\"queries\"].append(query_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error processing query {idx + 1}/{len(dataset)}: {e}\")\n",
    "            print(f\"   Query ID: {query.get('financebench_id', 'unknown')}\")\n",
    "            raise  # Stop execution on error\n",
    "    \n",
    "    # Save results to JSON file\n",
    "    filename = generate_filename(config)\n",
    "    filepath = Path(OUTPUT_DIR) / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Successfully generated and saved: {filename}\")\n",
    "    print(f\"   Total queries processed: {len(results['queries'])}\")\n",
    "    print(f\"   File size: {filepath.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Main execution loop function created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4fb3624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Run all configurations function created successfully!\n",
      "\n",
      "================================================================================\n",
      "‚ö†Ô∏è  READY TO EXECUTE\n",
      "================================================================================\n",
      "To start generating answers, define your CONFIGURATIONS and run:\n",
      "   run_all_configurations(CONFIGURATIONS)\n",
      "\n",
      "This will process all configurations and may take significant time.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 11: RUN ALL CONFIGURATIONS\n",
    "# ============================================================================\n",
    "\n",
    "def run_all_configurations(configurations: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    Execute all configurations in the provided configurations list.\n",
    "    Generates JSON files for each configuration.\n",
    "    \n",
    "    Args:\n",
    "        configurations: List of configuration dictionaries to process\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"üéØ STARTING BATCH GENERATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total configurations: {len(configurations)}\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "    print(f\"Dataset: {DATASET_NAME} ({len(dataset)} questions)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Track statistics\n",
    "    generated_count = 0\n",
    "    skipped_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    # Process each configuration\n",
    "    for idx, config in enumerate(configurations, 1):\n",
    "        print(f\"\\n[{idx}/{len(configurations)}] Processing configuration...\")\n",
    "        \n",
    "        try:\n",
    "            # Check if file exists before processing\n",
    "            if check_file_exists(config):\n",
    "                skipped_count += 1\n",
    "            else:\n",
    "                generate_answers_for_config(config, dataset)\n",
    "                generated_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            failed_count += 1\n",
    "            print(f\"\\n‚ùå FATAL ERROR: Configuration failed!\")\n",
    "            print(f\"   Config: {config}\")\n",
    "            print(f\"   Error: {e}\")\n",
    "            print(f\"\\n‚õî Stopping execution due to error.\")\n",
    "            break\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä GENERATION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚úÖ Generated: {generated_count}\")\n",
    "    print(f\"‚è≠Ô∏è  Skipped (already exists): {skipped_count}\")\n",
    "    print(f\"‚ùå Failed: {failed_count}\")\n",
    "    print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if failed_count == 0:\n",
    "        print(\"üéâ All configurations completed successfully!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Some configurations failed. Check errors above.\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Run all configurations function created successfully!\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚ö†Ô∏è  READY TO EXECUTE\")\n",
    "print(\"=\"*80)\n",
    "print(\"To start generating answers, define your CONFIGURATIONS and run:\")\n",
    "print(\"   run_all_configurations(CONFIGURATIONS)\")\n",
    "print(\"\\nThis will process all configurations and may take significant time.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00867e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION CONFIGURATIONS & BATCH GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "# Execution Configurations\n",
    "# Each configuration will generate a separate output JSON file\n",
    "CONFIGURATIONS = [\n",
    "    # Closed-Book Configurations\n",
    "    # {\n",
    "    #     \"mode\": \"closed_book\",\n",
    "    #     \"provider\": \"openai\",\n",
    "    #     \"model\": \"gpt-4o\",\n",
    "    #     \"template_key\": \"basic\",\n",
    "    #     \"temperature\": 0.0\n",
    "    # },\n",
    "    {\n",
    "        \"mode\": \"closed_book\",\n",
    "        \"provider\": \"openai\",\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"template_key\": \"basic\",\n",
    "        \"temperature\": 0.0\n",
    "    },\n",
    "    # {\n",
    "    #     \"mode\": \"closed_book\",\n",
    "    #     \"provider\": \"anthropic\",\n",
    "    #     \"model\": \"claude-sonnet-4\",\n",
    "    #     \"template_key\": \"basic\",\n",
    "    #     \"temperature\": 0.0\n",
    "    # },\n",
    "    \n",
    "    # # Oracle Configurations\n",
    "    # {\n",
    "    #     \"mode\": \"oracle\",\n",
    "    #     \"provider\": \"openai\",\n",
    "    #     \"model\": \"gpt-4o\",\n",
    "    #     \"template_key\": \"basic\",\n",
    "    #     \"temperature\": 0.0\n",
    "    # },\n",
    "    # {\n",
    "    #     \"mode\": \"oracle\",\n",
    "    #     \"provider\": \"openai\",\n",
    "    #     \"model\": \"gpt-4o-mini\",\n",
    "    #     \"template_key\": \"basic\",\n",
    "    #     \"temperature\": 0.0\n",
    "    # },\n",
    "    # {\n",
    "    #     \"mode\": \"oracle\",\n",
    "    #     \"provider\": \"anthropic\",\n",
    "    #     \"model\": \"claude-sonnet-4\",\n",
    "    #     \"template_key\": \"structured\",\n",
    "    #     \"temperature\": 0.0\n",
    "    # },\n",
    "    # {\n",
    "    #     \"mode\": \"oracle\",\n",
    "    #     \"provider\": \"ollama\",\n",
    "    #     \"model\": \"llama3.1:8b\",\n",
    "    #     \"template_key\": \"basic\",\n",
    "    #     \"temperature\": 0.0\n",
    "    # }\n",
    "]\n",
    "\n",
    "# Display configuration statistics\n",
    "print(\"=\"*80)\n",
    "print(\"üìã CONFIGURATION STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count by mode\n",
    "closed_book_count = sum(1 for c in CONFIGURATIONS if c[\"mode\"] == \"closed_book\")\n",
    "oracle_count = sum(1 for c in CONFIGURATIONS if c[\"mode\"] == \"oracle\")\n",
    "\n",
    "print(f\"Total configurations: {len(CONFIGURATIONS)}\")\n",
    "print(f\"  ‚Ä¢ Closed-book: {closed_book_count}\")\n",
    "print(f\"  ‚Ä¢ Oracle: {oracle_count}\")\n",
    "\n",
    "# Count by provider\n",
    "providers = {}\n",
    "for config in CONFIGURATIONS:\n",
    "    provider = config[\"provider\"]\n",
    "    providers[provider] = providers.get(provider, 0) + 1\n",
    "\n",
    "print(f\"\\nBy provider:\")\n",
    "for provider, count in sorted(providers.items()):\n",
    "    print(f\"  ‚Ä¢ {provider}: {count}\")\n",
    "\n",
    "# Check which files already exist and which need to be generated\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÇ FILE STATUS CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "existing_files = []\n",
    "to_generate = []\n",
    "\n",
    "for idx, config in enumerate(CONFIGURATIONS, 1):\n",
    "    filename = generate_filename(config)\n",
    "    exists = check_file_exists(config)\n",
    "    \n",
    "    if exists:\n",
    "        existing_files.append((idx, filename, config))\n",
    "    else:\n",
    "        to_generate.append((idx, filename, config))\n",
    "\n",
    "print(f\"Existing files: {len(existing_files)}\")\n",
    "print(f\"To be generated: {len(to_generate)}\")\n",
    "\n",
    "# Show existing files\n",
    "if existing_files:\n",
    "    print(f\"\\n‚úÖ Already exist ({len(existing_files)}):\")\n",
    "    for idx, filename, config in existing_files:\n",
    "        print(f\"  [{idx}] {filename}\")\n",
    "\n",
    "# Show files to be generated\n",
    "if to_generate:\n",
    "    print(f\"\\nüîÑ Will generate ({len(to_generate)}):\")\n",
    "    for idx, filename, config in to_generate:\n",
    "        print(f\"  [{idx}] {filename}\")\n",
    "        print(f\"      Mode: {config['mode']} | Provider: {config['provider']} | Model: {config['model']}\")\n",
    "\n",
    "# Estimate time\n",
    "if to_generate:\n",
    "    estimated_time_minutes = (len(to_generate) * len(dataset) * CALL_DELAY) / 60\n",
    "    print(f\"\\n‚è±Ô∏è  Estimated time: ~{estimated_time_minutes:.1f} minutes\")\n",
    "    print(f\"   (Based on {len(dataset)} queries √ó {CALL_DELAY}s delay √ó {len(to_generate)} configs)\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Confirmation before starting\n",
    "if to_generate:\n",
    "    print(\"\\nüöÄ Ready to start generation!\")\n",
    "    print(\"   This will process all configurations listed above.\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Start the batch generation process\n",
    "    run_all_configurations(CONFIGURATIONS)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All files already exist. Nothing to generate.\")\n",
    "    print(\"   Delete files from output directory if you want to regenerate.\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
