{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f638d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e02561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 3, 'key_facts_gold': ['AMD', 'higher sales', 'EPYC server processors', 'higher semi-custom product sales', 'inclusion of Xilinx embedded product sales'], 'facts_present': ['AMD', 'revenue change', '64% increase in Data Center segment revenue', '21% increase in Gaming segment revenue', 'significant growth in Embedded segment revenue from Xilinx product sales'], 'facts_missing': ['higher sales of EPYC server processors', 'higher semi-custom product sales'], 'justification': 'The generated answer provides specific percentage increases for the Data Center and Gaming segments, as well as mentioning growth from Xilinx products, which aligns with the gold answer. However, it omits the mention of higher sales of EPYC server processors and higher semi-custom product sales, which are key components of the revenue change.', 'success': True, 'raw_response': {'score': 3, 'key_facts_gold': ['AMD', 'higher sales', 'EPYC server processors', 'higher semi-custom product sales', 'inclusion of Xilinx embedded product sales'], 'facts_present': ['AMD', 'revenue change', '64% increase in Data Center segment revenue', '21% increase in Gaming segment revenue', 'significant growth in Embedded segment revenue from Xilinx product sales'], 'facts_missing': ['higher sales of EPYC server processors', 'higher semi-custom product sales'], 'justification': 'The generated answer provides specific percentage increases for the Data Center and Gaming segments, as well as mentioning growth from Xilinx products, which aligns with the gold answer. However, it omits the mention of higher sales of EPYC server processors and higher semi-custom product sales, which are key components of the revenue change.'}, 'metadata': {'provider': 'openai', 'model': 'gpt-4o-mini', 'temperature': 0.0, 'question': 'What drove revenue change as of the FY22 for AMD?', 'gold_answer': 'In 2022, AMD reported Higher sales of their EPYC server processors, higher semi-custom product sales, and the inclusion of Xilinx embedded product sales', 'generated_answer': 'Revenue change for AMD in FY22 was driven by a 64% increase in Data Center segment revenue, a 21% increase in Gaming segment revenue, and significant growth in Embedded segment revenue from Xilinx product sales.'}}\n"
     ]
    }
   ],
   "source": [
    "from generation_evaluation_suit.llm_as_judge_graded import llm_as_judge_graded\n",
    "\n",
    "question = \"What drove revenue change as of the FY22 for AMD?\"\n",
    "gold_answer = \"In 2022, AMD reported Higher sales of their EPYC server processors, higher semi-custom product sales, and the inclusion of Xilinx embedded product sales\"\n",
    "generated_answer = \"Revenue change for AMD in FY22 was driven by a 64% increase in Data Center segment revenue, a 21% increase in Gaming segment revenue, and significant growth in Embedded segment revenue from Xilinx product sales.\"\n",
    "\n",
    "result = llm_as_judge_graded(\n",
    "    question=question,\n",
    "    gold_answer=gold_answer,\n",
    "    generated_answer=generated_answer,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_retries=3,\n",
    "    retry_delay_ms=1000\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3b5b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'match': True, 'gold_num': 1577.0, 'gen_num': 1580.0, 'relative_error': 0.19023462270133165, 'absolute_error': 3.0, 'error_category': 'within_tolerance', 'justification': 'The generated answer (1580 million) differs from the gold answer (1577 million) by 3 units, resulting in a relative error of 0.191%. Since 0.191% is less than the 1% tolerance, this is within tolerance and is a match.', 'success': True, 'raw_response': {'match': True, 'gold_number': 1577.0, 'generated_number': 1580.0, 'relative_error': 0.191, 'absolute_error': 3.0, 'error_category': 'within_tolerance', 'justification': 'The generated answer (1580 million) differs from the gold answer (1577 million) by 3 units, resulting in a relative error of 0.191%. Since 0.191% is less than the 1% tolerance, this is within tolerance and is a match.'}, 'metadata': {'provider': 'openai', 'model': 'gpt-4o-mini', 'temperature': 0.0, 'tolerance': 0.01, 'question': 'What is the FY2018 capital expenditure amount (in USD millions) for 3M?', 'gold_answer': '$1577.00', 'generated_answer': '1580 million dollars'}}\n"
     ]
    }
   ],
   "source": [
    "from generation_evaluation_suit.llm_as_judge_binary import llm_as_judge_binary\n",
    "\n",
    "question = \"What is the FY2018 capital expenditure amount (in USD millions) for 3M?\"\n",
    "gold = \"$1577.00\"\n",
    "gen = \"1580 million dollars\"\n",
    "\n",
    "result = llm_as_judge_binary(\n",
    "    question=question,\n",
    "    gold_answer=gold,\n",
    "    generated_answer=gen,\n",
    "    tolerance=0.01\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598b3dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Match! Error: 1.25%\n",
      "{'match': True, 'gold_num': 0.8, 'gen_num': 79.0, 'gold_scale': None, 'gen_scale': None, 'gold_is_percentage': False, 'gen_is_percentage': True, 'relative_error': 1.25, 'absolute_error': 1.0, 'error_category': 'within_tolerance', 'normalized_gold': 80.0, 'normalized_gen': 79.0, 'common_scale': None}\n"
     ]
    }
   ],
   "source": [
    "from generation_evaluation_suit.numerical_exact_match import numerical_exact_match\n",
    "\n",
    "result = numerical_exact_match(\n",
    "    gold_answer=\"$0.8\",\n",
    "    generated_answer=\"79%\",\n",
    "    tolerance=0.05  # 5% tolerance\n",
    ")\n",
    "\n",
    "if result['match']:\n",
    "    print(f\"✓ Match! Error: {result['relative_error']:.2f}%\")\n",
    "else:\n",
    "    print(f\"✗ No match. Category: {result['error_category']}\")\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2f651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_refusal': True, 'confidence': 1.0, 'refusal_type': 'explicit', 'matched_pattern': \"\\\\bi\\\\s+(?:do\\\\s+not|don't|cannot|can't|could\\\\s+not|couldn't)\\\\s+(?:know|have|provide|answer|calculate|determine|find)\", 'answer_length': 41}\n"
     ]
    }
   ],
   "source": [
    "from generation_evaluation_suit.detect_refusal import detect_refusal\n",
    "\n",
    "result = detect_refusal(\"I don't know the answer to that question.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58b6138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.400\n",
      "Precision: 0.429\n",
      "Recall: 0.375\n",
      "Common tokens: {'segment', 'the', 'consumer'}\n",
      "Missing tokens: {'by', '9', 'organically', 'shrunk', '0'}\n"
     ]
    }
   ],
   "source": [
    "from generation_evaluation_suit.token_f1 import token_f1\n",
    "result = token_f1(\n",
    "    gold_answer=\"The consumer segment shrunk by 0.9% organically.\",\n",
    "    generated_answer=\"The Consumer segment has dragged down growth.\",\n",
    "    normalize=True,\n",
    "    remove_stopwords=False\n",
    ")\n",
    "\n",
    "print(f\"F1: {result['f1']:.3f}\")\n",
    "print(f\"Precision: {result['precision']:.3f}\")\n",
    "print(f\"Recall: {result['recall']:.3f}\")\n",
    "print(f\"Common tokens: {result['common_tokens']}\")\n",
    "print(f\"Missing tokens: {result['missing_tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97ce4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Question Type: metrics-generated\n",
      "Question: What is the FY2018 capital expenditure?...\n",
      "Gold Answer: $1577.00...\n",
      "Generated Answer: 1577 million dollars...\n",
      "\n",
      "Refusal Detected: False\n",
      "\n",
      "Metrics Computed: numerical_exact_match, llm_as_judge_binary\n",
      "\n",
      "NUMERICAL_EXACT_MATCH:\n",
      "  Match: True\n",
      "  Category: exact_match\n",
      "\n",
      "LLM_AS_JUDGE_BINARY:\n",
      "  Match: True\n",
      "  Category: exact_match\n",
      "\n",
      "Evaluation Complete: True\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from generation_evaluation_suit.evaluate_answer import evaluate_answer, print_evaluation_summary\n",
    "\n",
    "result = evaluate_answer(\n",
    "    question=\"What is the FY2018 capital expenditure?\",\n",
    "    question_type=\"metrics-generated\",\n",
    "    gold_answer=\"$1577.00\",\n",
    "    generated_answer=\"1577 million dollars\"\n",
    ")\n",
    "\n",
    "# Use built-in pretty printer\n",
    "print_evaluation_summary(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
