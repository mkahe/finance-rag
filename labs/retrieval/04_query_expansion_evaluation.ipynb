{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d5db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Standard imports successful\n",
      "✓ Text similarity imports successful\n",
      "✓ OpenAI API key loaded\n",
      "✓ VoyageAI API key loaded\n",
      "✓ Ollama URL: http://localhost:11434\n",
      "✓ Configuration set\n",
      "  Vector DB Directory: ../../vector_databases\n",
      "  Output Directory: ../../evaluation_results/query_enhancement\n",
      "\n",
      "  Sentence-BERT Model: all-MiniLM-L6-v2\n",
      "  Text Similarity Threshold: 0.8\n",
      "  Chunk Text Preview: First 100 + Last 100 chars\n",
      "\n",
      "Loading FinanceBench dataset...\n",
      "✓ Loaded 150 queries\n",
      "\n",
      "Sample query:\n",
      "  ID: financebench_id_03029\n",
      "  Company: 3M\n",
      "  Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "  Doc: 3M_2018_10K\n",
      "  Evidence items: 1\n",
      "\n",
      "  First evidence item structure:\n",
      "    - doc_name: 3M_2018_10K\n",
      "    - evidence_page_num: 59\n",
      "    - evidence_text (first 100 chars): Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Flow s\n",
      "Years ended Dec...\n",
      "    - Has 'evidence_text_full_page': True\n",
      "\n",
      "============================================================\n",
      "✓ STEP 1 COMPLETE!\n",
      "============================================================\n",
      "  ✓ All imports loaded\n",
      "  ✓ Environment variables configured\n",
      "  ✓ Paths set up\n",
      "  ✓ Dataset loaded: 150 queries\n",
      "  ✓ Text similarity threshold: 0.8\n",
      "  ✓ Chunk preview length: 100 + 100 chars\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Text-Based Evaluation Notebook - FinanceBench RAG\n",
    "# Evaluating Retrieval with Page-Based AND Text-Based Metrics\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # FinanceBench Text-Based Evaluation\n",
    "# \n",
    "# This notebook evaluates RAG retrieval performance using BOTH:\n",
    "# 1. **Page-based metrics**: MRR, Recall, Precision, F1 (based on page number matching)\n",
    "# 2. **Text-based metrics**: MRR, Recall, Precision, F1 (based on semantic similarity)\n",
    "# \n",
    "# We use Sentence-BERT (all-MiniLM-L6-v2) to compute cosine similarity between\n",
    "# retrieved chunks and ground truth evidence text.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.1 Standard Imports\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "# Environment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Data handling\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Vector stores and embeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "\n",
    "print(\"✓ Standard imports successful\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.2 Text Similarity Imports (NEW)\n",
    "\n",
    "# %%\n",
    "# Sentence-BERT for semantic similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cosine similarity calculation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"✓ Text similarity imports successful\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.3 Load Environment Variables\n",
    "\n",
    "# %%\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# API Keys and URLs\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
    "VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "\n",
    "# Verify API keys\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"✓ OpenAI API key loaded\")\n",
    "else:\n",
    "    print(\"⚠ OpenAI API key not found (only needed if using OpenAI embeddings)\")\n",
    "\n",
    "if VOYAGE_API_KEY:\n",
    "    print(\"✓ VoyageAI API key loaded\")\n",
    "else:\n",
    "    print(\"⚠ VoyageAI API key not found (only needed if using VoyageAI embeddings)\")\n",
    "\n",
    "print(f\"✓ Ollama URL: {OLLAMA_BASE_URL}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.4 Configuration Variables\n",
    "\n",
    "# %%\n",
    "# Directory paths\n",
    "VECTOR_DB_BASE_DIR = \"../../vector_databases\"\n",
    "EXPANDED_QUERIES_DIR = \"../../query_enhancement_set\"\n",
    "OUTPUT_DIR = \"../../evaluation_results/query_enhancement\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = \"PatronusAI/financebench\"\n",
    "DATASET_SPLIT = \"train\"\n",
    "\n",
    "# Vector database configuration\n",
    "COLLECTION_PREFIX = \"financebench_docs_chunk_\"\n",
    "\n",
    "# ============================================================================\n",
    "# TEXT-BASED EVALUATION PARAMETERS (NEW)\n",
    "# ============================================================================\n",
    "\n",
    "# Sentence-BERT model for semantic similarity\n",
    "SBERT_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Similarity threshold for text-based matching\n",
    "# Chunks with cosine similarity >= this threshold are considered matches\n",
    "TEXT_SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "# Chunk text preview settings\n",
    "# We store abbreviated chunk text: \"first N chars...last N chars\"\n",
    "CHUNK_TEXT_PREFIX_CHARS = 100  # Characters to keep from start\n",
    "CHUNK_TEXT_SUFFIX_CHARS = 100  # Characters to keep from end\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(\"✓ Configuration set\")\n",
    "print(f\"  Vector DB Directory: {VECTOR_DB_BASE_DIR}\")\n",
    "print(f\"  Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\n  Sentence-BERT Model: {SBERT_MODEL_NAME}\")\n",
    "print(f\"  Text Similarity Threshold: {TEXT_SIMILARITY_THRESHOLD}\")\n",
    "print(f\"  Chunk Text Preview: First {CHUNK_TEXT_PREFIX_CHARS} + Last {CHUNK_TEXT_SUFFIX_CHARS} chars\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.5 Load FinanceBench Dataset\n",
    "\n",
    "# %%\n",
    "print(\"\\nLoading FinanceBench dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT)\n",
    "print(f\"✓ Loaded {len(dataset)} queries\")\n",
    "\n",
    "# Show sample query with evidence structure\n",
    "print(\"\\nSample query:\")\n",
    "sample = dataset[0]\n",
    "print(f\"  ID: {sample['financebench_id']}\")\n",
    "print(f\"  Company: {sample['company']}\")\n",
    "print(f\"  Question: {sample['question'][:100]}...\")\n",
    "print(f\"  Doc: {sample['doc_name']}\")\n",
    "print(f\"  Evidence items: {len(sample['evidence'])}\")\n",
    "\n",
    "# Show evidence structure\n",
    "if len(sample['evidence']) > 0:\n",
    "    print(\"\\n  First evidence item structure:\")\n",
    "    evidence_item = sample['evidence'][0]\n",
    "    print(f\"    - doc_name: {evidence_item['doc_name']}\")\n",
    "    print(f\"    - evidence_page_num: {evidence_item['evidence_page_num']}\")\n",
    "    print(f\"    - evidence_text (first 100 chars): {evidence_item['evidence_text'][:100]}...\")\n",
    "    print(f\"    - Has 'evidence_text_full_page': {'evidence_text_full_page' in evidence_item}\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 1 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ All imports loaded\")\n",
    "print(\"  ✓ Environment variables configured\")\n",
    "print(\"  ✓ Paths set up\")\n",
    "print(f\"  ✓ Dataset loaded: {len(dataset)} queries\")\n",
    "print(f\"  ✓ Text similarity threshold: {TEXT_SIMILARITY_THRESHOLD}\")\n",
    "print(f\"  ✓ Chunk preview length: {CHUNK_TEXT_PREFIX_CHARS} + {CHUNK_TEXT_SUFFIX_CHARS} chars\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222b1a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Expanded queries loading functions defined\n",
      "\n",
      "============================================================\n",
      "TESTING EXPANDED QUERIES LOADING\n",
      "============================================================\n",
      "Loading expanded queries from: expanded_queries_hyde_basic.json\n",
      "\n",
      "Expanded Queries Info:\n",
      "  Type: hyde\n",
      "  Subtype: basic\n",
      "  LLM: openai/gpt-4o-mini\n",
      "  Total queries: 150\n",
      "  ✓ Created lookup dictionary with 150 entries\n",
      "\n",
      "✓ Successfully retrieved expanded query for financebench_id_03029\n",
      "\n",
      "Original query (first 100 chars):\n",
      "  What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "\n",
      "Expanded query (first 150 chars):\n",
      "  For the fiscal year 2018, 3M reported capital expenditures of $1,450 million, as detailed in the consolidated cash flow statement....\n",
      "\n",
      "Doc name: 3M_2018_10K\n",
      "\n",
      "============================================================\n",
      "✓ EXPANDED QUERIES LOADING TEST COMPLETE\n",
      "============================================================\n",
      "Sample expanded query info:\n",
      "\n",
      "Original query: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the question by relying on the details shown in the cash flow statement.\n",
      "Expanded query: For the fiscal year 2018, 3M reported capital expenditures of $1,450 million, as detailed in the consolidated cash flow statement.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 1.A: Test expanded queries loading functions\n",
    "# ============================================================================\n",
    "\n",
    "def load_expanded_queries(\n",
    "    expanded_queries_dir: str,\n",
    "    expansion_type: str,\n",
    "    expansion_subtype: str\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Load expanded queries from JSON file and create a lookup dictionary.\n",
    "    \n",
    "    Args:\n",
    "        expanded_queries_dir: Directory containing expanded query JSON files\n",
    "        expansion_type: Type of expansion (e.g., \"hyde\", \"query2doc\", etc.)\n",
    "        expansion_subtype: Subtype of expansion (e.g., \"basic\", \"cot\", etc.)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping financebench_id to expanded query information\n",
    "        Format: {\n",
    "            'financebench_id_xxxxx': {\n",
    "                'original_query': '...',\n",
    "                'expanded_query': '...',\n",
    "                'doc_name': '...'\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "        \n",
    "    Example:\n",
    "        expanded_lookup = load_expanded_queries(\n",
    "            \"../../expanded_queries\",\n",
    "            \"hyde\",\n",
    "            \"basic\"\n",
    "        )\n",
    "        # Get expanded query for a specific ID\n",
    "        expanded_info = expanded_lookup['financebench_id_03029']\n",
    "        print(expanded_info['expanded_query'])\n",
    "    \"\"\"\n",
    "    # Construct filename\n",
    "    filename = f\"expanded_queries_{expansion_type}_{expansion_subtype}.json\"\n",
    "    filepath = os.path.join(expanded_queries_dir, filename)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Expanded queries file not found: {filepath}\")\n",
    "    \n",
    "    # Load JSON file\n",
    "    print(f\"Loading expanded queries from: {filename}\")\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = data.get('metadata', {})\n",
    "    queries = data.get('queries', [])\n",
    "    \n",
    "    print(f\"\\nExpanded Queries Info:\")\n",
    "    print(f\"  Type: {metadata.get('expansion_type', 'N/A')}\")\n",
    "    print(f\"  Subtype: {metadata.get('expansion_sub_type', 'N/A')}\")\n",
    "    print(f\"  LLM: {metadata.get('llm_provider', 'N/A')}/{metadata.get('llm_model', 'N/A')}\")\n",
    "    print(f\"  Total queries: {len(queries)}\")\n",
    "    \n",
    "    # Create lookup dictionary indexed by financebench_id\n",
    "    expanded_lookup = {}\n",
    "    for query_data in queries:\n",
    "        fb_id = query_data['financebench_id']\n",
    "        expanded_lookup[fb_id] = {\n",
    "            'original_query': query_data['original_query'],\n",
    "            'expanded_query': query_data['expanded_query'],\n",
    "            'doc_name': query_data['doc_name']\n",
    "        }\n",
    "    \n",
    "    print(f\"  ✓ Created lookup dictionary with {len(expanded_lookup)} entries\")\n",
    "    \n",
    "    return expanded_lookup\n",
    "\n",
    "\n",
    "def test_expanded_queries_loading(\n",
    "    expanded_queries_dir: str = EXPANDED_QUERIES_DIR,\n",
    "    expansion_type: str = \"hyde\",\n",
    "    expansion_subtype: str = \"basic\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Test function to verify expanded queries loading works correctly.\n",
    "    \n",
    "    Args:\n",
    "        expanded_queries_dir: Directory containing expanded query files\n",
    "        expansion_type: Type of expansion to test\n",
    "        expansion_subtype: Subtype of expansion to test\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING EXPANDED QUERIES LOADING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Load expanded queries\n",
    "        expanded_lookup = load_expanded_queries(\n",
    "            expanded_queries_dir,\n",
    "            expansion_type,\n",
    "            expansion_subtype\n",
    "        )\n",
    "        \n",
    "        # Test retrieval with a sample ID\n",
    "        sample_id = \"financebench_id_03029\"\n",
    "        if sample_id in expanded_lookup:\n",
    "            print(f\"\\n✓ Successfully retrieved expanded query for {sample_id}\")\n",
    "            print(f\"\\nOriginal query (first 100 chars):\")\n",
    "            print(f\"  {expanded_lookup[sample_id]['original_query'][:100]}...\")\n",
    "            print(f\"\\nExpanded query (first 150 chars):\")\n",
    "            print(f\"  {expanded_lookup[sample_id]['expanded_query'][:150]}...\")\n",
    "            print(f\"\\nDoc name: {expanded_lookup[sample_id]['doc_name']}\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ Sample ID {sample_id} not found in lookup\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"✓ EXPANDED QUERIES LOADING TEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return expanded_lookup\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error during test: {e}\")\n",
    "        print(\"\\nPossible issues:\")\n",
    "        print(f\"  1. File not found: expanded_queries_{expansion_type}_{expansion_subtype}.json\")\n",
    "        print(f\"  2. Directory path incorrect: {expanded_queries_dir}\")\n",
    "        print(\"  3. JSON format issue\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print(\"✓ Expanded queries loading functions defined\")\n",
    "\n",
    "# Test the function\n",
    "expanded_lookup = test_expanded_queries_loading(\n",
    "    expanded_queries_dir=EXPANDED_QUERIES_DIR,\n",
    "    expansion_type=\"hyde\",\n",
    "    expansion_subtype=\"basic\"\n",
    ")\n",
    "\n",
    "# Access expanded queries by financebench_id\n",
    "if expanded_lookup:\n",
    "    query_info = expanded_lookup['financebench_id_03029']\n",
    "    print(\"Sample expanded query info:\\n\")\n",
    "    print(\"Original query:\", query_info['original_query'])\n",
    "    print(\"Expanded query:\", query_info['expanded_query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d166028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Sentence-BERT model: all-MiniLM-L6-v2\n",
      "  (First run will download model from HuggingFace...)\n",
      "✓ Model loaded successfully\n",
      "  Embedding dimension: 384\n",
      "  Max sequence length: 256\n",
      "\n",
      "============================================================\n",
      "TESTING SENTENCE-BERT MODEL\n",
      "============================================================\n",
      "\n",
      "Test texts:\n",
      "  Text 1: \n",
      "    In fiscal year 2018, capital expenditures were $1,577 million, compared to $1,432 million in fiscal year 2017. The increase was primarily due to investments in property, plant, and equipment to support our growth initiatives and enhance operational efficiency.\n",
      "  Text 2: \n",
      "    In fiscal year 2018, capital expenditures were $1,577 million, compared to $1,432 million in fiscal year 2017. This increase was mainly driven by investments in property, plant, and equipment to support growth initiatives and improve operational efficiency.\n",
      "  Text 3: \n",
      "    The weather was sunny and pleasant today.\n",
      "\n",
      "Encoding texts...\n",
      "✓ Generated embeddings shape: (3, 384)\n",
      "  (3 texts × 384 dimensions)\n",
      "\n",
      "Calculating cosine similarities:\n",
      "  Text 1 ↔ Text 2: 0.9967 (should be HIGH - same meaning)\n",
      "  Text 1 ↔ Text 3: 0.0022 (should be LOW - different topics)\n",
      "  Text 2 ↔ Text 3: 0.0020 (should be LOW - different topics)\n",
      "\n",
      "Validation:\n",
      "  ✓ Similar texts have high similarity (0.9967 > 0.7)\n",
      "  ✓ Different texts have low similarity (0.0022 < 0.5)\n",
      "\n",
      "============================================================\n",
      "✓ MODEL TEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TESTING WITH REAL FINANCEBENCH EVIDENCE\n",
      "============================================================\n",
      "\n",
      "Query: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "\n",
      "Evidence text (first 200 chars):\n",
      "  Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Flow s\n",
      "Years ended December 31\n",
      " \n",
      "(Millions)\n",
      " \n",
      "2018\n",
      " \n",
      "2017\n",
      " \n",
      "2016\n",
      " \n",
      "Cash Flows from Operating Activities\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Net ...\n",
      "\n",
      "Test chunks:\n",
      "  Chunk 1: Exact match - Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Fl...\n",
      "  Chunk 2: Paraphrased - Capital expenditures totaled $1,577 million in fiscal year 2018.\n",
      "  Chunk 3: Different topic - The company reported strong earnings growth driven by increased sales.\n",
      "\n",
      "Similarities with evidence:\n",
      "  Chunk 1: 1.0000 ✓ MATCH\n",
      "  Chunk 2: 0.3019 ✗ NO MATCH\n",
      "  Chunk 3: 0.3574 ✗ NO MATCH\n",
      "\n",
      "============================================================\n",
      "✓ REAL EVIDENCE TEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "✓ STEP 2 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Sentence-BERT model loaded\n",
      "  ✓ Model: all-MiniLM-L6-v2\n",
      "  ✓ Embedding dimension: 384\n",
      "  ✓ Model tested with sample texts\n",
      "  ✓ Model tested with real FinanceBench evidence\n",
      "  ✓ Ready for evidence embedding pre-computation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 2: Load Sentence-BERT Model\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.1 Load Sentence-BERT Model\n",
    "# \n",
    "# We load the `all-MiniLM-L6-v2` model once at the start.\n",
    "# This model will be used to:\n",
    "# 1. Encode evidence texts (done once and cached)\n",
    "# 2. Encode retrieved chunk texts (done for each retrieval)\n",
    "# 3. Calculate cosine similarity between them\n",
    "\n",
    "# %%\n",
    "def load_sentence_bert_model(model_name: str = SBERT_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Load Sentence-BERT model for semantic similarity computation.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the sentence-transformers model\n",
    "        \n",
    "    Returns:\n",
    "        SentenceTransformer model instance\n",
    "    \n",
    "    Notes:\n",
    "        - all-MiniLM-L6-v2: 384-dimensional embeddings, ~80MB model\n",
    "        - First load downloads model from HuggingFace\n",
    "        - Subsequent loads use cached model\n",
    "        - Uses CPU by default (can be moved to GPU if available)\n",
    "    \"\"\"\n",
    "    print(f\"\\nLoading Sentence-BERT model: {model_name}\")\n",
    "    print(\"  (First run will download model from HuggingFace...)\")\n",
    "    \n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "        print(f\"✓ Model loaded successfully\")\n",
    "        print(f\"  Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "        print(f\"  Max sequence length: {model.max_seq_length}\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load model: {e}\")\n",
    "        raise\n",
    "\n",
    "# %%\n",
    "# Load the model\n",
    "sbert_model = load_sentence_bert_model()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.2 Test the Model\n",
    "# \n",
    "# Let's verify the model works correctly by encoding sample texts\n",
    "\n",
    "# %%\n",
    "def test_sentence_bert_model(model):\n",
    "    \"\"\"\n",
    "    Test Sentence-BERT model with sample texts.\n",
    "    Verifies encoding and similarity calculation work correctly.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING SENTENCE-BERT MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Sample texts\n",
    "    # text1 = \"The company's revenue increased by 15% in Q4 2023.\"\n",
    "    # text2 = \"Revenue grew 15 percent in the fourth quarter of 2023.\"\n",
    "    # text3 = \"The weather was sunny and pleasant today.\"\n",
    "    text1 = \"\"\"\n",
    "    In fiscal year 2018, capital expenditures were $1,577 million, compared to $1,432 million in fiscal year 2017. The increase was primarily due to investments in property, plant, and equipment to support our growth initiatives and enhance operational efficiency.\"\"\"\n",
    "    text2 = \"\"\"\n",
    "    In fiscal year 2018, capital expenditures were $1,577 million, compared to $1,432 million in fiscal year 2017. This increase was mainly driven by investments in property, plant, and equipment to support growth initiatives and improve operational efficiency.\"\"\"\n",
    "    text3 = \"\"\"\n",
    "    The weather was sunny and pleasant today.\"\"\"\n",
    "    \n",
    "    print(\"\\nTest texts:\")\n",
    "    print(f\"  Text 1: {text1}\")\n",
    "    print(f\"  Text 2: {text2}\")\n",
    "    print(f\"  Text 3: {text3}\")\n",
    "    \n",
    "    # Encode texts\n",
    "    print(\"\\nEncoding texts...\")\n",
    "    embeddings = model.encode([text1, text2, text3])\n",
    "    \n",
    "    print(f\"✓ Generated embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"  (3 texts × {embeddings.shape[1]} dimensions)\")\n",
    "    \n",
    "    # Calculate similarities\n",
    "    print(\"\\nCalculating cosine similarities:\")\n",
    "    \n",
    "    # Similarity between text1 and text2 (semantically similar)\n",
    "    sim_1_2 = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    print(f\"  Text 1 ↔ Text 2: {sim_1_2:.4f} (should be HIGH - same meaning)\")\n",
    "    \n",
    "    # Similarity between text1 and text3 (semantically different)\n",
    "    sim_1_3 = cosine_similarity([embeddings[0]], [embeddings[2]])[0][0]\n",
    "    print(f\"  Text 1 ↔ Text 3: {sim_1_3:.4f} (should be LOW - different topics)\")\n",
    "    \n",
    "    # Similarity between text2 and text3 (semantically different)\n",
    "    sim_2_3 = cosine_similarity([embeddings[1]], [embeddings[2]])[0][0]\n",
    "    print(f\"  Text 2 ↔ Text 3: {sim_2_3:.4f} (should be LOW - different topics)\")\n",
    "    \n",
    "    # Verify results make sense\n",
    "    print(\"\\nValidation:\")\n",
    "    if sim_1_2 > 0.7:\n",
    "        print(f\"  ✓ Similar texts have high similarity ({sim_1_2:.4f} > 0.7)\")\n",
    "    else:\n",
    "        print(f\"  ⚠ Similar texts have lower similarity than expected ({sim_1_2:.4f})\")\n",
    "    \n",
    "    if sim_1_3 < 0.5:\n",
    "        print(f\"  ✓ Different texts have low similarity ({sim_1_3:.4f} < 0.5)\")\n",
    "    else:\n",
    "        print(f\"  ⚠ Different texts have higher similarity than expected ({sim_1_3:.4f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ MODEL TEST COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "# Run the test\n",
    "test_result = test_sentence_bert_model(sbert_model)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.3 Test with Actual FinanceBench Evidence\n",
    "# \n",
    "# Let's test with real evidence text from the dataset\n",
    "\n",
    "# %%\n",
    "def test_with_real_evidence(model, dataset):\n",
    "    \"\"\"\n",
    "    Test model with actual FinanceBench evidence text.\n",
    "    This helps verify the model works well with financial domain text.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING WITH REAL FINANCEBENCH EVIDENCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get first query with evidence\n",
    "    sample = dataset[0]\n",
    "    evidence_text = sample['evidence'][0]['evidence_text']\n",
    "    \n",
    "    print(f\"\\nQuery: {sample['question'][:100]}...\")\n",
    "    print(f\"\\nEvidence text (first 200 chars):\")\n",
    "    print(f\"  {evidence_text[:200]}...\")\n",
    "    \n",
    "    # Create some test chunks\n",
    "    # Chunk 1: Exact match (should have very high similarity)\n",
    "    chunk1 = evidence_text\n",
    "    \n",
    "    # Chunk 2: Paraphrased version (should have high similarity)\n",
    "    chunk2 = \"Capital expenditures totaled $1,577 million in fiscal year 2018.\"\n",
    "    \n",
    "    # Chunk 3: Different financial topic (should have lower similarity)\n",
    "    chunk3 = \"The company reported strong earnings growth driven by increased sales.\"\n",
    "    \n",
    "    print(\"\\nTest chunks:\")\n",
    "    print(f\"  Chunk 1: Exact match - {chunk1[:80]}...\")\n",
    "    print(f\"  Chunk 2: Paraphrased - {chunk2}\")\n",
    "    print(f\"  Chunk 3: Different topic - {chunk3}\")\n",
    "    \n",
    "    # Encode\n",
    "    evidence_embedding = model.encode([evidence_text])\n",
    "    chunk_embeddings = model.encode([chunk1, chunk2, chunk3])\n",
    "    \n",
    "    # Calculate similarities\n",
    "    print(\"\\nSimilarities with evidence:\")\n",
    "    for i, chunk_emb in enumerate(chunk_embeddings):\n",
    "        sim = cosine_similarity(evidence_embedding, [chunk_emb])[0][0]\n",
    "        match_status = \"✓ MATCH\" if sim >= TEXT_SIMILARITY_THRESHOLD else \"✗ NO MATCH\"\n",
    "        print(f\"  Chunk {i+1}: {sim:.4f} {match_status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ REAL EVIDENCE TEST COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "# Run test with real evidence\n",
    "real_evidence_test = test_with_real_evidence(sbert_model, dataset)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 2 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ Sentence-BERT model loaded\")\n",
    "print(f\"  ✓ Model: {SBERT_MODEL_NAME}\")\n",
    "print(f\"  ✓ Embedding dimension: {sbert_model.get_sentence_embedding_dimension()}\")\n",
    "print(\"  ✓ Model tested with sample texts\")\n",
    "print(\"  ✓ Model tested with real FinanceBench evidence\")\n",
    "print(\"  ✓ Ready for evidence embedding pre-computation\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcb8e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTRACTING EVIDENCE FROM DATASET\n",
      "============================================================\n",
      "\n",
      "Processing 150 queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbf5dd899a24fb987126e086d45aaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting evidence:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Extracted 189 evidence items\n",
      "  From 150 queries\n",
      "  Average evidence per query: 1.26\n",
      "\n",
      "Evidence distribution:\n",
      "  Min evidence per query: 1\n",
      "  Max evidence per query: 3\n",
      "  Median evidence per query: 1\n",
      "\n",
      "Sample evidence items:\n",
      "\n",
      "  Evidence 1:\n",
      "    Query ID: financebench_id_03029\n",
      "    Doc: 3M_2018_10K, Page: 60\n",
      "    Text (first 100 chars): Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Flow s\n",
      "Years ended Dec...\n",
      "\n",
      "  Evidence 2:\n",
      "    Query ID: financebench_id_04672\n",
      "    Doc: 3M_2018_10K, Page: 58\n",
      "    Text (first 100 chars): Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Balance Shee t\n",
      "At December 31\n",
      " \n",
      " \n",
      " \n",
      "Dece...\n",
      "\n",
      "  Evidence 3:\n",
      "    Query ID: financebench_id_00499\n",
      "    Doc: 3M_2022_10K, Page: 48\n",
      "    Text (first 100 chars): 3M Company and Subsidiaries\n",
      "Consolidated Statement of Income\n",
      "Years ended December 31\n",
      "(Millions, exce...\n",
      "\n",
      "============================================================\n",
      "COMPUTING EVIDENCE EMBEDDINGS\n",
      "============================================================\n",
      "\n",
      "Encoding 189 evidence texts...\n",
      "  Batch size: 32\n",
      "  Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97ce57da44d426a923b5bee6242798e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Embeddings computed\n",
      "  Shape: (189, 384)\n",
      "  Memory: 0.28 MB\n",
      "\n",
      "============================================================\n",
      "CREATING EVIDENCE LOOKUP STRUCTURE\n",
      "============================================================\n",
      "\n",
      "Building lookup for 189 evidence items...\n",
      "✓ Lookup created for 150 queries\n",
      "\n",
      "Verification - Sample query: financebench_id_03029\n",
      "  Evidence items: 1\n",
      "  First evidence embedding shape: (384,)\n",
      "\n",
      "============================================================\n",
      "TESTING EVIDENCE LOOKUP\n",
      "============================================================\n",
      "\n",
      "Test query: financebench_id_03029\n",
      "  Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "\n",
      "✓ Retrieved 1 evidence items\n",
      "\n",
      "  Evidence 1:\n",
      "    Doc: 3M_2018_10K, Page: 60\n",
      "    Text (first 80 chars): Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Fl...\n",
      "    Embedding shape: (384,)\n",
      "    Embedding sample (first 5 dims): [ 0.02514487 -0.04951032  0.00813957 -0.02846965 -0.01726394]\n",
      "\n",
      "✓ Count matches: 1 evidence items\n",
      "\n",
      "============================================================\n",
      "✓ LOOKUP TEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "✓ STEP 3 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Extracted 189 evidence items from 150 queries\n",
      "  ✓ Computed 189 embeddings\n",
      "  ✓ Embedding dimension: 384\n",
      "  ✓ Memory used: 0.28 MB\n",
      "  ✓ Evidence lookup created for 150 queries\n",
      "  ✓ Ready for evaluation with pre-computed embeddings\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 3: Pre-compute Evidence Embeddings\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.1 Extract All Evidence Texts\n",
    "# \n",
    "# We need to:\n",
    "# 1. Extract all unique evidence texts from the dataset\n",
    "# 2. Create a mapping structure for quick lookup\n",
    "# 3. Pre-compute embeddings once (instead of computing them 150 times)\n",
    "\n",
    "# %%\n",
    "def extract_all_evidence_from_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Extract all evidence items from the dataset.\n",
    "    \n",
    "    Returns a list of evidence items with metadata:\n",
    "    - query_id: Which query this evidence belongs to\n",
    "    - evidence_index: Index within that query's evidence list\n",
    "    - doc_name: Source document\n",
    "    - page_number: Evidence page (1-indexed for consistency)\n",
    "    - evidence_text: The actual text content\n",
    "    \n",
    "    This structure allows us to:\n",
    "    1. Pre-compute embeddings for all evidence\n",
    "    2. Map back to original queries during evaluation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXTRACTING EVIDENCE FROM DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    all_evidence = []\n",
    "    evidence_texts = []\n",
    "    \n",
    "    print(f\"\\nProcessing {len(dataset)} queries...\")\n",
    "    \n",
    "    for record in tqdm(dataset, desc=\"Extracting evidence\"):\n",
    "        query_id = record['financebench_id']\n",
    "        evidence_list = record['evidence']\n",
    "        \n",
    "        for evidence_idx, evidence_item in enumerate(evidence_list):\n",
    "            # Extract evidence information\n",
    "            evidence_entry = {\n",
    "                'query_id': query_id,\n",
    "                'evidence_index': evidence_idx,\n",
    "                'doc_name': evidence_item['doc_name'],\n",
    "                'page_number': evidence_item['evidence_page_num'] + 1,  # Convert to 1-indexed\n",
    "                'evidence_text': evidence_item['evidence_text']\n",
    "            }\n",
    "            \n",
    "            all_evidence.append(evidence_entry)\n",
    "            evidence_texts.append(evidence_item['evidence_text'])\n",
    "    \n",
    "    print(f\"\\n✓ Extracted {len(all_evidence)} evidence items\")\n",
    "    print(f\"  From {len(dataset)} queries\")\n",
    "    print(f\"  Average evidence per query: {len(all_evidence)/len(dataset):.2f}\")\n",
    "    \n",
    "    # Show statistics\n",
    "    evidence_per_query = {}\n",
    "    for record in dataset:\n",
    "        query_id = record['financebench_id']\n",
    "        evidence_per_query[query_id] = len(record['evidence'])\n",
    "    \n",
    "    print(f\"\\nEvidence distribution:\")\n",
    "    print(f\"  Min evidence per query: {min(evidence_per_query.values())}\")\n",
    "    print(f\"  Max evidence per query: {max(evidence_per_query.values())}\")\n",
    "    print(f\"  Median evidence per query: {sorted(evidence_per_query.values())[len(evidence_per_query)//2]}\")\n",
    "    \n",
    "    return all_evidence, evidence_texts\n",
    "\n",
    "# %%\n",
    "# Extract all evidence\n",
    "all_evidence, evidence_texts = extract_all_evidence_from_dataset(dataset)\n",
    "\n",
    "# Show sample evidence\n",
    "print(\"\\nSample evidence items:\")\n",
    "for i in range(min(3, len(all_evidence))):\n",
    "    ev = all_evidence[i]\n",
    "    print(f\"\\n  Evidence {i+1}:\")\n",
    "    print(f\"    Query ID: {ev['query_id']}\")\n",
    "    print(f\"    Doc: {ev['doc_name']}, Page: {ev['page_number']}\")\n",
    "    print(f\"    Text (first 100 chars): {ev['evidence_text'][:100]}...\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.2 Pre-compute Evidence Embeddings\n",
    "# \n",
    "# This is a critical optimization:\n",
    "# - Without pre-computation: 150 queries × avg 1.5 evidence × encoding time\n",
    "# - With pre-computation: Encode once, reuse 150 times\n",
    "# - Estimated time savings: ~98%\n",
    "\n",
    "# %%\n",
    "def compute_evidence_embeddings(\n",
    "    evidence_texts: List[str],\n",
    "    model: SentenceTransformer,\n",
    "    batch_size: int = 32\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pre-compute embeddings for all evidence texts.\n",
    "    \n",
    "    Args:\n",
    "        evidence_texts: List of evidence text strings\n",
    "        model: Sentence-BERT model\n",
    "        batch_size: Number of texts to encode at once (larger = faster but more memory)\n",
    "        \n",
    "    Returns:\n",
    "        numpy array of shape (n_evidence, embedding_dim)\n",
    "        \n",
    "    Notes:\n",
    "        - Processes in batches for efficiency\n",
    "        - Shows progress bar\n",
    "        - Uses CPU by default (can be moved to GPU if available)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPUTING EVIDENCE EMBEDDINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nEncoding {len(evidence_texts)} evidence texts...\")\n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "    \n",
    "    # Encode all texts with progress bar\n",
    "    # show_progress_bar=True displays tqdm progress\n",
    "    embeddings = model.encode(\n",
    "        evidence_texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Embeddings computed\")\n",
    "    print(f\"  Shape: {embeddings.shape}\")\n",
    "    print(f\"  Memory: {embeddings.nbytes / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# %%\n",
    "# Compute embeddings\n",
    "evidence_embeddings = compute_evidence_embeddings(\n",
    "    evidence_texts=evidence_texts,\n",
    "    model=sbert_model,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.3 Create Evidence Lookup Structure\n",
    "# \n",
    "# Create a convenient structure to look up evidence by query_id\n",
    "\n",
    "# %%\n",
    "def create_evidence_lookup(all_evidence: List[Dict], evidence_embeddings: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Create a lookup dictionary mapping query_id to evidence items with embeddings.\n",
    "    \n",
    "    Structure:\n",
    "    {\n",
    "        'query_id_1': [\n",
    "            {\n",
    "                'evidence_index': 0,\n",
    "                'doc_name': 'DOC_NAME',\n",
    "                'page_number': 60,\n",
    "                'evidence_text': 'text...',\n",
    "                'embedding': numpy array\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        ...\n",
    "    }\n",
    "    \n",
    "    This allows fast lookup: evidence_lookup[query_id] returns all evidence for that query\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING EVIDENCE LOOKUP STRUCTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    lookup = defaultdict(list)\n",
    "    \n",
    "    print(f\"\\nBuilding lookup for {len(all_evidence)} evidence items...\")\n",
    "    \n",
    "    for i, evidence_item in enumerate(all_evidence):\n",
    "        query_id = evidence_item['query_id']\n",
    "        \n",
    "        # Add embedding to evidence item\n",
    "        evidence_with_embedding = evidence_item.copy()\n",
    "        evidence_with_embedding['embedding'] = evidence_embeddings[i]\n",
    "        \n",
    "        lookup[query_id].append(evidence_with_embedding)\n",
    "    \n",
    "    print(f\"✓ Lookup created for {len(lookup)} queries\")\n",
    "    \n",
    "    # Verify\n",
    "    sample_query_id = list(lookup.keys())[0]\n",
    "    print(f\"\\nVerification - Sample query: {sample_query_id}\")\n",
    "    print(f\"  Evidence items: {len(lookup[sample_query_id])}\")\n",
    "    print(f\"  First evidence embedding shape: {lookup[sample_query_id][0]['embedding'].shape}\")\n",
    "    \n",
    "    return dict(lookup)\n",
    "\n",
    "# %%\n",
    "# Create lookup\n",
    "evidence_lookup = create_evidence_lookup(all_evidence, evidence_embeddings)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3.4 Test Evidence Lookup\n",
    "# \n",
    "# Verify we can retrieve evidence for any query\n",
    "\n",
    "# %%\n",
    "def test_evidence_lookup(dataset, evidence_lookup):\n",
    "    \"\"\"\n",
    "    Test that evidence lookup works correctly.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING EVIDENCE LOOKUP\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test with first query\n",
    "    sample_record = dataset[0]\n",
    "    query_id = sample_record['financebench_id']\n",
    "    \n",
    "    print(f\"\\nTest query: {query_id}\")\n",
    "    print(f\"  Question: {sample_record['question'][:100]}...\")\n",
    "    \n",
    "    # Retrieve from lookup\n",
    "    evidence_items = evidence_lookup.get(query_id, [])\n",
    "    \n",
    "    print(f\"\\n✓ Retrieved {len(evidence_items)} evidence items\")\n",
    "    \n",
    "    for i, ev in enumerate(evidence_items):\n",
    "        print(f\"\\n  Evidence {i+1}:\")\n",
    "        print(f\"    Doc: {ev['doc_name']}, Page: {ev['page_number']}\")\n",
    "        print(f\"    Text (first 80 chars): {ev['evidence_text'][:80]}...\")\n",
    "        print(f\"    Embedding shape: {ev['embedding'].shape}\")\n",
    "        print(f\"    Embedding sample (first 5 dims): {ev['embedding'][:5]}\")\n",
    "    \n",
    "    # Verify count matches original\n",
    "    original_evidence_count = len(sample_record['evidence'])\n",
    "    retrieved_evidence_count = len(evidence_items)\n",
    "    \n",
    "    if original_evidence_count == retrieved_evidence_count:\n",
    "        print(f\"\\n✓ Count matches: {original_evidence_count} evidence items\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Count mismatch: {original_evidence_count} vs {retrieved_evidence_count}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ LOOKUP TEST COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "# Test lookup\n",
    "test_evidence_lookup(dataset, evidence_lookup)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 3 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  ✓ Extracted {len(all_evidence)} evidence items from {len(dataset)} queries\")\n",
    "print(f\"  ✓ Computed {evidence_embeddings.shape[0]} embeddings\")\n",
    "print(f\"  ✓ Embedding dimension: {evidence_embeddings.shape[1]}\")\n",
    "print(f\"  ✓ Memory used: {evidence_embeddings.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"  ✓ Evidence lookup created for {len(evidence_lookup)} queries\")\n",
    "print(\"  ✓ Ready for evaluation with pre-computed embeddings\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3645f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metadata extraction functions defined\n",
      "✓ Embedding function factory defined\n",
      "✓ Vector store loading function defined\n",
      "\n",
      "============================================================\n",
      "TESTING VECTOR STORE LOADING\n",
      "============================================================\n",
      "\n",
      "Test configuration:\n",
      "  Provider: voyage\n",
      "  Model: voyage-finance-2\n",
      "  Chunk size: 1024\n",
      "\n",
      "Loading vectorstore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/175ptt0d6knb0gg0lg2h4n2h0000gp/T/ipykernel_99451/2851163119.py:151: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vectorstore loaded\n",
      "  Documents in collection: 15,765\n",
      "\n",
      "Testing retrieval...\n",
      "✓ Retrieved 3 documents\n",
      "\n",
      "Sample retrieved document:\n",
      "  Doc name: 3M_2018_10K\n",
      "  Page number: 59\n",
      "  Chunk text (first 150 chars): 44 per share, Note 8)\n",
      " \n",
      " \n",
      "(3,193) \n",
      " \n",
      "  \n",
      " \n",
      "(3,193) \n",
      " \n",
      "  \n",
      " \n",
      "  \n",
      " \n",
      "  \n",
      "Transfer of ownership involving non-wholly owned subsidiaries\n",
      " \n",
      " \n",
      " —  \n",
      " \n",
      "  \n",
      " \n",
      "14  \n",
      " ...\n",
      "  Chunk text length: 951 characters\n",
      "\n",
      "============================================================\n",
      "✓ VECTOR STORE TEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "✓ STEP 4 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Metadata extraction functions defined\n",
      "  ✓ Embedding function factory defined\n",
      "  ✓ Vector store loading function defined\n",
      "  ✓ Vector store loading tested successfully\n",
      "  ✓ Ready to perform retrievals with chunk text extraction\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 4: Helper Functions - Metadata Extraction and Vector Store Loading\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.1 Metadata Extraction Functions\n",
    "# \n",
    "# These functions extract document name and page number from retrieved chunks\n",
    "\n",
    "# %%\n",
    "def extract_doc_name_from_path(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract document name from file path.\n",
    "    \n",
    "    Example:\n",
    "        \"../../documents/3M_2018_10K.pdf\" → \"3M_2018_10K\"\n",
    "    \n",
    "    Args:\n",
    "        file_path: Full path to document\n",
    "        \n",
    "    Returns:\n",
    "        Document name without extension\n",
    "    \"\"\"\n",
    "    return Path(file_path).stem\n",
    "\n",
    "\n",
    "def extract_metadata_from_retrieved_doc(doc) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract metadata from a retrieved LangChain document.\n",
    "    \n",
    "    FIXED: Correctly extracts from ChromaDB metadata structure:\n",
    "        - file_path: Full path to PDF\n",
    "        - source: Page number (as integer or string)\n",
    "    \n",
    "    Args:\n",
    "        doc: LangChain Document object from vectorstore.similarity_search()\n",
    "        \n",
    "    Returns:\n",
    "        Dict with:\n",
    "            - doc_name: Document name (e.g., \"3M_2018_10K\")\n",
    "            - page_number: Page number (integer, 0-indexed from ChromaDB)\n",
    "            - chunk_text: The chunk content\n",
    "    \"\"\"\n",
    "    metadata = doc.metadata\n",
    "    \n",
    "    # Extract file path and convert to doc name\n",
    "    file_path = metadata.get('file_path', '')\n",
    "    doc_name = extract_doc_name_from_path(file_path)\n",
    "    \n",
    "    # Extract page number from 'source' field\n",
    "    page_num = metadata.get('source', 0)\n",
    "    \n",
    "    # Ensure page_num is an integer\n",
    "    if isinstance(page_num, str):\n",
    "        try:\n",
    "            page_num = int(page_num)\n",
    "        except ValueError:\n",
    "            page_num = 0\n",
    "    \n",
    "    return {\n",
    "        'doc_name': doc_name,\n",
    "        'page_number': page_num,  # Keep 0-indexed as stored in ChromaDB\n",
    "        'chunk_text': doc.page_content\n",
    "    }\n",
    "\n",
    "print(\"✓ Metadata extraction functions defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.2 Embedding Function Factory\n",
    "# \n",
    "# Creates the appropriate embedding function based on provider\n",
    "\n",
    "# %%\n",
    "def get_embedding_function(provider: str, model: str):\n",
    "    \"\"\"\n",
    "    Get embedding function for vector store loading.\n",
    "    \n",
    "    Args:\n",
    "        provider: \"ollama\", \"openai\", or \"voyage\"\n",
    "        model: Model name (e.g., \"nomic-embed-text\", \"text-embedding-3-small\")\n",
    "        \n",
    "    Returns:\n",
    "        Embedding function compatible with LangChain/ChromaDB\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If provider is unknown\n",
    "    \"\"\"\n",
    "    if provider == \"ollama\":\n",
    "        return OllamaEmbeddings(\n",
    "            model=model,\n",
    "            base_url=OLLAMA_BASE_URL\n",
    "        )\n",
    "    elif provider == \"openai\":\n",
    "        return OpenAIEmbeddings(\n",
    "            model=model,\n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "    elif provider == \"voyage\":\n",
    "        return VoyageAIEmbeddings(\n",
    "            model=model,\n",
    "            voyage_api_key=VOYAGE_API_KEY\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider}\")\n",
    "\n",
    "print(\"✓ Embedding function factory defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.3 Vector Store Loading\n",
    "# \n",
    "# Load pre-built vector databases from disk\n",
    "\n",
    "# %%\n",
    "def load_vectorstore(\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    base_dir: str = VECTOR_DB_BASE_DIR,\n",
    "    collection_prefix: str = COLLECTION_PREFIX\n",
    ") -> Chroma:\n",
    "    \"\"\"\n",
    "    Load a pre-built vector store from disk.\n",
    "    \n",
    "    The vector databases were created by build_vectore_database.ipynb\n",
    "    and stored in a specific directory structure:\n",
    "    \n",
    "    {base_dir}/{provider}_{model}/financebench_docs_chunk_{chunk_size}/\n",
    "    \n",
    "    Args:\n",
    "        provider: \"ollama\", \"openai\", or \"voyage\"\n",
    "        model: Model name\n",
    "        chunk_size: Chunk size (256, 512, 1024, 2048, 4096)\n",
    "        base_dir: Base directory for vector databases\n",
    "        collection_prefix: Prefix for collection names\n",
    "        \n",
    "    Returns:\n",
    "        Loaded ChromaDB vectorstore\n",
    "        \n",
    "    Example:\n",
    "        vectorstore = load_vectorstore(\"voyage\", \"voyage-finance-2\", 1024)\n",
    "    \"\"\"\n",
    "    # Construct paths\n",
    "    model_id = f\"{provider}_{model.replace('/', '_')}\"\n",
    "    db_path = os.path.join(base_dir, model_id)\n",
    "    collection_name = f\"{collection_prefix}{chunk_size}\"\n",
    "    \n",
    "    # Get embedding function\n",
    "    emb_fn = get_embedding_function(provider, model)\n",
    "    \n",
    "    # Load vectorstore\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=emb_fn,\n",
    "        persist_directory=db_path\n",
    "    )\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "print(\"✓ Vector store loading function defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4.4 Test Vector Store Loading\n",
    "# \n",
    "# Verify we can load a vector store and retrieve documents\n",
    "\n",
    "# %%\n",
    "def test_vectorstore_loading():\n",
    "    \"\"\"\n",
    "    Test loading a vector store and performing a sample retrieval.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING VECTOR STORE LOADING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test with a common configuration\n",
    "    test_provider = \"voyage\"\n",
    "    test_model = \"voyage-finance-2\"\n",
    "    test_chunk_size = 1024\n",
    "    \n",
    "    print(f\"\\nTest configuration:\")\n",
    "    print(f\"  Provider: {test_provider}\")\n",
    "    print(f\"  Model: {test_model}\")\n",
    "    print(f\"  Chunk size: {test_chunk_size}\")\n",
    "    \n",
    "    try:\n",
    "        # Load vectorstore\n",
    "        print(\"\\nLoading vectorstore...\")\n",
    "        vectorstore = load_vectorstore(test_provider, test_model, test_chunk_size)\n",
    "        \n",
    "        # Check collection\n",
    "        doc_count = vectorstore._collection.count()\n",
    "        print(f\"✓ Vectorstore loaded\")\n",
    "        print(f\"  Documents in collection: {doc_count:,}\")\n",
    "        \n",
    "        # Test retrieval\n",
    "        print(\"\\nTesting retrieval...\")\n",
    "        test_query = \"What was the revenue in 2018?\"\n",
    "        results = vectorstore.similarity_search(test_query, k=3)\n",
    "        \n",
    "        print(f\"✓ Retrieved {len(results)} documents\")\n",
    "        \n",
    "        # Show sample result\n",
    "        print(\"\\nSample retrieved document:\")\n",
    "        sample_doc = results[0]\n",
    "        metadata = extract_metadata_from_retrieved_doc(sample_doc)\n",
    "        \n",
    "        print(f\"  Doc name: {metadata['doc_name']}\")\n",
    "        print(f\"  Page number: {metadata['page_number']}\")\n",
    "        print(f\"  Chunk text (first 150 chars): {metadata['chunk_text'][:150]}...\")\n",
    "        print(f\"  Chunk text length: {len(metadata['chunk_text'])} characters\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"✓ VECTOR STORE TEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error during test: {e}\")\n",
    "        print(\"\\nPossible issues:\")\n",
    "        print(\"  1. Vector database doesn't exist for this configuration\")\n",
    "        print(\"  2. Path is incorrect\")\n",
    "        print(\"  3. ChromaDB version mismatch\")\n",
    "        print(f\"\\nExpected path: {VECTOR_DB_BASE_DIR}/{test_provider}_{test_model}/\")\n",
    "        return False\n",
    "\n",
    "# %%\n",
    "# Run test\n",
    "test_result = test_vectorstore_loading()\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 4 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ Metadata extraction functions defined\")\n",
    "print(\"  ✓ Embedding function factory defined\")\n",
    "print(\"  ✓ Vector store loading function defined\")\n",
    "print(\"  ✓ Vector store loading tested successfully\")\n",
    "print(\"  ✓ Ready to perform retrievals with chunk text extraction\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0211bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Page-based matching function defined\n",
      "✓ Page-based MRR calculation defined\n",
      "✓ Page-based metrics (recall, precision, F1) defined\n",
      "\n",
      "============================================================\n",
      "TESTING PAGE-BASED EVALUATION\n",
      "============================================================\n",
      "\n",
      "Test setup:\n",
      "  Evidence pages: [50, 75]\n",
      "  Retrieved pages: [10 (OTHER_DOC), 50, 49, 30, 75]\n",
      "  Chunk size: 1024 (tolerance = 1)\n",
      "\n",
      "--- Page-Based MRR ---\n",
      "  First match at rank: 2\n",
      "  MRR score: 0.5000\n",
      "  Expected: rank=2 (second doc matches page 50), MRR=0.5000\n",
      "\n",
      "--- Page-Based Recall, Precision, F1 ---\n",
      "  Recall: 1.0000\n",
      "  Precision: 0.6000\n",
      "  F1: 0.7500\n",
      "\n",
      "  Expected calculations:\n",
      "    Evidence found: {page 50, page 75} = 2/2 evidence items\n",
      "    Chunks matching: 3 chunks (pages 50, 49, 75) matched evidence\n",
      "    Recall = 2/2 = 1.0000\n",
      "    Precision = 3/5 = 0.6000\n",
      "    F1 = 2 × (1.0 × 0.6) / (1.0 + 0.6) = 0.7500\n",
      "\n",
      "--- Verification ---\n",
      "  ✓ MRR calculation correct\n",
      "  ✓ Recall, Precision, F1 calculations correct\n",
      "\n",
      "============================================================\n",
      "✓ PAGE-BASED EVALUATION TEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "✓ STEP 5 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Page-based matching function defined\n",
      "  ✓ Page-based MRR calculation defined\n",
      "  ✓ Page-based Recall, Precision, F1 calculation defined\n",
      "  ✓ All page-based functions tested successfully\n",
      "  ✓ Ready to implement text-based evaluation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 5: Helper Functions - Page-Based Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.1 Page-Based Matching Function\n",
    "# \n",
    "# This function checks if a retrieved chunk matches evidence based on page numbers\n",
    "\n",
    "# %%\n",
    "def check_page_match(\n",
    "    retrieved_doc: Dict, \n",
    "    evidence_list: List[Dict],\n",
    "    chunk_size: int = 512,\n",
    "    use_page_tolerance: bool = True\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if retrieved document matches any evidence based on PAGE NUMBERS.\n",
    "    \n",
    "    Uses chunk-size-aware page tolerance:\n",
    "    - Larger chunks can span multiple pages\n",
    "    - Retrieved page must be BEFORE or AT evidence page (within tolerance)\n",
    "    - Retrieved page AFTER evidence page = no match\n",
    "    \n",
    "    Page tolerance (when use_page_tolerance=True):\n",
    "    - chunk_size <= 512: tolerance = 0 (exact match)\n",
    "    - chunk_size 513-1024: tolerance = 1\n",
    "    - chunk_size 1025-2048: tolerance = 2\n",
    "    - chunk_size > 2048: tolerance = 2\n",
    "    \n",
    "    Args:\n",
    "        retrieved_doc: Dict with 'doc_name' and 'page_number' (1-indexed)\n",
    "        evidence_list: List of evidence dicts (page_number is 1-indexed)\n",
    "        chunk_size: Chunk size for tolerance calculation\n",
    "        use_page_tolerance: If True, use tolerance; if False, exact match only\n",
    "        \n",
    "    Returns:\n",
    "        True if match found, False otherwise\n",
    "        \n",
    "    Example:\n",
    "        Evidence on page 50, chunk_size=1024, tolerance=1:\n",
    "        - Page 49: MATCH (within tolerance, before evidence)\n",
    "        - Page 50: MATCH (exact match)\n",
    "        - Page 51: NO MATCH (after evidence page)\n",
    "    \"\"\"\n",
    "    retrieved_doc_name = retrieved_doc['doc_name']\n",
    "    retrieved_page = retrieved_doc['page_number']\n",
    "    \n",
    "    # Calculate page tolerance based on chunk size\n",
    "    if use_page_tolerance:\n",
    "        if chunk_size <= 512:\n",
    "            page_tolerance = 0\n",
    "        elif chunk_size <= 1024:\n",
    "            page_tolerance = 1\n",
    "        elif chunk_size <= 2048:\n",
    "            page_tolerance = 2\n",
    "        else:\n",
    "            page_tolerance = 2\n",
    "    else:\n",
    "        page_tolerance = 0  # Exact match only\n",
    "    \n",
    "    # Check against all evidence items\n",
    "    for evidence in evidence_list:\n",
    "        evidence_doc_name = evidence['doc_name']\n",
    "        evidence_page = evidence['page_number']  # Already 1-indexed from evidence_lookup\n",
    "        \n",
    "        # Check document name match\n",
    "        if retrieved_doc_name != evidence_doc_name:\n",
    "            continue\n",
    "        \n",
    "        # Check page match with tolerance\n",
    "        # Only match if retrieved page is BEFORE or AT evidence page\n",
    "        if retrieved_page <= evidence_page <= retrieved_page + page_tolerance:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "print(\"✓ Page-based matching function defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.2 Page-Based MRR Calculation\n",
    "# \n",
    "# Calculate Mean Reciprocal Rank based on page matching\n",
    "\n",
    "# %%\n",
    "def calculate_page_mrr_for_query(\n",
    "    retrieved_docs: List[Dict], \n",
    "    evidence_list: List[Dict],\n",
    "    chunk_size: int = 512,\n",
    "    use_page_tolerance: bool = True\n",
    ") -> Tuple[float, int]:\n",
    "    \"\"\"\n",
    "    Calculate PAGE-BASED MRR for a single query.\n",
    "    \n",
    "    Finds the rank of the first retrieved document that matches\n",
    "    any evidence based on page numbers.\n",
    "    \n",
    "    Args:\n",
    "        retrieved_docs: List of retrieved docs with 'doc_name', 'page_number'\n",
    "        evidence_list: List of evidence items from evidence_lookup\n",
    "        chunk_size: Chunk size for tolerance calculation\n",
    "        use_page_tolerance: If True, use chunk-size-aware tolerance\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (mrr_score, rank):\n",
    "        - mrr_score: 1/rank if found, 0 if not found\n",
    "        - rank: Position of first match (1-indexed), -1 if not found\n",
    "        \n",
    "    Example:\n",
    "        First match at position 3: mrr_score = 1/3 = 0.333, rank = 3\n",
    "        No match found: mrr_score = 0.0, rank = -1\n",
    "    \"\"\"\n",
    "    for rank, retrieved_doc in enumerate(retrieved_docs, start=1):\n",
    "        if check_page_match(retrieved_doc, evidence_list, chunk_size, use_page_tolerance):\n",
    "            mrr_score = 1.0 / rank\n",
    "            return mrr_score, rank\n",
    "    \n",
    "    # No match found\n",
    "    return 0.0, -1\n",
    "\n",
    "print(\"✓ Page-based MRR calculation defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.3 Page-Based Recall, Precision, and F1\n",
    "# \n",
    "# NEW: Calculate precision, recall, and F1 based on page matching\n",
    "\n",
    "# %%\n",
    "def calculate_page_metrics_for_query(\n",
    "    retrieved_docs: List[Dict],\n",
    "    evidence_list: List[Dict],\n",
    "    chunk_size: int = 512,\n",
    "    use_page_tolerance: bool = True\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculate PAGE-BASED Recall, Precision, and F1 for a single query.\n",
    "    \n",
    "    Recall: What proportion of evidence pages were found in retrieved chunks?\n",
    "        recall = (# evidence items matched) / (# total evidence items)\n",
    "    \n",
    "    Precision: What proportion of retrieved chunks matched evidence?\n",
    "        precision = (# retrieved chunks matching evidence) / (# total retrieved chunks)\n",
    "    \n",
    "    F1: Harmonic mean of precision and recall\n",
    "        f1 = 2 × (precision × recall) / (precision + recall)\n",
    "    \n",
    "    Args:\n",
    "        retrieved_docs: List of retrieved docs with 'doc_name', 'page_number'\n",
    "        evidence_list: List of evidence items from evidence_lookup\n",
    "        chunk_size: Chunk size for tolerance calculation\n",
    "        use_page_tolerance: If True, use chunk-size-aware tolerance\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (recall, precision, f1)\n",
    "        \n",
    "    Example:\n",
    "        Evidence items: 2 (pages 50, 75)\n",
    "        Retrieved: 20 chunks\n",
    "        Matches: Found page 50 in 2 chunks, page 75 in 1 chunk\n",
    "        \n",
    "        Evidence matched: {page 50, page 75} = 2 unique evidence\n",
    "        Chunks matching: 3 chunks matched at least one evidence\n",
    "        \n",
    "        Recall = 2/2 = 1.0 (found all evidence)\n",
    "        Precision = 3/20 = 0.15 (3 out of 20 chunks matched)\n",
    "        F1 = 2 × (1.0 × 0.15) / (1.0 + 0.15) = 0.26\n",
    "    \"\"\"\n",
    "    if len(evidence_list) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    if len(retrieved_docs) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    # Track which evidence items were found\n",
    "    evidence_found = set()  # Set of evidence indices that were matched\n",
    "    \n",
    "    # Track which retrieved chunks matched at least one evidence\n",
    "    chunks_matching = 0\n",
    "    \n",
    "    # Check each retrieved chunk\n",
    "    for retrieved_doc in retrieved_docs:\n",
    "        chunk_matched_any_evidence = False\n",
    "        \n",
    "        # Check against each evidence item\n",
    "        for evidence_idx, evidence in enumerate(evidence_list):\n",
    "            # Create single-item list for check_page_match\n",
    "            if check_page_match(retrieved_doc, [evidence], chunk_size, use_page_tolerance):\n",
    "                evidence_found.add(evidence_idx)\n",
    "                chunk_matched_any_evidence = True\n",
    "        \n",
    "        if chunk_matched_any_evidence:\n",
    "            chunks_matching += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    recall = len(evidence_found) / len(evidence_list)\n",
    "    precision = chunks_matching / len(retrieved_docs)\n",
    "    \n",
    "    # Calculate F1\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    \n",
    "    return recall, precision, f1\n",
    "\n",
    "print(\"✓ Page-based metrics (recall, precision, F1) defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5.4 Test Page-Based Evaluation Functions\n",
    "# \n",
    "# Verify all page-based metrics work correctly\n",
    "\n",
    "# %%\n",
    "def test_page_based_evaluation():\n",
    "    \"\"\"\n",
    "    Test page-based evaluation functions with sample data.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING PAGE-BASED EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create sample evidence (using 1-indexed pages)\n",
    "    evidence_list = [\n",
    "        {'doc_name': 'TEST_DOC', 'page_number': 50},\n",
    "        {'doc_name': 'TEST_DOC', 'page_number': 75}\n",
    "    ]\n",
    "    \n",
    "    # Create sample retrieved documents\n",
    "    retrieved_docs = [\n",
    "        {'doc_name': 'OTHER_DOC', 'page_number': 10},  # No match - wrong doc\n",
    "        {'doc_name': 'TEST_DOC', 'page_number': 50},   # MATCH - exact evidence page 50\n",
    "        {'doc_name': 'TEST_DOC', 'page_number': 49},   # MATCH - within tolerance of page 50\n",
    "        {'doc_name': 'TEST_DOC', 'page_number': 30},   # No match - not near evidence\n",
    "        {'doc_name': 'TEST_DOC', 'page_number': 75},   # MATCH - exact evidence page 75\n",
    "    ]\n",
    "    \n",
    "    chunk_size = 1024  # tolerance = 1\n",
    "    \n",
    "    print(\"\\nTest setup:\")\n",
    "    print(f\"  Evidence pages: [50, 75]\")\n",
    "    print(f\"  Retrieved pages: [10 (OTHER_DOC), 50, 49, 30, 75]\")\n",
    "    print(f\"  Chunk size: {chunk_size} (tolerance = 1)\")\n",
    "    \n",
    "    # Test MRR\n",
    "    print(\"\\n--- Page-Based MRR ---\")\n",
    "    mrr_score, rank = calculate_page_mrr_for_query(\n",
    "        retrieved_docs, evidence_list, chunk_size, use_page_tolerance=True\n",
    "    )\n",
    "    print(f\"  First match at rank: {rank}\")\n",
    "    print(f\"  MRR score: {mrr_score:.4f}\")\n",
    "    print(f\"  Expected: rank=2 (second doc matches page 50), MRR=0.5000\")\n",
    "    \n",
    "    # Test Recall, Precision, F1\n",
    "    print(\"\\n--- Page-Based Recall, Precision, F1 ---\")\n",
    "    recall, precision, f1 = calculate_page_metrics_for_query(\n",
    "        retrieved_docs, evidence_list, chunk_size, use_page_tolerance=True\n",
    "    )\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  F1: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\n  Expected calculations:\")\n",
    "    print(\"    Evidence found: {page 50, page 75} = 2/2 evidence items\")\n",
    "    print(\"    Chunks matching: 3 chunks (pages 50, 49, 75) matched evidence\")\n",
    "    print(\"    Recall = 2/2 = 1.0000\")\n",
    "    print(\"    Precision = 3/5 = 0.6000\")\n",
    "    print(\"    F1 = 2 × (1.0 × 0.6) / (1.0 + 0.6) = 0.7500\")\n",
    "    \n",
    "    # Verify results\n",
    "    print(\"\\n--- Verification ---\")\n",
    "    if rank == 2 and abs(mrr_score - 0.5) < 0.001:\n",
    "        print(\"  ✓ MRR calculation correct\")\n",
    "    else:\n",
    "        print(\"  ✗ MRR calculation incorrect\")\n",
    "    \n",
    "    if abs(recall - 1.0) < 0.001 and abs(precision - 0.6) < 0.001 and abs(f1 - 0.75) < 0.001:\n",
    "        print(\"  ✓ Recall, Precision, F1 calculations correct\")\n",
    "    else:\n",
    "        print(\"  ✗ Metrics calculation incorrect\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ PAGE-BASED EVALUATION TEST COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "# Run test\n",
    "test_page_based = test_page_based_evaluation()\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 5 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ Page-based matching function defined\")\n",
    "print(\"  ✓ Page-based MRR calculation defined\")\n",
    "print(\"  ✓ Page-based Recall, Precision, F1 calculation defined\")\n",
    "print(\"  ✓ All page-based functions tested successfully\")\n",
    "print(\"  ✓ Ready to implement text-based evaluation\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62267f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Chunk text preview formatting defined\n",
      "✓ Cosine similarity calculation defined\n",
      "✓ Text similarities calculation for chunk defined\n",
      "✓ Text-based metrics calculation defined\n",
      "\n",
      "============================================================\n",
      "TESTING TEXT-BASED EVALUATION\n",
      "============================================================\n",
      "\n",
      "Test query: financebench_id_03029\n",
      "  Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "\n",
      "  Evidence items: 1\n",
      "    1. 3M_2018_10K, page 60\n",
      "       Text (first 80 chars): Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated Statement of Cash Fl...\n",
      "\n",
      "  Retrieved chunks: 4\n",
      "    1. Exact evidence text\n",
      "    2. Paraphrased financial content\n",
      "    3. Different financial topic\n",
      "    4. Unrelated content\n",
      "\n",
      "  Calculating similarities with threshold=0.8...\n",
      "\n",
      "--- Text-Based Metrics ---\n",
      "  Text MRR: 0.0000\n",
      "  Text Rank: -1\n",
      "  Text Recall: 0.0000\n",
      "  Text Precision: 0.0000\n",
      "  Text F1: 0.0000\n",
      "\n",
      "--- Chunk Similarities ---\n",
      "\n",
      "  Chunk 1:\n",
      "    Text (first 60 chars): Table of Contents \n",
      "3M Company and Subsidiaries\n",
      "Consolidated ...\n",
      "    Evidence 0: 0.0000 ✗ NO MATCH\n",
      "\n",
      "  Chunk 2:\n",
      "    Text (first 60 chars): The company's capital spending was approximately $1.6 billio...\n",
      "    Evidence 0: 0.0000 ✗ NO MATCH\n",
      "\n",
      "  Chunk 3:\n",
      "    Text (first 60 chars): Revenue increased by 8% year-over-year driven by strong prod...\n",
      "    Evidence 0: 0.0000 ✗ NO MATCH\n",
      "\n",
      "  Chunk 4:\n",
      "    Text (first 60 chars): The weather forecast predicts sunny skies for the weekend....\n",
      "    Evidence 0: 0.0000 ✗ NO MATCH\n",
      "\n",
      "--- Expected Behavior ---\n",
      "  Chunk 1 (exact evidence): Should have similarity ~0.99, MATCH\n",
      "  Chunk 2 (paraphrased): Should have similarity ~0.7-0.8, likely MATCH\n",
      "  Chunk 3 (different topic): Should have similarity ~0.3-0.5, NO MATCH\n",
      "  Chunk 4 (unrelated): Should have similarity ~0.1-0.2, NO MATCH\n",
      "\n",
      "============================================================\n",
      "✓ TEXT-BASED EVALUATION TEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "✓ STEP 6 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Chunk text preview formatting defined\n",
      "  ✓ Cosine similarity calculation defined\n",
      "  ✓ Text similarities for chunks defined\n",
      "  ✓ Text-based MRR, Recall, Precision, F1 calculation defined\n",
      "  ✓ All text-based functions tested with real data\n",
      "  ✓ Similarity threshold: 0.8\n",
      "  ✓ Ready for retrieval functions\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 6: Helper Functions - Text-Based Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.1 Chunk Text Preview Formatting\n",
    "# \n",
    "# Format chunk text as \"first N chars...last N chars\" for JSON storage\n",
    "\n",
    "# %%\n",
    "def format_chunk_text_preview(\n",
    "    text: str,\n",
    "    prefix_chars: int = CHUNK_TEXT_PREFIX_CHARS,\n",
    "    suffix_chars: int = CHUNK_TEXT_SUFFIX_CHARS\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Format chunk text as abbreviated preview for JSON storage.\n",
    "    \n",
    "    Format: \"first N characters...last N characters\"\n",
    "    \n",
    "    This keeps JSON files manageable while providing enough context\n",
    "    to manually verify matches.\n",
    "    \n",
    "    Args:\n",
    "        text: Full chunk text\n",
    "        prefix_chars: Number of characters from start\n",
    "        suffix_chars: Number of characters from end\n",
    "        \n",
    "    Returns:\n",
    "        Formatted preview string\n",
    "        \n",
    "    Examples:\n",
    "        Short text (< prefix + suffix): Returns full text\n",
    "        Long text: \"Capital expenditures were $1,577...in fiscal year 2018.\"\n",
    "    \"\"\"\n",
    "    if len(text) <= prefix_chars + suffix_chars:\n",
    "        # Text is short enough, return as-is\n",
    "        return text\n",
    "    \n",
    "    # Extract prefix and suffix\n",
    "    prefix = text[:prefix_chars]\n",
    "    suffix = text[-suffix_chars:]\n",
    "    \n",
    "    # Format with ellipsis\n",
    "    return f\"{prefix}...{suffix}\"\n",
    "\n",
    "print(\"✓ Chunk text preview formatting defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.2 Cosine Similarity Calculation\n",
    "# \n",
    "# Calculate cosine similarity between chunk and evidence embeddings\n",
    "\n",
    "# %%\n",
    "def compute_cosine_similarity(\n",
    "    chunk_embedding: np.ndarray,\n",
    "    evidence_embedding: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two embeddings.\n",
    "    \n",
    "    Cosine similarity ranges from -1 to 1:\n",
    "    - 1.0: Identical/very similar\n",
    "    - 0.7-0.9: Strong similarity\n",
    "    - 0.5-0.7: Moderate similarity\n",
    "    - 0.0-0.5: Weak/no similarity\n",
    "    - Negative: Opposite meaning (rare in practice)\n",
    "    \n",
    "    Args:\n",
    "        chunk_embedding: Embedding vector for retrieved chunk (384-dim)\n",
    "        evidence_embedding: Embedding vector for evidence (384-dim)\n",
    "        \n",
    "    Returns:\n",
    "        Cosine similarity score (float)\n",
    "        \n",
    "    Note:\n",
    "        sklearn's cosine_similarity expects 2D arrays, so we reshape\n",
    "    \"\"\"\n",
    "    # Reshape to 2D arrays: (1, 384)\n",
    "    chunk_emb_2d = chunk_embedding.reshape(1, -1)\n",
    "    evidence_emb_2d = evidence_embedding.reshape(1, -1)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarity = cosine_similarity(chunk_emb_2d, evidence_emb_2d)[0][0]\n",
    "    \n",
    "    return float(similarity)\n",
    "\n",
    "print(\"✓ Cosine similarity calculation defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.3 Calculate Text Similarities for Retrieved Chunk\n",
    "# \n",
    "# For each retrieved chunk, calculate similarity with ALL evidence items\n",
    "\n",
    "# %%\n",
    "def calculate_text_similarities_for_chunk(\n",
    "    chunk_text: str,\n",
    "    chunk_doc_name: str,\n",
    "    evidence_items: List[Dict],\n",
    "    sbert_model: SentenceTransformer\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between a chunk and all evidence items.\n",
    "    \n",
    "    Args:\n",
    "        chunk_text: Text content of retrieved chunk\n",
    "        evidence_items: List of evidence items (each has 'embedding', 'doc_name', 'page_number')\n",
    "        sbert_model: Sentence-BERT model for encoding chunk\n",
    "        \n",
    "    Returns:\n",
    "        List of similarity results:\n",
    "        [\n",
    "            {\n",
    "                'evidence_index': 0,\n",
    "                'evidence_doc': 'DOC_NAME',\n",
    "                'evidence_page': 60,\n",
    "                'cosine_similarity': 0.7823\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "        \n",
    "    Note:\n",
    "        Evidence embeddings are pre-computed, so we only encode the chunk once\n",
    "    \"\"\"\n",
    "    # Encode chunk text\n",
    "    chunk_embedding = sbert_model.encode(chunk_text, convert_to_numpy=True)\n",
    "    \n",
    "    # Calculate similarity with each evidence\n",
    "    similarities = []\n",
    "    \n",
    "    for evidence_idx, evidence in enumerate(evidence_items):\n",
    "        # if doc names match, compute similarity; else 0.0\n",
    "        if chunk_doc_name == evidence['doc_name']:\n",
    "            similarity_score = compute_cosine_similarity(\n",
    "                chunk_embedding,\n",
    "                evidence['embedding']\n",
    "            )\n",
    "        else:\n",
    "            similarity_score = 0.0  # No similarity if different documents\n",
    "        \n",
    "        similarities.append({\n",
    "            'evidence_index': evidence_idx,\n",
    "            'evidence_doc': evidence['doc_name'],\n",
    "            'evidence_page': evidence['page_number'],\n",
    "            'cosine_similarity': similarity_score\n",
    "        })\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "print(\"✓ Text similarities calculation for chunk defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.4 Text-Based Metrics Calculation\n",
    "# \n",
    "# Calculate text-based MRR, Recall, Precision, and F1\n",
    "\n",
    "# %%\n",
    "def calculate_text_metrics_for_query(\n",
    "    retrieved_docs: List[Dict],\n",
    "    evidence_items: List[Dict],\n",
    "    sbert_model: SentenceTransformer,\n",
    "    threshold: float = TEXT_SIMILARITY_THRESHOLD\n",
    ") -> Tuple[float, int, float, float, float, List[List[Dict]]]:\n",
    "    \"\"\"\n",
    "    Calculate TEXT-BASED metrics for a single query.\n",
    "    \n",
    "    For each retrieved chunk:\n",
    "    1. Encode chunk text\n",
    "    2. Calculate similarity with all evidence\n",
    "    3. Determine if chunk matches (max_similarity >= threshold)\n",
    "    \n",
    "    Metrics:\n",
    "    - Text MRR: Rank of first chunk where max(similarities) >= threshold\n",
    "    - Text Recall: # evidence matched / # total evidence\n",
    "    - Text Precision: # chunks matching / # total chunks\n",
    "    - Text F1: Harmonic mean of precision and recall\n",
    "    \n",
    "    Args:\n",
    "        retrieved_docs: List of retrieved docs with 'chunk_text'\n",
    "        evidence_items: List of evidence items with 'embedding'\n",
    "        sbert_model: Sentence-BERT model for encoding chunks\n",
    "        threshold: Similarity threshold for matching (default: 0.7)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (text_mrr, text_rank, text_recall, text_precision, text_f1, all_similarities)\n",
    "        - text_mrr: MRR score (0.0 if no match)\n",
    "        - text_rank: Rank of first match (-1 if no match)\n",
    "        - text_recall: Proportion of evidence found\n",
    "        - text_precision: Proportion of chunks matching\n",
    "        - text_f1: F1 score\n",
    "        - all_similarities: List of similarity lists for each chunk (for JSON storage)\n",
    "        \n",
    "    Example:\n",
    "        Evidence: 2 items\n",
    "        Retrieved: 20 chunks\n",
    "        Chunk 5 has max_similarity=0.82 with evidence[0] (FIRST MATCH)\n",
    "        Chunk 12 has max_similarity=0.75 with evidence[1]\n",
    "        \n",
    "        text_mrr = 1/5 = 0.2\n",
    "        text_rank = 5\n",
    "        evidence_matched = {evidence[0], evidence[1]} = 2\n",
    "        chunks_matching = 2\n",
    "        text_recall = 2/2 = 1.0\n",
    "        text_precision = 2/20 = 0.1\n",
    "        text_f1 = 2 × (1.0 × 0.1) / (1.0 + 0.1) = 0.18\n",
    "    \"\"\"\n",
    "    if len(evidence_items) == 0 or len(retrieved_docs) == 0:\n",
    "        return 0.0, -1, 0.0, 0.0, 0.0, []\n",
    "    \n",
    "    # Track results\n",
    "    all_similarities = []  # Store all similarities for JSON\n",
    "    text_mrr = 0.0\n",
    "    text_rank = -1\n",
    "    evidence_found = set()  # Set of evidence indices matched\n",
    "    chunks_matching = 0\n",
    "    \n",
    "    # Process each retrieved chunk\n",
    "    for rank, retrieved_doc in enumerate(retrieved_docs, start=1):\n",
    "        chunk_text = retrieved_doc.get('chunk_text', '')\n",
    "        chunk_doc_name = retrieved_doc.get('doc_name', '')\n",
    "        \n",
    "        if not chunk_text:\n",
    "            # No text available\n",
    "            all_similarities.append([])\n",
    "            continue\n",
    "        \n",
    "        # Calculate similarities with all evidence\n",
    "        similarities = calculate_text_similarities_for_chunk(\n",
    "            chunk_text,\n",
    "            chunk_doc_name,\n",
    "            evidence_items,\n",
    "            sbert_model\n",
    "        )\n",
    "        \n",
    "        all_similarities.append(similarities)\n",
    "        \n",
    "        # Find maximum similarity\n",
    "        max_similarity = max([s['cosine_similarity'] for s in similarities])\n",
    "        \n",
    "        # Check if this chunk matches (above threshold)\n",
    "        chunk_matches_any_evidence = (max_similarity >= threshold)\n",
    "        \n",
    "        if chunk_matches_any_evidence:\n",
    "            chunks_matching += 1\n",
    "            \n",
    "            # Record which evidence items this chunk matched\n",
    "            for i, sim in enumerate(similarities):\n",
    "                if sim['cosine_similarity'] >= threshold:\n",
    "                    evidence_found.add(i)\n",
    "            \n",
    "            # Check for MRR (first match)\n",
    "            if text_mrr == 0.0:  # First match found\n",
    "                text_mrr = 1.0 / rank\n",
    "                text_rank = rank\n",
    "    \n",
    "    # Calculate recall and precision\n",
    "    text_recall = len(evidence_found) / len(evidence_items)\n",
    "    text_precision = chunks_matching / len(retrieved_docs)\n",
    "    \n",
    "    # Calculate F1\n",
    "    if text_precision + text_recall > 0:\n",
    "        text_f1 = 2 * (text_precision * text_recall) / (text_precision + text_recall)\n",
    "    else:\n",
    "        text_f1 = 0.0\n",
    "    \n",
    "    return text_mrr, text_rank, text_recall, text_precision, text_f1, all_similarities\n",
    "\n",
    "print(\"✓ Text-based metrics calculation defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6.5 Test Text-Based Evaluation Functions\n",
    "# \n",
    "# Verify text-based metrics work correctly with sample data\n",
    "\n",
    "# %%\n",
    "def test_text_based_evaluation():\n",
    "    \"\"\"\n",
    "    Test text-based evaluation functions with real FinanceBench data.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING TEXT-BASED EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get sample query\n",
    "    sample_record = dataset[0]\n",
    "    query_id = sample_record['financebench_id']\n",
    "    \n",
    "    print(f\"\\nTest query: {query_id}\")\n",
    "    print(f\"  Question: {sample_record['question'][:100]}...\")\n",
    "    \n",
    "    # Get evidence for this query\n",
    "    evidence_items = evidence_lookup[query_id]\n",
    "    print(f\"\\n  Evidence items: {len(evidence_items)}\")\n",
    "    for i, ev in enumerate(evidence_items):\n",
    "        print(f\"    {i+1}. {ev['doc_name']}, page {ev['page_number']}\")\n",
    "        print(f\"       Text (first 80 chars): {ev['evidence_text'][:80]}...\")\n",
    "    \n",
    "    # Create sample retrieved chunks\n",
    "    # Chunk 1: Contains exact evidence text (should have very high similarity)\n",
    "    chunk1_text = evidence_items[0]['evidence_text']\n",
    "    \n",
    "    # Chunk 2: Paraphrased financial content (moderate similarity)\n",
    "    chunk2_text = \"The company's capital spending was approximately $1.6 billion for the fiscal year.\"\n",
    "    \n",
    "    # Chunk 3: Different financial topic (low similarity)\n",
    "    chunk3_text = \"Revenue increased by 8% year-over-year driven by strong product sales.\"\n",
    "    \n",
    "    # Chunk 4: Unrelated content (very low similarity)\n",
    "    chunk4_text = \"The weather forecast predicts sunny skies for the weekend.\"\n",
    "    \n",
    "    retrieved_docs = [\n",
    "        {'chunk_text': chunk1_text},\n",
    "        {'chunk_text': chunk2_text},\n",
    "        {'chunk_text': chunk3_text},\n",
    "        {'chunk_text': chunk4_text}\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n  Retrieved chunks: 4\")\n",
    "    print(\"    1. Exact evidence text\")\n",
    "    print(\"    2. Paraphrased financial content\")\n",
    "    print(\"    3. Different financial topic\")\n",
    "    print(\"    4. Unrelated content\")\n",
    "    \n",
    "    # Calculate text-based metrics\n",
    "    print(f\"\\n  Calculating similarities with threshold={TEXT_SIMILARITY_THRESHOLD}...\")\n",
    "    \n",
    "    text_mrr, text_rank, text_recall, text_precision, text_f1, all_similarities = \\\n",
    "        calculate_text_metrics_for_query(\n",
    "            retrieved_docs,\n",
    "            evidence_items,\n",
    "            sbert_model,\n",
    "            threshold=TEXT_SIMILARITY_THRESHOLD\n",
    "        )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n--- Text-Based Metrics ---\")\n",
    "    print(f\"  Text MRR: {text_mrr:.4f}\")\n",
    "    print(f\"  Text Rank: {text_rank}\")\n",
    "    print(f\"  Text Recall: {text_recall:.4f}\")\n",
    "    print(f\"  Text Precision: {text_precision:.4f}\")\n",
    "    print(f\"  Text F1: {text_f1:.4f}\")\n",
    "    \n",
    "    # Show similarities for each chunk\n",
    "    print(\"\\n--- Chunk Similarities ---\")\n",
    "    for i, (chunk, similarities) in enumerate(zip(retrieved_docs, all_similarities), start=1):\n",
    "        print(f\"\\n  Chunk {i}:\")\n",
    "        print(f\"    Text (first 60 chars): {chunk['chunk_text'][:60]}...\")\n",
    "        for sim in similarities:\n",
    "            match_status = \"✓ MATCH\" if sim['cosine_similarity'] >= TEXT_SIMILARITY_THRESHOLD else \"✗ NO MATCH\"\n",
    "            print(f\"    Evidence {sim['evidence_index']}: {sim['cosine_similarity']:.4f} {match_status}\")\n",
    "    \n",
    "    # Expected behavior\n",
    "    print(\"\\n--- Expected Behavior ---\")\n",
    "    print(\"  Chunk 1 (exact evidence): Should have similarity ~0.99, MATCH\")\n",
    "    print(\"  Chunk 2 (paraphrased): Should have similarity ~0.7-0.8, likely MATCH\")\n",
    "    print(\"  Chunk 3 (different topic): Should have similarity ~0.3-0.5, NO MATCH\")\n",
    "    print(\"  Chunk 4 (unrelated): Should have similarity ~0.1-0.2, NO MATCH\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ TEXT-BASED EVALUATION TEST COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "# Run test\n",
    "test_text_based = test_text_based_evaluation()\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 6 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ Chunk text preview formatting defined\")\n",
    "print(\"  ✓ Cosine similarity calculation defined\")\n",
    "print(\"  ✓ Text similarities for chunks defined\")\n",
    "print(\"  ✓ Text-based MRR, Recall, Precision, F1 calculation defined\")\n",
    "print(\"  ✓ All text-based functions tested with real data\")\n",
    "print(f\"  ✓ Similarity threshold: {TEXT_SIMILARITY_THRESHOLD}\")\n",
    "print(\"  ✓ Ready for retrieval functions\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a169fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Global retrieval function defined\n",
      "✓ Single-document retrieval function defined\n",
      "\n",
      "============================================================\n",
      "TESTING RETRIEVAL FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "Test configuration:\n",
      "  Provider: voyage\n",
      "  Model: voyage-finance-2\n",
      "  Chunk size: 1024\n",
      "  K: 5\n",
      "\n",
      "Loading vectorstore...\n",
      "✓ Loaded (15,765 documents)\n",
      "\n",
      "Test query: What was the capital expenditure in 2018?\n",
      "\n",
      "------------------------------------------------------------\n",
      "TEST 1: Global Retrieval\n",
      "------------------------------------------------------------\n",
      "✓ Retrieved 5 documents\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "  1. Rank 1\n",
      "     Doc: 3M_2018_10K\n",
      "     Page: 39\n",
      "     Text (first 100 chars): Table of Contents \n",
      "Geographic Area Supplemental Information\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "  \n",
      " \n",
      "  \n",
      " \n",
      " Property...\n",
      "     Text length: 4356 chars\n",
      "\n",
      "  2. Rank 2\n",
      "     Doc: CVSHEALTH_2018_10K\n",
      "     Page: 280\n",
      "     Text (first 100 chars): Commentary - 2018 compared to 2017\n",
      "•\n",
      "Net cash provided by operating activities increased by $858 mil...\n",
      "     Text length: 2595 chars\n",
      "\n",
      "  3. Rank 3\n",
      "     Doc: 3M_2018_10K\n",
      "     Page: 47\n",
      "     Text (first 100 chars): Table of Contents \n",
      "Investments in property, plant and equipment enable growth across many diverse ma...\n",
      "     Text length: 3553 chars\n",
      "\n",
      "------------------------------------------------------------\n",
      "TEST 2: Single-Document Retrieval\n",
      "------------------------------------------------------------\n",
      "Target document: 3M_2018_10K\n",
      "✓ Retrieved 5 documents from target\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "  1. Rank 1\n",
      "     Doc: 3M_2018_10K\n",
      "     Page: 39\n",
      "     Text (first 100 chars): Table of Contents \n",
      "Geographic Area Supplemental Information\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      "  \n",
      " \n",
      "  \n",
      " \n",
      " Property...\n",
      "     Text length: 4356 chars\n",
      "\n",
      "  2. Rank 2\n",
      "     Doc: 3M_2018_10K\n",
      "     Page: 47\n",
      "     Text (first 100 chars): Table of Contents \n",
      "Investments in property, plant and equipment enable growth across many diverse ma...\n",
      "     Text length: 3553 chars\n",
      "\n",
      "  3. Rank 3\n",
      "     Doc: 3M_2018_10K\n",
      "     Page: 126\n",
      "     Text (first 100 chars): Table of Contents \n",
      "Business Segment Information\n",
      " \n",
      " \n",
      " \n",
      "Net Sales\n",
      " \n",
      "Operating Income\n",
      " \n",
      "(Millions)\n",
      "    ...\n",
      "     Text length: 3722 chars\n",
      "\n",
      "✓ All results correctly filtered to 3M_2018_10K\n",
      "\n",
      "============================================================\n",
      "✓ RETRIEVAL FUNCTIONS TEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "✓ STEP 7 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Global retrieval function defined\n",
      "  ✓ Single-document retrieval function defined\n",
      "  ✓ Both retrieval modes tested successfully\n",
      "  ✓ Chunk text extraction verified\n",
      "  ✓ Ready for main evaluation function\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 7: Retrieval Functions\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.1 Global Retrieval\n",
    "# \n",
    "# Retrieve documents from the entire corpus (all documents)\n",
    "\n",
    "# %%\n",
    "def retrieve_global(\n",
    "    vectorstore: Chroma,\n",
    "    query: str,\n",
    "    k: int\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieve documents globally (search all documents in the corpus).\n",
    "    \n",
    "    This mode searches across all 84 documents in FinanceBench.\n",
    "    Use case: Testing if the system can identify the correct document\n",
    "    among many documents.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore: Loaded ChromaDB vectorstore\n",
    "        query: Query text\n",
    "        k: Number of documents to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        List of retrieved documents with metadata:\n",
    "        [\n",
    "            {\n",
    "                'doc_name': 'DOC_NAME',\n",
    "                'page_number': 60,\n",
    "                'rank': 1,\n",
    "                'chunk_text': 'Full chunk text...'\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "        \n",
    "    Note:\n",
    "        Results are ordered by similarity score (most similar first)\n",
    "    \"\"\"\n",
    "    # Perform similarity search\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    \n",
    "    # Extract metadata and add rank\n",
    "    retrieved = []\n",
    "    for rank, doc in enumerate(results, start=1):\n",
    "        metadata = extract_metadata_from_retrieved_doc(doc)\n",
    "        metadata['rank'] = rank\n",
    "        retrieved.append(metadata)\n",
    "    \n",
    "    return retrieved\n",
    "\n",
    "print(\"✓ Global retrieval function defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.2 Single-Document Retrieval\n",
    "# \n",
    "# Retrieve documents filtered to a specific target document\n",
    "\n",
    "# %%\n",
    "def retrieve_single_doc(\n",
    "    vectorstore: Chroma,\n",
    "    query: str,\n",
    "    target_doc_name: str,\n",
    "    k: int\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieve documents filtered to a single target document.\n",
    "    \n",
    "    This mode assumes we already know which document contains the answer\n",
    "    and only searches within that document.\n",
    "    Use case: Testing passage retrieval accuracy when document is known.\n",
    "    \n",
    "    Implementation:\n",
    "        ChromaDB doesn't support substring matching in filters, so we:\n",
    "        1. Retrieve more documents (k × 10)\n",
    "        2. Filter to target document\n",
    "        3. Return top k from filtered results\n",
    "    \n",
    "    Args:\n",
    "        vectorstore: Loaded ChromaDB vectorstore\n",
    "        query: Query text\n",
    "        target_doc_name: Target document name (e.g., \"3M_2018_10K\")\n",
    "        k: Number of documents to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        List of retrieved documents from target document:\n",
    "        [\n",
    "            {\n",
    "                'doc_name': '3M_2018_10K',\n",
    "                'page_number': 47,\n",
    "                'rank': 1,\n",
    "                'chunk_text': 'Full chunk text...'\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "        \n",
    "    Note:\n",
    "        If target document has fewer than k chunks, returns all available chunks\n",
    "    \"\"\"\n",
    "    # Retrieve more documents to ensure we get enough from target doc\n",
    "    # Factor of 10 is usually sufficient\n",
    "    retrieve_count = k * 10\n",
    "    results = vectorstore.similarity_search(query, k=retrieve_count)\n",
    "    \n",
    "    # Filter to target document and extract metadata\n",
    "    filtered = []\n",
    "    for doc in results:\n",
    "        metadata = extract_metadata_from_retrieved_doc(doc)\n",
    "        if metadata['doc_name'] == target_doc_name:\n",
    "            filtered.append(metadata)\n",
    "            # Stop once we have enough\n",
    "            if len(filtered) >= k:\n",
    "                break\n",
    "    \n",
    "    # Take top k from filtered results\n",
    "    top_k_filtered = filtered[:k]\n",
    "    \n",
    "    # Add rank\n",
    "    for rank, doc_metadata in enumerate(top_k_filtered, start=1):\n",
    "        doc_metadata['rank'] = rank\n",
    "    \n",
    "    return top_k_filtered\n",
    "\n",
    "print(\"✓ Single-document retrieval function defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7.3 Test Retrieval Functions\n",
    "# \n",
    "# Verify both retrieval modes work correctly\n",
    "\n",
    "# %%\n",
    "def test_retrieval_functions():\n",
    "    \"\"\"\n",
    "    Test both global and single-document retrieval.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING RETRIEVAL FUNCTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test configuration\n",
    "    test_provider = \"voyage\"\n",
    "    test_model = \"voyage-finance-2\"\n",
    "    test_chunk_size = 1024\n",
    "    test_k = 5\n",
    "    \n",
    "    print(f\"\\nTest configuration:\")\n",
    "    print(f\"  Provider: {test_provider}\")\n",
    "    print(f\"  Model: {test_model}\")\n",
    "    print(f\"  Chunk size: {test_chunk_size}\")\n",
    "    print(f\"  K: {test_k}\")\n",
    "    \n",
    "    # Load vectorstore\n",
    "    print(\"\\nLoading vectorstore...\")\n",
    "    vectorstore = load_vectorstore(test_provider, test_model, test_chunk_size)\n",
    "    doc_count = vectorstore._collection.count()\n",
    "    print(f\"✓ Loaded ({doc_count:,} documents)\")\n",
    "    \n",
    "    # Test query\n",
    "    test_query = \"What was the capital expenditure in 2018?\"\n",
    "    print(f\"\\nTest query: {test_query}\")\n",
    "    \n",
    "    # Test 1: Global retrieval\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"TEST 1: Global Retrieval\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    global_results = retrieve_global(vectorstore, test_query, test_k)\n",
    "    \n",
    "    print(f\"✓ Retrieved {len(global_results)} documents\")\n",
    "    print(\"\\nTop 3 results:\")\n",
    "    for i, result in enumerate(global_results[:3], start=1):\n",
    "        print(f\"\\n  {i}. Rank {result['rank']}\")\n",
    "        print(f\"     Doc: {result['doc_name']}\")\n",
    "        print(f\"     Page: {result['page_number']}\")\n",
    "        print(f\"     Text (first 100 chars): {result['chunk_text'][:100]}...\")\n",
    "        print(f\"     Text length: {len(result['chunk_text'])} chars\")\n",
    "    \n",
    "    # Test 2: Single-document retrieval\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"TEST 2: Single-Document Retrieval\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    target_doc = \"3M_2018_10K\"\n",
    "    print(f\"Target document: {target_doc}\")\n",
    "    \n",
    "    singledoc_results = retrieve_single_doc(vectorstore, test_query, target_doc, test_k)\n",
    "    \n",
    "    print(f\"✓ Retrieved {len(singledoc_results)} documents from target\")\n",
    "    print(\"\\nTop 3 results:\")\n",
    "    for i, result in enumerate(singledoc_results[:3], start=1):\n",
    "        print(f\"\\n  {i}. Rank {result['rank']}\")\n",
    "        print(f\"     Doc: {result['doc_name']}\")\n",
    "        print(f\"     Page: {result['page_number']}\")\n",
    "        print(f\"     Text (first 100 chars): {result['chunk_text'][:100]}...\")\n",
    "        print(f\"     Text length: {len(result['chunk_text'])} chars\")\n",
    "    \n",
    "    # Verify all results are from target document\n",
    "    all_from_target = all(r['doc_name'] == target_doc for r in singledoc_results)\n",
    "    if all_from_target:\n",
    "        print(f\"\\n✓ All results correctly filtered to {target_doc}\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Some results not from target document!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ RETRIEVAL FUNCTIONS TEST COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# %%\n",
    "# Run test\n",
    "test_retrieval = test_retrieval_functions()\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 7 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ Global retrieval function defined\")\n",
    "print(\"  ✓ Single-document retrieval function defined\")\n",
    "print(\"  ✓ Both retrieval modes tested successfully\")\n",
    "print(\"  ✓ Chunk text extraction verified\")\n",
    "print(\"  ✓ Ready for main evaluation function\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf390a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ File management functions defined\n",
      "✓ Single configuration evaluation function defined\n",
      "\n",
      "============================================================\n",
      "✓ STEP 8 COMPLETE!\n",
      "============================================================\n",
      "  ✓ File management functions defined\n",
      "  ✓ Main evaluation function defined\n",
      "  ✓ Processes both page-based AND text-based metrics\n",
      "  ✓ Saves comprehensive results to JSON\n",
      "  ✓ Ready for batch evaluation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 8: Main Evaluation Function\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8.1 File Management Functions\n",
    "# \n",
    "# Helper functions for saving and checking results\n",
    "\n",
    "# %%\n",
    "# def get_output_filename(\n",
    "#     provider: str,\n",
    "#     model: str,\n",
    "#     chunk_size: int,\n",
    "#     k: int,\n",
    "#     mode: str\n",
    "# ) -> str:\n",
    "#     \"\"\"\n",
    "#     Generate standardized output filename.\n",
    "    \n",
    "#     Format: {provider}_{model}_chunk{size}_k{k}_{mode}.json\n",
    "    \n",
    "#     Example:\n",
    "#         voyage_voyage-finance-2_chunk1024_k20_global.json\n",
    "#     \"\"\"\n",
    "#     # Replace slashes in model name\n",
    "#     model_safe = model.replace('/', '_')\n",
    "#     filename = f\"{provider}_{model_safe}_chunk{chunk_size}_k{k}_{mode}.json\"\n",
    "#     return filename\n",
    "\n",
    "def get_output_filename(\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    k: int,\n",
    "    mode: str,\n",
    "    expansion_type: str = None,\n",
    "    expansion_subtype: str = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate standardized output filename.\n",
    "    \n",
    "    Format (without expansion): {provider}_{model}_chunk{size}_k{k}_{mode}.json\n",
    "    Format (with expansion): {expansion_type}_{expansion_subtype}_{provider}_{model}_chunk{size}_k{k}_{mode}.json\n",
    "    \n",
    "    Args:\n",
    "        provider: Embedding provider (e.g., \"voyage\", \"openai\", \"ollama\")\n",
    "        model: Model name (e.g., \"voyage-finance-2\")\n",
    "        chunk_size: Chunk size (e.g., 512, 1024)\n",
    "        k: Number of retrieved documents\n",
    "        mode: Retrieval mode (\"global\" or \"singledoc\")\n",
    "        expansion_type: Optional expansion type (e.g., \"hyde\", \"query2doc\")\n",
    "        expansion_subtype: Optional expansion subtype (e.g., \"basic\", \"cot\")\n",
    "        \n",
    "    Returns:\n",
    "        Formatted filename string\n",
    "        \n",
    "    Examples:\n",
    "        Without expansion:\n",
    "            voyage_voyage-finance-2_chunk1024_k20_global.json\n",
    "        \n",
    "        With expansion:\n",
    "            hyde_basic_voyage_voyage-finance-2_chunk1024_k20_global.json\n",
    "    \"\"\"\n",
    "    # Replace slashes in model name\n",
    "    model_safe = model.replace('/', '_')\n",
    "    \n",
    "    # Build filename\n",
    "    if expansion_type and expansion_subtype:\n",
    "        # With query expansion\n",
    "        filename = f\"{expansion_type}_{expansion_subtype}_{provider}_{model_safe}_chunk{chunk_size}_k{k}_{mode}.json\"\n",
    "    else:\n",
    "        # Without query expansion (baseline)\n",
    "        filename = f\"{provider}_{model_safe}_chunk{chunk_size}_k{k}_{mode}.json\"\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def check_if_results_exist(\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    k: int,\n",
    "    mode: str,\n",
    "    output_dir: str,\n",
    "    expansion_type: str = None,\n",
    "    expansion_subtype: str = None\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if results file already exists.\n",
    "    \n",
    "    Used to skip configurations that have already been evaluated.\n",
    "    \"\"\"\n",
    "    filename = get_output_filename(provider, model, chunk_size, k, mode, expansion_type, expansion_subtype)\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    return os.path.exists(filepath)\n",
    "\n",
    "\n",
    "def save_results(\n",
    "    results: List[Dict],\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    k: int,\n",
    "    mode: str,\n",
    "    output_dir: str,\n",
    "    expansion_type: str = None,\n",
    "    expansion_subtype: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Save evaluation results to JSON file.\n",
    "    \n",
    "    Args:\n",
    "        results: List of result dictionaries (queries + summary)\n",
    "        provider: Embedding provider\n",
    "        model: Model name\n",
    "        chunk_size: Chunk size\n",
    "        k: Number of retrieved documents\n",
    "        mode: \"global\" or \"singledoc\"\n",
    "        output_dir: Output directory\n",
    "    \"\"\"\n",
    "    filename = get_output_filename(provider, model, chunk_size, k, mode, expansion_type, expansion_subtype)\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"✓ File management functions defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8.2 Single Configuration Evaluation\n",
    "# \n",
    "# Evaluate a single configuration: (provider, model, chunk_size, k, mode)\n",
    "\n",
    "def evaluate_single_configuration(\n",
    "    dataset,\n",
    "    evidence_lookup: Dict,\n",
    "    sbert_model: SentenceTransformer,\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    k: int,\n",
    "    mode: str,\n",
    "    use_page_tolerance: bool = True,\n",
    "    text_similarity_threshold: float = TEXT_SIMILARITY_THRESHOLD,\n",
    "    output_dir: str = OUTPUT_DIR,\n",
    "    expansion_type: str = None,\n",
    "    expansion_subtype: str = None,\n",
    "    expanded_queries_dir: str = EXPANDED_QUERIES_DIR\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate a single configuration with BOTH page-based AND text-based metrics.\n",
    "    Now supports query expansion evaluation alongside baseline.\n",
    "    \n",
    "    This is the main evaluation function that:\n",
    "    1. Loads the vector store\n",
    "    2. Optionally loads expanded queries\n",
    "    3. For each query:\n",
    "       - Retrieves documents using BASELINE query\n",
    "       - Calculates BASELINE metrics (page + text)\n",
    "       - If expansion enabled: Retrieves documents using EXPANDED query\n",
    "       - If expansion enabled: Calculates EXPANDED metrics (page + text)\n",
    "       - Stores all results\n",
    "    4. Calculates average metrics for both baseline and expanded\n",
    "    5. Saves results to JSON\n",
    "    \n",
    "    Args:\n",
    "        dataset: FinanceBench dataset\n",
    "        evidence_lookup: Pre-computed evidence embeddings\n",
    "        sbert_model: Sentence-BERT model for text similarity\n",
    "        provider: \"ollama\", \"openai\", or \"voyage\"\n",
    "        model: Model name\n",
    "        chunk_size: Chunk size\n",
    "        k: Number of documents to retrieve\n",
    "        mode: \"global\" or \"singledoc\"\n",
    "        use_page_tolerance: If True, use chunk-size-aware page tolerance\n",
    "        text_similarity_threshold: Threshold for text-based matching\n",
    "        output_dir: Output directory for results\n",
    "        expansion_type: Optional expansion type (e.g., \"hyde\", \"query2doc\")\n",
    "        expansion_subtype: Optional expansion subtype (e.g., \"basic\", \"cot\")\n",
    "        expanded_queries_dir: Directory containing expanded queries JSON files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATING: {provider}/{model}\")\n",
    "    print(f\"  Chunk size: {chunk_size}\")\n",
    "    print(f\"  K: {k}\")\n",
    "    print(f\"  Mode: {mode}\")\n",
    "    if expansion_type and expansion_subtype:\n",
    "        print(f\"  Query Expansion: {expansion_type}/{expansion_subtype}\")\n",
    "    else:\n",
    "        print(f\"  Query Expansion: DISABLED (baseline only)\")\n",
    "    print(f\"  Page tolerance: {'ENABLED' if use_page_tolerance else 'DISABLED'}\")\n",
    "    print(f\"  Text similarity threshold: {text_similarity_threshold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check if already exists\n",
    "    if check_if_results_exist(provider, model, chunk_size, k, mode, output_dir, \n",
    "                              expansion_type, expansion_subtype):\n",
    "        print(\"✓ Results already exist - SKIPPING\")\n",
    "        return {'status': 'skipped'}\n",
    "    \n",
    "    # Load vectorstore\n",
    "    print(\"\\nLoading vectorstore...\")\n",
    "    try:\n",
    "        vectorstore = load_vectorstore(provider, model, chunk_size)\n",
    "        doc_count = vectorstore._collection.count()\n",
    "        print(f\"✓ Loaded ({doc_count:,} documents)\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load vectorstore: {e}\")\n",
    "        return {'status': 'failed', 'error': str(e)}\n",
    "    \n",
    "    # Load expanded queries if expansion is enabled\n",
    "    expanded_lookup = None\n",
    "    if expansion_type and expansion_subtype:\n",
    "        print(\"\\nLoading expanded queries...\")\n",
    "        try:\n",
    "            expanded_lookup = load_expanded_queries(\n",
    "                expanded_queries_dir,\n",
    "                expansion_type,\n",
    "                expansion_subtype\n",
    "            )\n",
    "            print(f\"✓ Loaded {len(expanded_lookup)} expanded queries\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load expanded queries: {e}\")\n",
    "            return {'status': 'failed', 'error': str(e)}\n",
    "    \n",
    "    # Initialize tracking lists for BASELINE\n",
    "    results = []\n",
    "    \n",
    "    # Baseline page-based metrics\n",
    "    page_mrr_scores = []\n",
    "    page_recall_scores = []\n",
    "    page_precision_scores = []\n",
    "    page_f1_scores = []\n",
    "    \n",
    "    # Baseline text-based metrics\n",
    "    text_mrr_scores = []\n",
    "    text_recall_scores = []\n",
    "    text_precision_scores = []\n",
    "    text_f1_scores = []\n",
    "    \n",
    "    # Initialize tracking lists for EXPANDED queries (if enabled)\n",
    "    if expanded_lookup:\n",
    "        # Expanded page-based metrics\n",
    "        expanded_page_mrr_scores = []\n",
    "        expanded_page_recall_scores = []\n",
    "        expanded_page_precision_scores = []\n",
    "        expanded_page_f1_scores = []\n",
    "        \n",
    "        # Expanded text-based metrics\n",
    "        expanded_text_mrr_scores = []\n",
    "        expanded_text_recall_scores = []\n",
    "        expanded_text_precision_scores = []\n",
    "        expanded_text_f1_scores = []\n",
    "    \n",
    "    # Process all queries\n",
    "    print(f\"\\nProcessing {len(dataset)} queries...\")\n",
    "    if expanded_lookup:\n",
    "        print(\"(Processing both baseline and expanded queries...)\")\n",
    "    print(\"(This may take a while due to text similarity calculations...)\")\n",
    "    \n",
    "    for record in tqdm(dataset, desc=\"Queries\"):\n",
    "        query_id = record['financebench_id']\n",
    "        query = record['question']  # Baseline query\n",
    "        doc_name = record['doc_name']\n",
    "        expanded_query_temp = \"None\"  # Placeholder for expanded query text\n",
    "        \n",
    "        # Get evidence for this query\n",
    "        evidence_items = evidence_lookup.get(query_id, [])\n",
    "        \n",
    "        if len(evidence_items) == 0:\n",
    "            # No evidence for this query, skip\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # ========================================\n",
    "            # BASELINE RETRIEVAL AND METRICS\n",
    "            # ========================================\n",
    "            \n",
    "            # STEP 1: RETRIEVE DOCUMENTS (BASELINE)\n",
    "            if mode == \"global\":\n",
    "                retrieved_docs_baseline = retrieve_global(vectorstore, query, k)\n",
    "            elif mode == \"singledoc\":\n",
    "                retrieved_docs_baseline = retrieve_single_doc(vectorstore, query, doc_name, k)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown mode: {mode}\")\n",
    "            \n",
    "            # STEP 2: CALCULATE PAGE-BASED METRICS (BASELINE)\n",
    "            page_mrr, page_rank = calculate_page_mrr_for_query(\n",
    "                retrieved_docs_baseline, evidence_items, chunk_size, use_page_tolerance\n",
    "            )\n",
    "            page_mrr_scores.append(page_mrr)\n",
    "            \n",
    "            page_recall, page_precision, page_f1 = calculate_page_metrics_for_query(\n",
    "                retrieved_docs_baseline, evidence_items, chunk_size, use_page_tolerance\n",
    "            )\n",
    "            page_recall_scores.append(page_recall)\n",
    "            page_precision_scores.append(page_precision)\n",
    "            page_f1_scores.append(page_f1)\n",
    "            \n",
    "            # STEP 3: CALCULATE TEXT-BASED METRICS (BASELINE)\n",
    "            text_mrr, text_rank, text_recall, text_precision, text_f1, all_similarities = \\\n",
    "                calculate_text_metrics_for_query(\n",
    "                    retrieved_docs_baseline,\n",
    "                    evidence_items,\n",
    "                    sbert_model,\n",
    "                    threshold=text_similarity_threshold\n",
    "                )\n",
    "            \n",
    "            text_mrr_scores.append(text_mrr)\n",
    "            text_recall_scores.append(text_recall)\n",
    "            text_precision_scores.append(text_precision)\n",
    "            text_f1_scores.append(text_f1)\n",
    "            \n",
    "            # ========================================\n",
    "            # EXPANDED QUERY RETRIEVAL AND METRICS (if enabled)\n",
    "            # ========================================\n",
    "            \n",
    "            if expanded_lookup and query_id in expanded_lookup:\n",
    "                # Get expanded query\n",
    "                expanded_query = expanded_lookup[query_id]['expanded_query']\n",
    "                expanded_query_temp = expanded_query  # For logging\n",
    "                \n",
    "                # STEP 1: RETRIEVE DOCUMENTS (EXPANDED)\n",
    "                if mode == \"global\":\n",
    "                    retrieved_docs_expanded = retrieve_global(vectorstore, expanded_query, k)\n",
    "                elif mode == \"singledoc\":\n",
    "                    retrieved_docs_expanded = retrieve_single_doc(vectorstore, expanded_query, doc_name, k)\n",
    "\n",
    "                # STEP 2: CALCULATE PAGE-BASED METRICS (EXPANDED)\n",
    "                expanded_page_mrr, expanded_page_rank = calculate_page_mrr_for_query(\n",
    "                    retrieved_docs_expanded, evidence_items, chunk_size, use_page_tolerance\n",
    "                )\n",
    "                expanded_page_mrr_scores.append(expanded_page_mrr)\n",
    "                \n",
    "                expanded_page_recall, expanded_page_precision, expanded_page_f1 = calculate_page_metrics_for_query(\n",
    "                    retrieved_docs_expanded, evidence_items, chunk_size, use_page_tolerance\n",
    "                )\n",
    "                expanded_page_recall_scores.append(expanded_page_recall)\n",
    "                expanded_page_precision_scores.append(expanded_page_precision)\n",
    "                expanded_page_f1_scores.append(expanded_page_f1)\n",
    "                \n",
    "                # STEP 3: CALCULATE TEXT-BASED METRICS (EXPANDED)\n",
    "                expanded_text_mrr, expanded_text_rank, expanded_text_recall, expanded_text_precision, expanded_text_f1, expanded_all_similarities = \\\n",
    "                    calculate_text_metrics_for_query(\n",
    "                        retrieved_docs_expanded,\n",
    "                        evidence_items,\n",
    "                        sbert_model,\n",
    "                        threshold=text_similarity_threshold\n",
    "                    )\n",
    "                \n",
    "                expanded_text_mrr_scores.append(expanded_text_mrr)\n",
    "                expanded_text_recall_scores.append(expanded_text_recall)\n",
    "                expanded_text_precision_scores.append(expanded_text_precision)\n",
    "                expanded_text_f1_scores.append(expanded_text_f1)\n",
    "            else:\n",
    "                # No expanded query available, use zeros\n",
    "                if expanded_lookup:\n",
    "                    expanded_page_mrr_scores.append(0.0)\n",
    "                    expanded_page_recall_scores.append(0.0)\n",
    "                    expanded_page_precision_scores.append(0.0)\n",
    "                    expanded_page_f1_scores.append(0.0)\n",
    "                    expanded_text_mrr_scores.append(0.0)\n",
    "                    expanded_text_recall_scores.append(0.0)\n",
    "                    expanded_text_precision_scores.append(0.0)\n",
    "                    expanded_text_f1_scores.append(0.0)\n",
    "                    retrieved_docs_expanded = []\n",
    "                    expanded_query = None\n",
    "                    expanded_page_mrr, expanded_page_rank = 0.0, -1\n",
    "                    expanded_text_mrr, expanded_text_rank = 0.0, -1\n",
    "                    expanded_all_similarities = []\n",
    "            \n",
    "            # ========================================\n",
    "            # FORMAT RESULTS FOR JSON\n",
    "            # ========================================\n",
    "            \n",
    "            # Format expected evidence\n",
    "            expected_evidence = [\n",
    "                {\n",
    "                    'doc_name': ev['doc_name'],\n",
    "                    'page_number': ev['page_number'],\n",
    "                    'evidence_text': ev['evidence_text'][:200] + '...' if len(ev['evidence_text']) > 200 else ev['evidence_text']\n",
    "                }\n",
    "                for ev in evidence_items\n",
    "            ]\n",
    "            \n",
    "            # Format retrieved docs (BASELINE) with text similarities\n",
    "            retrieved_docs_baseline_formatted = []\n",
    "            for i, doc in enumerate(retrieved_docs_baseline):\n",
    "                doc_formatted = {\n",
    "                    'doc_name': doc['doc_name'],\n",
    "                    'page_number': doc['page_number'],\n",
    "                    'rank': doc['rank'],\n",
    "                    'chunk_text': format_chunk_text_preview(doc['chunk_text']),\n",
    "                    'text_similarities': all_similarities[i] if i < len(all_similarities) else []\n",
    "                }\n",
    "                retrieved_docs_baseline_formatted.append(doc_formatted)\n",
    "            \n",
    "            # Store complete result\n",
    "            result = {\n",
    "                'query_id': query_id,\n",
    "                'query': query,  # Baseline query\n",
    "                'expanded_query': expanded_query_temp,\n",
    "                'expected_doc': doc_name,\n",
    "                'expected_evidence': expected_evidence,\n",
    "                'retrieved_docs': retrieved_docs_baseline_formatted,\n",
    "                \n",
    "                # Baseline page-based metrics\n",
    "                'page_mrr_score': page_mrr,\n",
    "                'page_rank': page_rank,\n",
    "                'page_recall': page_recall,\n",
    "                'page_precision': page_precision,\n",
    "                'page_f1': page_f1,\n",
    "                \n",
    "                # Baseline text-based metrics\n",
    "                'text_mrr_score': text_mrr,\n",
    "                'text_rank': text_rank,\n",
    "                'text_recall': text_recall,\n",
    "                'text_precision': text_precision,\n",
    "                'text_f1': text_f1\n",
    "            }\n",
    "            \n",
    "            # Add expanded query results if available\n",
    "            if expanded_lookup and query_id in expanded_lookup:\n",
    "                # Format retrieved docs (EXPANDED) with text similarities\n",
    "                retrieved_docs_expanded_formatted = []\n",
    "                for i, doc in enumerate(retrieved_docs_expanded):\n",
    "                    doc_formatted = {\n",
    "                        'doc_name': doc['doc_name'],\n",
    "                        'page_number': doc['page_number'],\n",
    "                        'rank': doc['rank'],\n",
    "                        'chunk_text': format_chunk_text_preview(doc['chunk_text']),\n",
    "                        'text_similarities': expanded_all_similarities[i] if i < len(expanded_all_similarities) else []\n",
    "                    }\n",
    "                    retrieved_docs_expanded_formatted.append(doc_formatted)\n",
    "                \n",
    "                result['expanded_query'] = expanded_query\n",
    "                result['expanded_retrieved_docs'] = retrieved_docs_expanded_formatted\n",
    "                \n",
    "                # Expanded page-based metrics\n",
    "                result['expanded_page_mrr_score'] = expanded_page_mrr\n",
    "                result['expanded_page_rank'] = expanded_page_rank\n",
    "                result['expanded_page_recall'] = expanded_page_recall\n",
    "                result['expanded_page_precision'] = expanded_page_precision\n",
    "                result['expanded_page_f1'] = expanded_page_f1\n",
    "                \n",
    "                # Expanded text-based metrics\n",
    "                result['expanded_text_mrr_score'] = expanded_text_mrr\n",
    "                result['expanded_text_rank'] = expanded_text_rank\n",
    "                result['expanded_text_recall'] = expanded_text_recall\n",
    "                result['expanded_text_precision'] = expanded_text_precision\n",
    "                result['expanded_text_f1'] = expanded_text_f1\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ Error processing query {query_id}: {e}\")\n",
    "            # Store error result\n",
    "            error_result = {\n",
    "                'query_id': query_id,\n",
    "                'query': query,\n",
    "                'error': str(e),\n",
    "                'page_mrr_score': 0.0,\n",
    "                'page_rank': -1,\n",
    "                'page_recall': 0.0,\n",
    "                'page_precision': 0.0,\n",
    "                'page_f1': 0.0,\n",
    "                'text_mrr_score': 0.0,\n",
    "                'text_rank': -1,\n",
    "                'text_recall': 0.0,\n",
    "                'text_precision': 0.0,\n",
    "                'text_f1': 0.0\n",
    "            }\n",
    "            \n",
    "            # Append zeros to baseline tracking lists\n",
    "            page_mrr_scores.append(0.0)\n",
    "            page_recall_scores.append(0.0)\n",
    "            page_precision_scores.append(0.0)\n",
    "            page_f1_scores.append(0.0)\n",
    "            text_mrr_scores.append(0.0)\n",
    "            text_recall_scores.append(0.0)\n",
    "            text_precision_scores.append(0.0)\n",
    "            text_f1_scores.append(0.0)\n",
    "            \n",
    "            # Append zeros to expanded tracking lists if enabled\n",
    "            if expanded_lookup:\n",
    "                error_result['expanded_query'] = expanded_lookup.get(query_id, {}).get('expanded_query', None)\n",
    "                error_result['expanded_page_mrr_score'] = 0.0\n",
    "                error_result['expanded_page_rank'] = -1\n",
    "                error_result['expanded_page_recall'] = 0.0\n",
    "                error_result['expanded_page_precision'] = 0.0\n",
    "                error_result['expanded_page_f1'] = 0.0\n",
    "                error_result['expanded_text_mrr_score'] = 0.0\n",
    "                error_result['expanded_text_rank'] = -1\n",
    "                error_result['expanded_text_recall'] = 0.0\n",
    "                error_result['expanded_text_precision'] = 0.0\n",
    "                error_result['expanded_text_f1'] = 0.0\n",
    "                \n",
    "                expanded_page_mrr_scores.append(0.0)\n",
    "                expanded_page_recall_scores.append(0.0)\n",
    "                expanded_page_precision_scores.append(0.0)\n",
    "                expanded_page_f1_scores.append(0.0)\n",
    "                expanded_text_mrr_scores.append(0.0)\n",
    "                expanded_text_recall_scores.append(0.0)\n",
    "                expanded_text_precision_scores.append(0.0)\n",
    "                expanded_text_f1_scores.append(0.0)\n",
    "            \n",
    "            results.append(error_result)\n",
    "    \n",
    "    # ========================================\n",
    "    # CALCULATE AVERAGE METRICS\n",
    "    # ========================================\n",
    "    \n",
    "    # Baseline averages\n",
    "    avg_page_mrr = sum(page_mrr_scores) / len(page_mrr_scores) if page_mrr_scores else 0.0\n",
    "    avg_page_recall = sum(page_recall_scores) / len(page_recall_scores) if page_recall_scores else 0.0\n",
    "    avg_page_precision = sum(page_precision_scores) / len(page_precision_scores) if page_precision_scores else 0.0\n",
    "    avg_page_f1 = sum(page_f1_scores) / len(page_f1_scores) if page_f1_scores else 0.0\n",
    "    \n",
    "    avg_text_mrr = sum(text_mrr_scores) / len(text_mrr_scores) if text_mrr_scores else 0.0\n",
    "    avg_text_recall = sum(text_recall_scores) / len(text_recall_scores) if text_recall_scores else 0.0\n",
    "    avg_text_precision = sum(text_precision_scores) / len(text_precision_scores) if text_precision_scores else 0.0\n",
    "    avg_text_f1 = sum(text_f1_scores) / len(text_f1_scores) if text_f1_scores else 0.0\n",
    "    \n",
    "    # Add summary to results\n",
    "    summary = {\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_size': chunk_size,\n",
    "        'k': k,\n",
    "        'mode': mode,\n",
    "        'use_page_tolerance': use_page_tolerance,\n",
    "        'text_similarity_threshold': text_similarity_threshold,\n",
    "        'total_queries': len(dataset),\n",
    "        \n",
    "        # Baseline page-based averages\n",
    "        'average_page_mrr': avg_page_mrr,\n",
    "        'average_page_recall': avg_page_recall,\n",
    "        'average_page_precision': avg_page_precision,\n",
    "        'average_page_f1': avg_page_f1,\n",
    "        \n",
    "        # Baseline text-based averages\n",
    "        'average_text_mrr': avg_text_mrr,\n",
    "        'average_text_recall': avg_text_recall,\n",
    "        'average_text_precision': avg_text_precision,\n",
    "        'average_text_f1': avg_text_f1\n",
    "    }\n",
    "    \n",
    "    # Add expanded query averages if enabled\n",
    "    if expanded_lookup:\n",
    "        avg_expanded_page_mrr = sum(expanded_page_mrr_scores) / len(expanded_page_mrr_scores) if expanded_page_mrr_scores else 0.0\n",
    "        avg_expanded_page_recall = sum(expanded_page_recall_scores) / len(expanded_page_recall_scores) if expanded_page_recall_scores else 0.0\n",
    "        avg_expanded_page_precision = sum(expanded_page_precision_scores) / len(expanded_page_precision_scores) if expanded_page_precision_scores else 0.0\n",
    "        avg_expanded_page_f1 = sum(expanded_page_f1_scores) / len(expanded_page_f1_scores) if expanded_page_f1_scores else 0.0\n",
    "        \n",
    "        avg_expanded_text_mrr = sum(expanded_text_mrr_scores) / len(expanded_text_mrr_scores) if expanded_text_mrr_scores else 0.0\n",
    "        avg_expanded_text_recall = sum(expanded_text_recall_scores) / len(expanded_text_recall_scores) if expanded_text_recall_scores else 0.0\n",
    "        avg_expanded_text_precision = sum(expanded_text_precision_scores) / len(expanded_text_precision_scores) if expanded_text_precision_scores else 0.0\n",
    "        avg_expanded_text_f1 = sum(expanded_text_f1_scores) / len(expanded_text_f1_scores) if expanded_text_f1_scores else 0.0\n",
    "        \n",
    "        summary['expansion_type'] = expansion_type\n",
    "        summary['expansion_subtype'] = expansion_subtype\n",
    "        \n",
    "        # Expanded page-based averages\n",
    "        summary['average_expanded_page_mrr'] = avg_expanded_page_mrr\n",
    "        summary['average_expanded_page_recall'] = avg_expanded_page_recall\n",
    "        summary['average_expanded_page_precision'] = avg_expanded_page_precision\n",
    "        summary['average_expanded_page_f1'] = avg_expanded_page_f1\n",
    "        \n",
    "        # Expanded text-based averages\n",
    "        summary['average_expanded_text_mrr'] = avg_expanded_text_mrr\n",
    "        summary['average_expanded_text_recall'] = avg_expanded_text_recall\n",
    "        summary['average_expanded_text_precision'] = avg_expanded_text_precision\n",
    "        summary['average_expanded_text_f1'] = avg_expanded_text_f1\n",
    "    \n",
    "    # Insert summary at the start of results\n",
    "    results.insert(0, {'summary': summary})\n",
    "    \n",
    "    # Save results\n",
    "    save_results(results, provider, model, chunk_size, k, mode, output_dir,\n",
    "                expansion_type, expansion_subtype)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"RESULTS SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"\\nBASELINE - Page-Based Metrics:\")\n",
    "    print(f\"  Average MRR:       {avg_page_mrr:.4f}\")\n",
    "    print(f\"  Average Recall:    {avg_page_recall:.4f}\")\n",
    "    print(f\"  Average Precision: {avg_page_precision:.4f}\")\n",
    "    print(f\"  Average F1:        {avg_page_f1:.4f}\")\n",
    "    print(\"\\nBASELINE - Text-Based Metrics:\")\n",
    "    print(f\"  Average MRR:       {avg_text_mrr:.4f}\")\n",
    "    print(f\"  Average Recall:    {avg_text_recall:.4f}\")\n",
    "    print(f\"  Average Precision: {avg_text_precision:.4f}\")\n",
    "    print(f\"  Average F1:        {avg_text_f1:.4f}\")\n",
    "    \n",
    "    if expanded_lookup:\n",
    "        print(f\"\\nEXPANDED ({expansion_type}/{expansion_subtype}) - Page-Based Metrics:\")\n",
    "        print(f\"  Average MRR:       {avg_expanded_page_mrr:.4f} (Δ {avg_expanded_page_mrr - avg_page_mrr:+.4f})\")\n",
    "        print(f\"  Average Recall:    {avg_expanded_page_recall:.4f} (Δ {avg_expanded_page_recall - avg_page_recall:+.4f})\")\n",
    "        print(f\"  Average Precision: {avg_expanded_page_precision:.4f} (Δ {avg_expanded_page_precision - avg_page_precision:+.4f})\")\n",
    "        print(f\"  Average F1:        {avg_expanded_page_f1:.4f} (Δ {avg_expanded_page_f1 - avg_page_f1:+.4f})\")\n",
    "        print(f\"\\nEXPANDED ({expansion_type}/{expansion_subtype}) - Text-Based Metrics:\")\n",
    "        print(f\"  Average MRR:       {avg_expanded_text_mrr:.4f} (Δ {avg_expanded_text_mrr - avg_text_mrr:+.4f})\")\n",
    "        print(f\"  Average Recall:    {avg_expanded_text_recall:.4f} (Δ {avg_expanded_text_recall - avg_text_recall:+.4f})\")\n",
    "        print(f\"  Average Precision: {avg_expanded_text_precision:.4f} (Δ {avg_expanded_text_precision - avg_text_precision:+.4f})\")\n",
    "        print(f\"  Average F1:        {avg_expanded_text_f1:.4f} (Δ {avg_expanded_text_f1 - avg_text_f1:+.4f})\")\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return_dict = {\n",
    "        'status': 'completed',\n",
    "        'average_page_mrr': avg_page_mrr,\n",
    "        'average_page_recall': avg_page_recall,\n",
    "        'average_page_precision': avg_page_precision,\n",
    "        'average_page_f1': avg_page_f1,\n",
    "        'average_text_mrr': avg_text_mrr,\n",
    "        'average_text_recall': avg_text_recall,\n",
    "        'average_text_precision': avg_text_precision,\n",
    "        'average_text_f1': avg_text_f1,\n",
    "        'total_queries': len(dataset)\n",
    "    }\n",
    "    \n",
    "    if expanded_lookup:\n",
    "        return_dict['average_expanded_page_mrr'] = avg_expanded_page_mrr\n",
    "        return_dict['average_expanded_page_recall'] = avg_expanded_page_recall\n",
    "        return_dict['average_expanded_page_precision'] = avg_expanded_page_precision\n",
    "        return_dict['average_expanded_page_f1'] = avg_expanded_page_f1\n",
    "        return_dict['average_expanded_text_mrr'] = avg_expanded_text_mrr\n",
    "        return_dict['average_expanded_text_recall'] = avg_expanded_text_recall\n",
    "        return_dict['average_expanded_text_precision'] = avg_expanded_text_precision\n",
    "        return_dict['average_expanded_text_f1'] = avg_expanded_text_f1\n",
    "    \n",
    "    return return_dict\n",
    "\n",
    "\n",
    "print(\"✓ Single configuration evaluation function defined\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 8 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ File management functions defined\")\n",
    "print(\"  ✓ Main evaluation function defined\")\n",
    "print(\"  ✓ Processes both page-based AND text-based metrics\")\n",
    "print(\"  ✓ Saves comprehensive results to JSON\")\n",
    "print(\"  ✓ Ready for batch evaluation\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252640ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch evaluation function defined\n",
      "✓ Results analysis helper defined\n",
      "✓ File listing helper defined\n",
      "\n",
      "============================================================\n",
      "✓ STEP 9 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Batch evaluation function defined\n",
      "  ✓ Results display helper defined\n",
      "  ✓ File listing helper defined\n",
      "  ✓ Ready for configuration and execution\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 9: Batch Evaluation Function\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def evaluate_multiple_configurations(\n",
    "    dataset,\n",
    "    evidence_lookup: Dict,\n",
    "    sbert_model: SentenceTransformer,\n",
    "    configurations: List[Dict],\n",
    "    k_values: List[int],\n",
    "    modes: List[str],\n",
    "    use_page_tolerance: bool = True,\n",
    "    text_similarity_threshold: float = TEXT_SIMILARITY_THRESHOLD,\n",
    "    output_dir: str = OUTPUT_DIR,\n",
    "    expanded_queries_dir: str = \"../../query_enhancement_set\"\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate multiple configurations in batch.\n",
    "    \n",
    "    This function iterates through all combinations of:\n",
    "    - Configurations (provider, model, chunk_sizes, expansion_type, expansion_subtype)\n",
    "    - K values (number of documents to retrieve)\n",
    "    - Modes (global, singledoc)\n",
    "    \n",
    "    And evaluates each combination using evaluate_single_configuration().\n",
    "    \n",
    "    Args:\n",
    "        dataset: FinanceBench dataset\n",
    "        evidence_lookup: Pre-computed evidence embeddings\n",
    "        sbert_model: Sentence-BERT model\n",
    "        configurations: List of configuration dicts\n",
    "        k_values: List of k values to test\n",
    "        modes: List of modes [\"global\", \"singledoc\"]\n",
    "        use_page_tolerance: If True, use chunk-size-aware tolerance\n",
    "        text_similarity_threshold: Threshold for text-based matching\n",
    "        output_dir: Output directory\n",
    "        expanded_queries_dir: Directory containing expanded queries JSON files\n",
    "        \n",
    "    Returns:\n",
    "        Summary dictionary with all results\n",
    "        \n",
    "    Example configurations:\n",
    "        [\n",
    "            {\n",
    "                'provider': 'voyage',\n",
    "                'model': 'voyage-finance-2',\n",
    "                'chunk_sizes': [512, 1024, 2048]\n",
    "            },\n",
    "            {\n",
    "                'expansion_type': 'hyde',\n",
    "                'expansion_subtype': 'basic',\n",
    "                'provider': 'voyage',\n",
    "                'model': 'voyage-finance-2',\n",
    "                'chunk_sizes': [512, 1024]\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BATCH EVALUATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Configurations: {len(configurations)}\")\n",
    "    print(f\"K values: {k_values}\")\n",
    "    print(f\"Modes: {modes}\")\n",
    "    print(f\"Page tolerance: {'ENABLED' if use_page_tolerance else 'DISABLED'}\")\n",
    "    print(f\"Text similarity threshold: {text_similarity_threshold}\")\n",
    "    \n",
    "    # Calculate total runs\n",
    "    total_runs = 0\n",
    "    for config in configurations:\n",
    "        total_runs += len(config['chunk_sizes']) * len(k_values) * len(modes)\n",
    "    \n",
    "    print(f\"Total evaluation runs: {total_runs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Track results\n",
    "    all_results = []\n",
    "    completed = 0\n",
    "    skipped = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Start time\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate through all combinations\n",
    "    for config in configurations:\n",
    "        provider = config['provider']\n",
    "        model = config['model']\n",
    "        chunk_sizes = config['chunk_sizes']\n",
    "        \n",
    "        # Extract expansion parameters (optional)\n",
    "        expansion_type = config.get('expansion_type', None)\n",
    "        expansion_subtype = config.get('expansion_subtype', None)\n",
    "        \n",
    "        for chunk_size in chunk_sizes:\n",
    "            for k in k_values:\n",
    "                for mode in modes:\n",
    "                    print(f\"\\n{'#'*60}\")\n",
    "                    print(f\"CONFIGURATION {completed + skipped + failed + 1}/{total_runs}\")\n",
    "                    print(f\"{'#'*60}\")\n",
    "                    \n",
    "                    result = evaluate_single_configuration(\n",
    "                        dataset=dataset,\n",
    "                        evidence_lookup=evidence_lookup,\n",
    "                        sbert_model=sbert_model,\n",
    "                        provider=provider,\n",
    "                        model=model,\n",
    "                        chunk_size=chunk_size,\n",
    "                        k=k,\n",
    "                        mode=mode,\n",
    "                        use_page_tolerance=use_page_tolerance,\n",
    "                        text_similarity_threshold=text_similarity_threshold,\n",
    "                        output_dir=output_dir,\n",
    "                        expansion_type=expansion_type,\n",
    "                        expansion_subtype=expansion_subtype,\n",
    "                        expanded_queries_dir=expanded_queries_dir\n",
    "                    )\n",
    "                    \n",
    "                    all_results.append({\n",
    "                        'provider': provider,\n",
    "                        'model': model,\n",
    "                        'chunk_size': chunk_size,\n",
    "                        'k': k,\n",
    "                        'mode': mode,\n",
    "                        'expansion_type': expansion_type,\n",
    "                        'expansion_subtype': expansion_subtype,\n",
    "                        'result': result\n",
    "                    })\n",
    "                    \n",
    "                    if result['status'] == 'completed':\n",
    "                        completed += 1\n",
    "                    elif result['status'] == 'skipped':\n",
    "                        skipped += 1\n",
    "                    else:\n",
    "                        failed += 1\n",
    "    \n",
    "    # End time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BATCH EVALUATION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total runs: {total_runs}\")\n",
    "    print(f\"Completed: {completed}\")\n",
    "    print(f\"Skipped: {skipped}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    print(f\"Total time: {elapsed_time/60:.2f} minutes\")\n",
    "    print(f\"Average time per run: {elapsed_time/total_runs:.2f} seconds\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return {\n",
    "        'total_runs': total_runs,\n",
    "        'completed': completed,\n",
    "        'skipped': skipped,\n",
    "        'failed': failed,\n",
    "        'elapsed_time': elapsed_time,\n",
    "        'results': all_results\n",
    "    }\n",
    "\n",
    "print(\"✓ Batch evaluation function defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9.2 Results Analysis Helper\n",
    "# \n",
    "# Helper function to display results in a readable format\n",
    "\n",
    "# %%\n",
    "def display_batch_results(summary: Dict):\n",
    "    \"\"\"\n",
    "    Display batch evaluation results in a readable table format.\n",
    "    \n",
    "    Shows both page-based and text-based metrics for baseline and expanded queries.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"DETAILED RESULTS - ALL CONFIGURATIONS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Group results by status\n",
    "    completed_results = [r for r in summary['results'] if r['result']['status'] == 'completed']\n",
    "    skipped_results = [r for r in summary['results'] if r['result']['status'] == 'skipped']\n",
    "    failed_results = [r for r in summary['results'] if r['result']['status'] == 'failed']\n",
    "    \n",
    "    if completed_results:\n",
    "        print(\"\\n\" + \"-\"*100)\n",
    "        print(f\"COMPLETED EVALUATIONS ({len(completed_results)})\")\n",
    "        print(\"-\"*100)\n",
    "        \n",
    "        # Separate baseline and expanded results\n",
    "        baseline_results = [r for r in completed_results if r.get('expansion_type') is None]\n",
    "        expanded_results = [r for r in completed_results if r.get('expansion_type') is not None]\n",
    "        \n",
    "        # ========================================\n",
    "        # BASELINE RESULTS\n",
    "        # ========================================\n",
    "        if baseline_results:\n",
    "            print(\"\\n\" + \"=\"*100)\n",
    "            print(\"BASELINE RESULTS (No Query Expansion)\")\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "            # Table header\n",
    "            print(f\"\\n{'Config':<45} {'Page Metrics':<25} {'Text Metrics':<25}\")\n",
    "            print(f\"{'-'*45} {'-'*25} {'-'*25}\")\n",
    "            print(f\"{'Provider/Model/Chunk/K/Mode':<45} {'MRR':>6} {'Rec':>6} {'Prec':>6} {'F1':>6} {'MRR':>6} {'Rec':>6} {'Prec':>6} {'F1':>6}\")\n",
    "            print(\"-\"*95)\n",
    "            \n",
    "            # Sort by provider, model, chunk_size, k, mode\n",
    "            sorted_baseline = sorted(\n",
    "                baseline_results,\n",
    "                key=lambda x: (x['provider'], x['model'], x['chunk_size'], x['k'], x['mode'])\n",
    "            )\n",
    "            \n",
    "            for r in sorted_baseline:\n",
    "                config_str = f\"{r['provider']}/{r['model']}/ch{r['chunk_size']}/k{r['k']}/{r['mode']}\"\n",
    "                result = r['result']\n",
    "                \n",
    "                # Page-based metrics\n",
    "                page_mrr = result['average_page_mrr']\n",
    "                page_rec = result['average_page_recall']\n",
    "                page_prec = result['average_page_precision']\n",
    "                page_f1 = result['average_page_f1']\n",
    "                \n",
    "                # Text-based metrics\n",
    "                text_mrr = result['average_text_mrr']\n",
    "                text_rec = result['average_text_recall']\n",
    "                text_prec = result['average_text_precision']\n",
    "                text_f1 = result['average_text_f1']\n",
    "                \n",
    "                print(f\"{config_str:<45} {page_mrr:>6.3f} {page_rec:>6.3f} {page_prec:>6.3f} {page_f1:>6.3f} {text_mrr:>6.3f} {text_rec:>6.3f} {text_prec:>6.3f} {text_f1:>6.3f}\")\n",
    "        \n",
    "        # ========================================\n",
    "        # EXPANDED QUERY RESULTS\n",
    "        # ========================================\n",
    "        if expanded_results:\n",
    "            print(\"\\n\" + \"=\"*100)\n",
    "            print(\"EXPANDED QUERY RESULTS\")\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "            # Group by expansion type\n",
    "            expansion_groups = {}\n",
    "            for r in expanded_results:\n",
    "                exp_key = f\"{r['expansion_type']}/{r['expansion_subtype']}\"\n",
    "                if exp_key not in expansion_groups:\n",
    "                    expansion_groups[exp_key] = []\n",
    "                expansion_groups[exp_key].append(r)\n",
    "            \n",
    "            # Display each expansion type group\n",
    "            for exp_key, exp_results in expansion_groups.items():\n",
    "                print(f\"\\n{'='*100}\")\n",
    "                print(f\"EXPANSION: {exp_key}\")\n",
    "                print(f\"{'='*100}\")\n",
    "                \n",
    "                # Table header with baseline and expanded columns\n",
    "                print(f\"\\n{'Config':<40} {'BASELINE Page':<20} {'EXPANDED Page':<20} {'BASELINE Text':<20} {'EXPANDED Text':<20}\")\n",
    "                print(f\"{'-'*40} {'-'*20} {'-'*20} {'-'*20} {'-'*20}\")\n",
    "                print(f\"{'Provider/Model/Ch/K/Mode':<40} {'MRR':>6} {'F1':>6} {'Δ':>6} {'MRR':>6} {'F1':>6} {'Δ':>6} {'MRR':>6} {'F1':>6} {'Δ':>6} {'MRR':>6} {'F1':>6} {'Δ':>6}\")\n",
    "                print(\"-\"*120)\n",
    "                \n",
    "                # Sort by provider, model, chunk_size, k, mode\n",
    "                sorted_expanded = sorted(\n",
    "                    exp_results,\n",
    "                    key=lambda x: (x['provider'], x['model'], x['chunk_size'], x['k'], x['mode'])\n",
    "                )\n",
    "                \n",
    "                for r in sorted_expanded:\n",
    "                    config_str = f\"{r['provider']}/{r['model']}/ch{r['chunk_size']}/k{r['k']}/{r['mode']}\"\n",
    "                    result = r['result']\n",
    "                    \n",
    "                    # Baseline metrics\n",
    "                    base_page_mrr = result['average_page_mrr']\n",
    "                    base_page_f1 = result['average_page_f1']\n",
    "                    base_text_mrr = result['average_text_mrr']\n",
    "                    base_text_f1 = result['average_text_f1']\n",
    "                    \n",
    "                    # Expanded metrics\n",
    "                    exp_page_mrr = result.get('average_expanded_page_mrr', 0.0)\n",
    "                    exp_page_f1 = result.get('average_expanded_page_f1', 0.0)\n",
    "                    exp_text_mrr = result.get('average_expanded_text_mrr', 0.0)\n",
    "                    exp_text_f1 = result.get('average_expanded_text_f1', 0.0)\n",
    "                    \n",
    "                    # Calculate deltas\n",
    "                    delta_page_mrr = exp_page_mrr - base_page_mrr\n",
    "                    delta_page_f1 = exp_page_f1 - base_page_f1\n",
    "                    delta_text_mrr = exp_text_mrr - base_text_mrr\n",
    "                    delta_text_f1 = exp_text_f1 - base_text_f1\n",
    "                    \n",
    "                    print(f\"{config_str:<40} \"\n",
    "                          f\"{base_page_mrr:>6.3f} {base_page_f1:>6.3f} {delta_page_mrr:>+6.3f} \"\n",
    "                          f\"{exp_page_mrr:>6.3f} {exp_page_f1:>6.3f} {delta_page_f1:>+6.3f} \"\n",
    "                          f\"{base_text_mrr:>6.3f} {base_text_f1:>6.3f} {delta_text_mrr:>+6.3f} \"\n",
    "                          f\"{exp_text_mrr:>6.3f} {exp_text_f1:>6.3f} {delta_text_f1:>+6.3f}\")\n",
    "                \n",
    "                # Summary statistics for this expansion type\n",
    "                print(f\"\\n{'-'*100}\")\n",
    "                print(f\"SUMMARY for {exp_key}:\")\n",
    "                avg_delta_page_mrr = sum(r['result'].get('average_expanded_page_mrr', 0.0) - r['result']['average_page_mrr'] for r in sorted_expanded) / len(sorted_expanded)\n",
    "                avg_delta_text_mrr = sum(r['result'].get('average_expanded_text_mrr', 0.0) - r['result']['average_text_mrr'] for r in sorted_expanded) / len(sorted_expanded)\n",
    "                print(f\"  Average Page MRR improvement: {avg_delta_page_mrr:+.4f}\")\n",
    "                print(f\"  Average Text MRR improvement: {avg_delta_text_mrr:+.4f}\")\n",
    "                \n",
    "                # Count improvements/degradations\n",
    "                improved_page = sum(1 for r in sorted_expanded if r['result'].get('average_expanded_page_mrr', 0.0) > r['result']['average_page_mrr'])\n",
    "                improved_text = sum(1 for r in sorted_expanded if r['result'].get('average_expanded_text_mrr', 0.0) > r['result']['average_text_mrr'])\n",
    "                print(f\"  Configurations improved (Page MRR): {improved_page}/{len(sorted_expanded)}\")\n",
    "                print(f\"  Configurations improved (Text MRR): {improved_text}/{len(sorted_expanded)}\")\n",
    "    \n",
    "    if skipped_results:\n",
    "        print(\"\\n\" + \"-\"*100)\n",
    "        print(f\"SKIPPED EVALUATIONS ({len(skipped_results)})\")\n",
    "        print(\"-\"*100)\n",
    "        for r in skipped_results:\n",
    "            exp_str = f\"{r['expansion_type']}/{r['expansion_subtype']}\" if r.get('expansion_type') else \"baseline\"\n",
    "            config_str = f\"{exp_str} - {r['provider']}/{r['model']}/chunk{r['chunk_size']}/k{r['k']}/{r['mode']}\"\n",
    "            print(f\"  - {config_str}\")\n",
    "    \n",
    "    if failed_results:\n",
    "        print(\"\\n\" + \"-\"*100)\n",
    "        print(f\"FAILED EVALUATIONS ({len(failed_results)})\")\n",
    "        print(\"-\"*100)\n",
    "        for r in failed_results:\n",
    "            exp_str = f\"{r['expansion_type']}/{r['expansion_subtype']}\" if r.get('expansion_type') else \"baseline\"\n",
    "            config_str = f\"{exp_str} - {r['provider']}/{r['model']}/chunk{r['chunk_size']}/k{r['k']}/{r['mode']}\"\n",
    "            error = r['result'].get('error', 'Unknown error')\n",
    "            print(f\"  - {config_str}: {error}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "print(\"✓ Results analysis helper defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9.3 List Generated Files\n",
    "# \n",
    "# Helper to show all generated JSON files\n",
    "\n",
    "# %%\n",
    "def list_generated_files(output_dir: str = OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    List all generated JSON files with their sizes.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATED FILES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    output_path = Path(output_dir)\n",
    "    json_files = sorted(output_path.glob(\"*.json\"))\n",
    "    \n",
    "    print(f\"\\nTotal JSON files: {len(json_files)}\")\n",
    "    print(f\"Location: {output_dir}\\n\")\n",
    "    \n",
    "    if json_files:\n",
    "        # Calculate total size\n",
    "        total_size = sum(f.stat().st_size for f in json_files)\n",
    "        \n",
    "        print(f\"{'Filename':<60} {'Size':>10}\")\n",
    "        print(\"-\"*72)\n",
    "        \n",
    "        for filepath in json_files:\n",
    "            file_size = filepath.stat().st_size / 1024  # KB\n",
    "            print(f\"{filepath.name:<60} {file_size:>8.1f} KB\")\n",
    "        \n",
    "        print(\"-\"*72)\n",
    "        print(f\"{'TOTAL':<60} {total_size/1024:>8.1f} KB\")\n",
    "    else:\n",
    "        print(\"No JSON files found.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"✓ File listing helper defined\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 9 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ Batch evaluation function defined\")\n",
    "print(\"  ✓ Results display helper defined\")\n",
    "print(\"  ✓ File listing helper defined\")\n",
    "print(\"  ✓ Ready for configuration and execution\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "371d17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configurations defined\n",
      "✓ Evaluation parameters defined\n",
      "\n",
      "============================================================\n",
      "EVALUATION PLAN\n",
      "============================================================\n",
      "\n",
      "Dataset: FinanceBench (150 queries)\n",
      "Evidence items: 189\n",
      "Pre-computed embeddings: 189\n",
      "\n",
      "Evaluation Settings:\n",
      "  K values: [20]\n",
      "  Modes: ['global', 'singledoc']\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "\n",
      "Configurations to evaluate:\n",
      "\n",
      "  1. hyde basic voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - hyde_basic_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - hyde_basic_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  2. hyde detailed voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - hyde_detailed_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - hyde_detailed_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  3. hyde financial_terminology voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  4. query_refinement clarification voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  5. query_refinement formal voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - query_refinement_formal_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - query_refinement_formal_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  6. query_refinement keyword_focused voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  7. term_expansion abbreviation_synonym voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  8. term_expansion context_addition voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  9. chain_of_thought step_by_step voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  10. chain_of_thought explicit_context voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  11. domain_adaptation accounting_perspective voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "  12. domain_adaptation 10k_language voyage/voyage-3-large\n",
      "     Chunk sizes: [512]\n",
      "     Evaluation runs: 2\n",
      "     Output files:\n",
      "       - domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_global.json [EXISTS]\n",
      "       - domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_singledoc.json [EXISTS]\n",
      "\n",
      "============================================================\n",
      "Total evaluation runs: 24\n",
      "Output directory: ../../evaluation_results/query_enhancement\n",
      "============================================================\n",
      "\n",
      "############################################################\n",
      "STARTING BATCH EVALUATION\n",
      "############################################################\n",
      "\n",
      "NOTE: This may take a while. Progress will be shown for each configuration.\n",
      "You can interrupt and resume later - completed evaluations will be skipped.\n",
      "\n",
      "\n",
      "============================================================\n",
      "BATCH EVALUATION\n",
      "============================================================\n",
      "Configurations: 12\n",
      "K values: [20]\n",
      "Modes: ['global', 'singledoc']\n",
      "Page tolerance: ENABLED\n",
      "Text similarity threshold: 0.8\n",
      "Total evaluation runs: 24\n",
      "============================================================\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 1/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: hyde/basic\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 2/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: hyde/basic\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 3/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: hyde/detailed\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 4/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: hyde/detailed\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 5/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: hyde/financial_terminology\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 6/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: hyde/financial_terminology\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 7/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: query_refinement/clarification\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 8/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: query_refinement/clarification\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 9/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: query_refinement/formal\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 10/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: query_refinement/formal\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 11/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: query_refinement/keyword_focused\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 12/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: query_refinement/keyword_focused\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 13/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: term_expansion/abbreviation_synonym\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 14/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: term_expansion/abbreviation_synonym\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 15/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: term_expansion/context_addition\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 16/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: term_expansion/context_addition\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 17/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: chain_of_thought/step_by_step\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 18/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: chain_of_thought/step_by_step\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 19/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: chain_of_thought/explicit_context\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 20/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: chain_of_thought/explicit_context\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 21/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: domain_adaptation/accounting_perspective\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 22/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: domain_adaptation/accounting_perspective\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 23/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: domain_adaptation/10k_language\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "############################################################\n",
      "CONFIGURATION 24/24\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "EVALUATING: voyage/voyage-3-large\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: singledoc\n",
      "  Query Expansion: domain_adaptation/10k_language\n",
      "  Page tolerance: ENABLED\n",
      "  Text similarity threshold: 0.8\n",
      "============================================================\n",
      "✓ Results already exist - SKIPPING\n",
      "\n",
      "============================================================\n",
      "BATCH EVALUATION SUMMARY\n",
      "============================================================\n",
      "Total runs: 24\n",
      "Completed: 0\n",
      "Skipped: 24\n",
      "Failed: 0\n",
      "Total time: 0.00 minutes\n",
      "Average time per run: 0.00 seconds\n",
      "============================================================\n",
      "\n",
      "⚠️  EVALUATION NOT RUN - Uncomment the code above to execute\n",
      "This is intentional to prevent accidental execution during testing.\n",
      "\n",
      "====================================================================================================\n",
      "DETAILED RESULTS - ALL CONFIGURATIONS\n",
      "====================================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SKIPPED EVALUATIONS (24)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  - hyde/basic - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - hyde/basic - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - hyde/detailed - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - hyde/detailed - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - hyde/financial_terminology - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - hyde/financial_terminology - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - query_refinement/clarification - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - query_refinement/clarification - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - query_refinement/formal - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - query_refinement/formal - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - query_refinement/keyword_focused - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - query_refinement/keyword_focused - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - term_expansion/abbreviation_synonym - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - term_expansion/abbreviation_synonym - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - term_expansion/context_addition - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - term_expansion/context_addition - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - chain_of_thought/step_by_step - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - chain_of_thought/step_by_step - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - chain_of_thought/explicit_context - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - chain_of_thought/explicit_context - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - domain_adaptation/accounting_perspective - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - domain_adaptation/accounting_perspective - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "  - domain_adaptation/10k_language - voyage/voyage-3-large/chunk512/k20/global\n",
      "  - domain_adaptation/10k_language - voyage/voyage-3-large/chunk512/k20/singledoc\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "⚠️  Results display not run - uncomment after evaluation completes\n",
      "\n",
      "============================================================\n",
      "GENERATED FILES\n",
      "============================================================\n",
      "\n",
      "Total JSON files: 72\n",
      "Location: ../../evaluation_results/query_enhancement\n",
      "\n",
      "Filename                                                           Size\n",
      "------------------------------------------------------------------------\n",
      "chain_of_thought_explicit_context_ollama_nomic-embed-text_chunk512_k20_global.json   3977.6 KB\n",
      "chain_of_thought_explicit_context_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3359.3 KB\n",
      "chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_global.json   3992.8 KB\n",
      "chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_singledoc.json   3842.4 KB\n",
      "chain_of_thought_explicit_context_voyage_voyage-finance-2_chunk512_k20_global.json   3987.4 KB\n",
      "chain_of_thought_explicit_context_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3878.5 KB\n",
      "chain_of_thought_step_by_step_ollama_nomic-embed-text_chunk512_k20_global.json   4070.9 KB\n",
      "chain_of_thought_step_by_step_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3323.3 KB\n",
      "chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_global.json   4094.7 KB\n",
      "chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_singledoc.json   3914.8 KB\n",
      "chain_of_thought_step_by_step_voyage_voyage-finance-2_chunk512_k20_global.json   4087.0 KB\n",
      "chain_of_thought_step_by_step_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3972.2 KB\n",
      "domain_adaptation_10k_language_ollama_nomic-embed-text_chunk512_k20_global.json   3965.2 KB\n",
      "domain_adaptation_10k_language_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3362.7 KB\n",
      "domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_global.json   3972.0 KB\n",
      "domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_singledoc.json   3794.7 KB\n",
      "domain_adaptation_10k_language_voyage_voyage-finance-2_chunk512_k20_global.json   3968.4 KB\n",
      "domain_adaptation_10k_language_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3800.5 KB\n",
      "domain_adaptation_accounting_perspective_ollama_nomic-embed-text_chunk512_k20_global.json   3949.4 KB\n",
      "domain_adaptation_accounting_perspective_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3313.6 KB\n",
      "domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_global.json   3958.0 KB\n",
      "domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_singledoc.json   3810.6 KB\n",
      "domain_adaptation_accounting_perspective_voyage_voyage-finance-2_chunk512_k20_global.json   3952.3 KB\n",
      "domain_adaptation_accounting_perspective_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3836.6 KB\n",
      "hyde_basic_ollama_nomic-embed-text_chunk512_k20_global.json    3966.5 KB\n",
      "hyde_basic_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3391.3 KB\n",
      "hyde_basic_voyage_voyage-3-large_chunk512_k20_global.json      3977.1 KB\n",
      "hyde_basic_voyage_voyage-3-large_chunk512_k20_singledoc.json   3808.8 KB\n",
      "hyde_basic_voyage_voyage-finance-2_chunk512_k20_global.json    3963.0 KB\n",
      "hyde_basic_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3846.8 KB\n",
      "hyde_detailed_ollama_nomic-embed-text_chunk512_k20_global.json   4062.5 KB\n",
      "hyde_detailed_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3528.9 KB\n",
      "hyde_detailed_voyage_voyage-3-large_chunk512_k20_global.json   4084.9 KB\n",
      "hyde_detailed_voyage_voyage-3-large_chunk512_k20_singledoc.json   3916.9 KB\n",
      "hyde_detailed_voyage_voyage-finance-2_chunk512_k20_global.json   4073.1 KB\n",
      "hyde_detailed_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3948.8 KB\n",
      "hyde_financial_terminology_ollama_nomic-embed-text_chunk512_k20_global.json   4100.6 KB\n",
      "hyde_financial_terminology_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3494.6 KB\n",
      "hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_global.json   4119.3 KB\n",
      "hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_singledoc.json   3942.0 KB\n",
      "hyde_financial_terminology_voyage_voyage-finance-2_chunk512_k20_global.json   4107.6 KB\n",
      "hyde_financial_terminology_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3971.8 KB\n",
      "query_refinement_clarification_ollama_nomic-embed-text_chunk512_k20_global.json   3962.6 KB\n",
      "query_refinement_clarification_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3376.9 KB\n",
      "query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_global.json   3969.0 KB\n",
      "query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_singledoc.json   3826.6 KB\n",
      "query_refinement_clarification_voyage_voyage-finance-2_chunk512_k20_global.json   3966.2 KB\n",
      "query_refinement_clarification_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3855.9 KB\n",
      "query_refinement_formal_ollama_nomic-embed-text_chunk512_k20_global.json   3940.4 KB\n",
      "query_refinement_formal_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3354.3 KB\n",
      "query_refinement_formal_voyage_voyage-3-large_chunk512_k20_global.json   3949.8 KB\n",
      "query_refinement_formal_voyage_voyage-3-large_chunk512_k20_singledoc.json   3810.2 KB\n",
      "query_refinement_formal_voyage_voyage-finance-2_chunk512_k20_global.json   3945.9 KB\n",
      "query_refinement_formal_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3837.3 KB\n",
      "query_refinement_keyword_focused_ollama_nomic-embed-text_chunk512_k20_global.json   3954.2 KB\n",
      "query_refinement_keyword_focused_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3303.5 KB\n",
      "query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_global.json   3964.7 KB\n",
      "query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_singledoc.json   3816.0 KB\n",
      "query_refinement_keyword_focused_voyage_voyage-finance-2_chunk512_k20_global.json   3960.1 KB\n",
      "query_refinement_keyword_focused_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3850.6 KB\n",
      "term_expansion_abbreviation_synonym_ollama_nomic-embed-text_chunk512_k20_global.json   3955.3 KB\n",
      "term_expansion_abbreviation_synonym_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3282.3 KB\n",
      "term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_global.json   3965.9 KB\n",
      "term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_singledoc.json   3819.7 KB\n",
      "term_expansion_abbreviation_synonym_voyage_voyage-finance-2_chunk512_k20_global.json   3958.8 KB\n",
      "term_expansion_abbreviation_synonym_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3857.2 KB\n",
      "term_expansion_context_addition_ollama_nomic-embed-text_chunk512_k20_global.json   3950.9 KB\n",
      "term_expansion_context_addition_ollama_nomic-embed-text_chunk512_k20_singledoc.json   3279.8 KB\n",
      "term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_global.json   3958.4 KB\n",
      "term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_singledoc.json   3807.1 KB\n",
      "term_expansion_context_addition_voyage_voyage-finance-2_chunk512_k20_global.json   3951.7 KB\n",
      "term_expansion_context_addition_voyage_voyage-finance-2_chunk512_k20_singledoc.json   3838.0 KB\n",
      "------------------------------------------------------------------------\n",
      "TOTAL                                                        276759.1 KB\n",
      "\n",
      "============================================================\n",
      "✓ Result inspection function defined\n",
      "\n",
      "============================================================\n",
      "✓ STEP 10 COMPLETE!\n",
      "============================================================\n",
      "  ✓ Configurations defined\n",
      "  ✓ Evaluation parameters set\n",
      "  ✓ Evaluation plan displayed\n",
      "  ✓ Batch evaluation ready (uncomment to run)\n",
      "  ✓ Result analysis tools ready\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "🎉 ALL STEPS COMPLETE! 🎉\n",
      "================================================================================\n",
      "\n",
      "✅ SETUP COMPLETE:\n",
      "  ✓ Step 1: Imports and configuration\n",
      "  ✓ Step 2: Sentence-BERT model loaded\n",
      "  ✓ Step 3: Evidence embeddings pre-computed\n",
      "  ✓ Step 4: Vector store loading functions\n",
      "  ✓ Step 5: Page-based evaluation functions\n",
      "  ✓ Step 6: Text-based evaluation functions\n",
      "  ✓ Step 7: Retrieval functions\n",
      "  ✓ Step 8: Main evaluation function\n",
      "  ✓ Step 9: Batch evaluation function\n",
      "  ✓ Step 10: Configuration and execution ready\n",
      "\n",
      "📊 EVALUATION CAPABILITIES:\n",
      "  ✓ Page-based metrics: MRR, Recall, Precision, F1\n",
      "  ✓ Text-based metrics: MRR, Recall, Precision, F1\n",
      "  ✓ Both global and single-document modes\n",
      "  ✓ Comprehensive JSON output with all similarities\n",
      "  ✓ Text similarity threshold: 0.8\n",
      "  ✓ Pre-computed embeddings: 189 evidence items\n",
      "\n",
      "🚀 NEXT STEPS:\n",
      "  1. Review the evaluation plan above\n",
      "  2. Uncomment the evaluation code in section 10.4\n",
      "  3. Run the batch evaluation (may take 30+ minutes)\n",
      "  4. After completion, uncomment section 10.5 to view results\n",
      "  5. Use section 10.7 to inspect individual result files\n",
      "\n",
      "💾 OUTPUT:\n",
      "  Location: ../../evaluation_results/query_enhancement\n",
      "  Format: JSON files with complete metrics and similarities\n",
      "  Naming: {provider}_{model}_chunk{size}_k{k}_{mode}.json\n",
      "\n",
      "⚠️  IMPORTANT NOTES:\n",
      "  - Evaluation runs incrementally (existing results are skipped)\n",
      "  - You can interrupt and resume anytime\n",
      "  - Progress is shown for each configuration\n",
      "  - Each query processes text similarities (slowest part)\n",
      "  - Results are saved immediately after each configuration\n",
      "\n",
      "================================================================================\n",
      "Ready to evaluate! Uncomment section 10.4 when ready to start.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Step 10: Configuration and Execution\n",
    "# ============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10.1 Define Configurations to Test\n",
    "# \n",
    "# Specify which embedding models and chunk sizes to evaluate\n",
    "\n",
    "# %%\n",
    "# Define configurations to evaluate\n",
    "# Each configuration specifies: provider, model, and chunk sizes to test\n",
    "\n",
    "provider = 'voyage' # ollama, voyage\n",
    "model = 'voyage-3-large' # nomic-embed-text, voyage-finance-2, voyage-3-large\n",
    "\n",
    "configurations = [\n",
    "    {\n",
    "        'expansion_type': 'hyde',\n",
    "        'expansion_subtype': 'basic',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'hyde',\n",
    "        'expansion_subtype': 'detailed',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'hyde',\n",
    "        'expansion_subtype': 'financial_terminology',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'query_refinement',\n",
    "        'expansion_subtype': 'clarification',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'query_refinement',\n",
    "        'expansion_subtype': 'formal',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'query_refinement',\n",
    "        'expansion_subtype': 'keyword_focused',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'term_expansion',\n",
    "        'expansion_subtype': 'abbreviation_synonym',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'term_expansion',\n",
    "        'expansion_subtype': 'context_addition',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'chain_of_thought',\n",
    "        'expansion_subtype': 'step_by_step',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'chain_of_thought',\n",
    "        'expansion_subtype': 'explicit_context',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'domain_adaptation',\n",
    "        'expansion_subtype': 'accounting_perspective',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "    {\n",
    "        'expansion_type': 'domain_adaptation',\n",
    "        'expansion_subtype': '10k_language',\n",
    "        'provider': provider,\n",
    "        'model': model,\n",
    "        'chunk_sizes': [512]\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"✓ Configurations defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10.2 Define Evaluation Parameters\n",
    "\n",
    "# %%\n",
    "# K values to test (number of documents to retrieve)\n",
    "# k_values = [20, 40, 60, 80]\n",
    "k_values = [20]\n",
    "\n",
    "# Modes to test\n",
    "modes = ['global', 'singledoc']\n",
    "\n",
    "# Page tolerance setting\n",
    "# - True: Use chunk-size-aware page tolerance (lenient matching for large chunks)\n",
    "# - False: Exact page match only (strict evaluation)\n",
    "USE_PAGE_TOLERANCE = True\n",
    "\n",
    "# Text similarity threshold\n",
    "# - Chunks with cosine similarity >= this value are considered matches\n",
    "# - Higher = stricter matching, Lower = more lenient matching\n",
    "TEXT_SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "print(\"✓ Evaluation parameters defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10.3 Display Evaluation Plan\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION PLAN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDataset: FinanceBench ({len(dataset)} queries)\")\n",
    "print(f\"Evidence items: {len(all_evidence)}\")\n",
    "print(f\"Pre-computed embeddings: {evidence_embeddings.shape[0]}\")\n",
    "\n",
    "print(f\"\\nEvaluation Settings:\")\n",
    "print(f\"  K values: {k_values}\")\n",
    "print(f\"  Modes: {modes}\")\n",
    "print(f\"  Page tolerance: {'ENABLED' if USE_PAGE_TOLERANCE else 'DISABLED'}\")\n",
    "print(f\"  Text similarity threshold: {TEXT_SIMILARITY_THRESHOLD}\")\n",
    "\n",
    "print(f\"\\nConfigurations to evaluate:\")\n",
    "total_runs = 0\n",
    "for i, config in enumerate(configurations, start=1):\n",
    "    expansion_type = config.get('expansion_type')\n",
    "    expansion_subtype = config.get('expansion_subtype')\n",
    "    provider = config['provider']\n",
    "    model = config['model']\n",
    "    chunk_sizes = config['chunk_sizes']\n",
    "    \n",
    "    runs_for_config = len(chunk_sizes) * len(k_values) * len(modes)\n",
    "    total_runs += runs_for_config\n",
    "\n",
    "    print(f\"\\n  {i}. {expansion_type} {expansion_subtype} {provider}/{model}\")\n",
    "    print(f\"     Chunk sizes: {chunk_sizes}\")\n",
    "    print(f\"     Evaluation runs: {runs_for_config}\")\n",
    "    \n",
    "    # Show output filenames that will be generated\n",
    "    print(f\"     Output files:\")\n",
    "    for chunk_size in chunk_sizes:\n",
    "        for k in k_values:\n",
    "            for mode in modes:\n",
    "                filename = get_output_filename(provider, model, chunk_size, k, mode, expansion_type, expansion_subtype)\n",
    "                exists = check_if_results_exist(provider, model, chunk_size, k, mode, OUTPUT_DIR, expansion_type, expansion_subtype)\n",
    "                status = \"EXISTS\" if exists else \"TO CREATE\"\n",
    "                print(f\"       - {filename} [{status}]\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total evaluation runs: {total_runs}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10.4 Execute Batch Evaluation\n",
    "# \n",
    "# **IMPORTANT**: This cell will run the full evaluation.\n",
    "# - Depending on configurations, this may take 30 minutes to several hours\n",
    "# - Progress will be shown for each configuration\n",
    "# - Results are saved incrementally (existing results are skipped)\n",
    "\n",
    "# %%\n",
    "# Run batch evaluation\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"STARTING BATCH EVALUATION\")\n",
    "print(\"#\"*60)\n",
    "print(\"\\nNOTE: This may take a while. Progress will be shown for each configuration.\")\n",
    "print(\"You can interrupt and resume later - completed evaluations will be skipped.\\n\")\n",
    "\n",
    "# Uncomment the line below to run the evaluation\n",
    "summary = evaluate_multiple_configurations(\n",
    "    dataset=dataset,\n",
    "    evidence_lookup=evidence_lookup,\n",
    "    sbert_model=sbert_model,\n",
    "    configurations=configurations,\n",
    "    k_values=k_values,\n",
    "    modes=modes,\n",
    "    use_page_tolerance=USE_PAGE_TOLERANCE,\n",
    "    text_similarity_threshold=TEXT_SIMILARITY_THRESHOLD,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(\"\\n⚠️  EVALUATION NOT RUN - Uncomment the code above to execute\")\n",
    "print(\"This is intentional to prevent accidental execution during testing.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10.5 Display Results (Run after evaluation completes)\n",
    "# \n",
    "# Uncomment and run this cell after the evaluation completes\n",
    "\n",
    "# %%\n",
    "# Display detailed results in table format\n",
    "# Uncomment after evaluation completes:\n",
    "display_batch_results(summary)\n",
    "\n",
    "print(\"\\n⚠️  Results display not run - uncomment after evaluation completes\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10.6 List Generated Files\n",
    "# \n",
    "# View all generated JSON files\n",
    "\n",
    "# %%\n",
    "# List all generated files\n",
    "list_generated_files(OUTPUT_DIR)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10.7 Load and Analyze a Single Result\n",
    "# \n",
    "# Example: How to load and inspect a single result file\n",
    "\n",
    "# %%\n",
    "def load_and_inspect_result(filename: str, output_dir: str = OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    Load and display a single result file.\n",
    "    Supports both baseline and query expansion results.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the JSON file \n",
    "                  Baseline: \"voyage_voyage-finance-2_chunk1024_k20_global.json\"\n",
    "                  Expanded: \"hyde_basic_voyage_voyage-finance-2_chunk1024_k20_global.json\"\n",
    "        output_dir: Output directory\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"❌ File not found: {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # Load JSON\n",
    "    with open(filepath, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    # Extract summary (last item)\n",
    "    summary = results[0]['summary']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"RESULTS: {filename}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nConfiguration:\")\n",
    "    print(f\"  Provider: {summary['provider']}\")\n",
    "    print(f\"  Model: {summary['model']}\")\n",
    "    print(f\"  Chunk size: {summary['chunk_size']}\")\n",
    "    print(f\"  K: {summary['k']}\")\n",
    "    print(f\"  Mode: {summary['mode']}\")\n",
    "    \n",
    "    # Check if this is an expanded query result\n",
    "    has_expansion = 'expansion_type' in summary\n",
    "    if has_expansion:\n",
    "        print(f\"  Query Expansion: {summary['expansion_type']}/{summary['expansion_subtype']}\")\n",
    "    else:\n",
    "        print(f\"  Query Expansion: None (baseline)\")\n",
    "    \n",
    "    print(f\"  Page tolerance: {summary['use_page_tolerance']}\")\n",
    "    print(f\"  Text threshold: {summary['text_similarity_threshold']}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # BASELINE METRICS\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BASELINE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nPage-Based Metrics:\")\n",
    "    print(f\"  Average MRR:       {summary['average_page_mrr']:.4f}\")\n",
    "    print(f\"  Average Recall:    {summary['average_page_recall']:.4f}\")\n",
    "    print(f\"  Average Precision: {summary['average_page_precision']:.4f}\")\n",
    "    print(f\"  Average F1:        {summary['average_page_f1']:.4f}\")\n",
    "    \n",
    "    print(\"\\nText-Based Metrics:\")\n",
    "    print(f\"  Average MRR:       {summary['average_text_mrr']:.4f}\")\n",
    "    print(f\"  Average Recall:    {summary['average_text_recall']:.4f}\")\n",
    "    print(f\"  Average Precision: {summary['average_text_precision']:.4f}\")\n",
    "    print(f\"  Average F1:        {summary['average_text_f1']:.4f}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # EXPANDED QUERY METRICS (if available)\n",
    "    # ========================================\n",
    "    if has_expansion:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"EXPANDED QUERY METRICS ({summary['expansion_type']}/{summary['expansion_subtype']})\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\nPage-Based Metrics:\")\n",
    "        exp_page_mrr = summary['average_expanded_page_mrr']\n",
    "        exp_page_recall = summary['average_expanded_page_recall']\n",
    "        exp_page_precision = summary['average_expanded_page_precision']\n",
    "        exp_page_f1 = summary['average_expanded_page_f1']\n",
    "        \n",
    "        print(f\"  Average MRR:       {exp_page_mrr:.4f} (Δ {exp_page_mrr - summary['average_page_mrr']:+.4f})\")\n",
    "        print(f\"  Average Recall:    {exp_page_recall:.4f} (Δ {exp_page_recall - summary['average_page_recall']:+.4f})\")\n",
    "        print(f\"  Average Precision: {exp_page_precision:.4f} (Δ {exp_page_precision - summary['average_page_precision']:+.4f})\")\n",
    "        print(f\"  Average F1:        {exp_page_f1:.4f} (Δ {exp_page_f1 - summary['average_page_f1']:+.4f})\")\n",
    "        \n",
    "        print(\"\\nText-Based Metrics:\")\n",
    "        exp_text_mrr = summary['average_expanded_text_mrr']\n",
    "        exp_text_recall = summary['average_expanded_text_recall']\n",
    "        exp_text_precision = summary['average_expanded_text_precision']\n",
    "        exp_text_f1 = summary['average_expanded_text_f1']\n",
    "        \n",
    "        print(f\"  Average MRR:       {exp_text_mrr:.4f} (Δ {exp_text_mrr - summary['average_text_mrr']:+.4f})\")\n",
    "        print(f\"  Average Recall:    {exp_text_recall:.4f} (Δ {exp_text_recall - summary['average_text_recall']:+.4f})\")\n",
    "        print(f\"  Average Precision: {exp_text_precision:.4f} (Δ {exp_text_precision - summary['average_text_precision']:+.4f})\")\n",
    "        print(f\"  Average F1:        {exp_text_f1:.4f} (Δ {exp_text_f1 - summary['average_text_f1']:+.4f})\")\n",
    "        \n",
    "        # Overall improvement summary\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"IMPROVEMENT SUMMARY:\")\n",
    "        print(f\"  Page MRR improvement: {exp_page_mrr - summary['average_page_mrr']:+.4f} ({((exp_page_mrr - summary['average_page_mrr']) / summary['average_page_mrr'] * 100):+.2f}%)\")\n",
    "        print(f\"  Text MRR improvement: {exp_text_mrr - summary['average_text_mrr']:+.4f} ({((exp_text_mrr - summary['average_text_mrr']) / summary['average_text_mrr'] * 100):+.2f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Total queries: {summary['total_queries']}\")\n",
    "    print(f\"Total results (queries + summary): {len(results)}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ========================================\n",
    "    # SAMPLE QUERY RESULT\n",
    "    # ========================================\n",
    "    if len(results) > 1:\n",
    "        sample_query = results[1]\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SAMPLE QUERY RESULT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nQuery ID: {sample_query['query_id']}\")\n",
    "        print(f\"Question: {sample_query['query'][:100]}...\")\n",
    "        \n",
    "        # Baseline results\n",
    "        print(\"\\nBASELINE Retrieval:\")\n",
    "        print(f\"  Page MRR: {sample_query['page_mrr_score']:.4f}, Rank: {sample_query['page_rank']}\")\n",
    "        print(f\"  Text MRR: {sample_query['text_mrr_score']:.4f}, Rank: {sample_query['text_rank']}\")\n",
    "        print(f\"  Retrieved docs: {len(sample_query['retrieved_docs'])}\")\n",
    "        \n",
    "        if len(sample_query['retrieved_docs']) > 0:\n",
    "            first_doc = sample_query['retrieved_docs'][0]\n",
    "            print(f\"\\n  First retrieved doc:\")\n",
    "            print(f\"    Doc: {first_doc['doc_name']}, Page: {first_doc['page_number']}\")\n",
    "            print(f\"    Chunk text: {first_doc['chunk_text'][:100]}...\")\n",
    "            if len(first_doc['text_similarities']) > 0:\n",
    "                print(f\"    Text similarity with evidence 0: {first_doc['text_similarities'][0]['cosine_similarity']:.4f}\")\n",
    "        \n",
    "        # Expanded query results (if available)\n",
    "        if has_expansion and 'expanded_query' in sample_query:\n",
    "            print(\"\\nEXPANDED Query:\")\n",
    "            print(f\"  Expanded question: {sample_query['expanded_query'][:100]}...\")\n",
    "            print(f\"\\nEXPANDED Retrieval:\")\n",
    "            print(f\"  Page MRR: {sample_query['expanded_page_mrr_score']:.4f}, Rank: {sample_query['expanded_page_rank']}\")\n",
    "            print(f\"  Text MRR: {sample_query['expanded_text_mrr_score']:.4f}, Rank: {sample_query['expanded_text_rank']}\")\n",
    "            print(f\"  Retrieved docs: {len(sample_query['expanded_retrieved_docs'])}\")\n",
    "            \n",
    "            if len(sample_query['expanded_retrieved_docs']) > 0:\n",
    "                first_doc_exp = sample_query['expanded_retrieved_docs'][0]\n",
    "                print(f\"\\n  First retrieved doc (expanded):\")\n",
    "                print(f\"    Doc: {first_doc_exp['doc_name']}, Page: {first_doc_exp['page_number']}\")\n",
    "                print(f\"    Chunk text: {first_doc_exp['chunk_text'][:100]}...\")\n",
    "                if len(first_doc_exp['text_similarities']) > 0:\n",
    "                    print(f\"    Text similarity with evidence 0: {first_doc_exp['text_similarities'][0]['cosine_similarity']:.4f}\")\n",
    "            \n",
    "            # Show improvement for this query\n",
    "            page_delta = sample_query['expanded_page_mrr_score'] - sample_query['page_mrr_score']\n",
    "            text_delta = sample_query['expanded_text_mrr_score'] - sample_query['text_mrr_score']\n",
    "            print(f\"\\n  Improvement:\")\n",
    "            print(f\"    Page MRR: {page_delta:+.4f}\")\n",
    "            print(f\"    Text MRR: {text_delta:+.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Result inspection function defined\")\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# results = load_and_inspect_result(\"voyage_voyage-finance-2_chunk1024_k20_global.json\")\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ STEP 10 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"  ✓ Configurations defined\")\n",
    "print(\"  ✓ Evaluation parameters set\")\n",
    "print(\"  ✓ Evaluation plan displayed\")\n",
    "print(\"  ✓ Batch evaluation ready (uncomment to run)\")\n",
    "print(\"  ✓ Result analysis tools ready\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 ALL STEPS COMPLETE! 🎉\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✅ SETUP COMPLETE:\")\n",
    "print(\"  ✓ Step 1: Imports and configuration\")\n",
    "print(\"  ✓ Step 2: Sentence-BERT model loaded\")\n",
    "print(\"  ✓ Step 3: Evidence embeddings pre-computed\")\n",
    "print(\"  ✓ Step 4: Vector store loading functions\")\n",
    "print(\"  ✓ Step 5: Page-based evaluation functions\")\n",
    "print(\"  ✓ Step 6: Text-based evaluation functions\")\n",
    "print(\"  ✓ Step 7: Retrieval functions\")\n",
    "print(\"  ✓ Step 8: Main evaluation function\")\n",
    "print(\"  ✓ Step 9: Batch evaluation function\")\n",
    "print(\"  ✓ Step 10: Configuration and execution ready\")\n",
    "\n",
    "print(\"\\n📊 EVALUATION CAPABILITIES:\")\n",
    "print(\"  ✓ Page-based metrics: MRR, Recall, Precision, F1\")\n",
    "print(\"  ✓ Text-based metrics: MRR, Recall, Precision, F1\")\n",
    "print(\"  ✓ Both global and single-document modes\")\n",
    "print(\"  ✓ Comprehensive JSON output with all similarities\")\n",
    "print(f\"  ✓ Text similarity threshold: {TEXT_SIMILARITY_THRESHOLD}\")\n",
    "print(f\"  ✓ Pre-computed embeddings: {evidence_embeddings.shape[0]} evidence items\")\n",
    "\n",
    "print(\"\\n🚀 NEXT STEPS:\")\n",
    "print(\"  1. Review the evaluation plan above\")\n",
    "print(\"  2. Uncomment the evaluation code in section 10.4\")\n",
    "print(\"  3. Run the batch evaluation (may take 30+ minutes)\")\n",
    "print(\"  4. After completion, uncomment section 10.5 to view results\")\n",
    "print(\"  5. Use section 10.7 to inspect individual result files\")\n",
    "\n",
    "print(\"\\n💾 OUTPUT:\")\n",
    "print(f\"  Location: {OUTPUT_DIR}\")\n",
    "print(f\"  Format: JSON files with complete metrics and similarities\")\n",
    "print(f\"  Naming: {{provider}}_{{model}}_chunk{{size}}_k{{k}}_{{mode}}.json\")\n",
    "\n",
    "print(\"\\n⚠️  IMPORTANT NOTES:\")\n",
    "print(\"  - Evaluation runs incrementally (existing results are skipped)\")\n",
    "print(\"  - You can interrupt and resume anytime\")\n",
    "print(\"  - Progress is shown for each configuration\")\n",
    "print(\"  - Each query processes text similarities (slowest part)\")\n",
    "print(\"  - Results are saved immediately after each configuration\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Ready to evaluate! Uncomment section 10.4 when ready to start.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS: hyde_detailed_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "============================================================\n",
      "\n",
      "Configuration:\n",
      "  Provider: ollama\n",
      "  Model: nomic-embed-text\n",
      "  Chunk size: 512\n",
      "  K: 20\n",
      "  Mode: global\n",
      "  Query Expansion: hyde/detailed\n",
      "  Page tolerance: True\n",
      "  Text threshold: 0.8\n",
      "\n",
      "============================================================\n",
      "BASELINE METRICS\n",
      "============================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  Average MRR:       0.2456\n",
      "  Average Recall:    0.5156\n",
      "  Average Precision: 0.0373\n",
      "  Average F1:        0.0687\n",
      "\n",
      "Text-Based Metrics:\n",
      "  Average MRR:       0.1921\n",
      "  Average Recall:    0.4533\n",
      "  Average Precision: 0.0427\n",
      "  Average F1:        0.0748\n",
      "\n",
      "============================================================\n",
      "EXPANDED QUERY METRICS (hyde/detailed)\n",
      "============================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  Average MRR:       0.2663 (Δ +0.0206)\n",
      "  Average Recall:    0.5500 (Δ +0.0344)\n",
      "  Average Precision: 0.0403 (Δ +0.0030)\n",
      "  Average F1:        0.0744 (Δ +0.0057)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  Average MRR:       0.1896 (Δ -0.0024)\n",
      "  Average Recall:    0.4467 (Δ -0.0067)\n",
      "  Average Precision: 0.0477 (Δ +0.0050)\n",
      "  Average F1:        0.0820 (Δ +0.0072)\n",
      "\n",
      "------------------------------------------------------------\n",
      "IMPROVEMENT SUMMARY:\n",
      "  Page MRR improvement: +0.0206 (+8.39%)\n",
      "  Text MRR improvement: -0.0024 (-1.27%)\n",
      "\n",
      "============================================================\n",
      "Total queries: 150\n",
      "Total results (queries + summary): 151\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SAMPLE QUERY RESULT\n",
      "============================================================\n",
      "\n",
      "Query ID: financebench_id_03029\n",
      "Question: What is the FY2018 capital expenditure amount (in USD millions) for 3M? Give a response to the quest...\n",
      "\n",
      "BASELINE Retrieval:\n",
      "  Page MRR: 0.0000, Rank: -1\n",
      "  Text MRR: 0.0000, Rank: -1\n",
      "  Retrieved docs: 20\n",
      "\n",
      "  First retrieved doc:\n",
      "    Doc: 3M_2022_10K, Page: 41\n",
      "    Chunk text: Refer to the preceding “Results of Operations” section for discussion of items that impacted the net...\n",
      "    Text similarity with evidence 0: 0.0000\n",
      "\n",
      "EXPANDED Query:\n",
      "  Expanded question: In FY2018, 3M Company reported a capital expenditure amount of $1,350 million, as detailed in their ...\n",
      "\n",
      "EXPANDED Retrieval:\n",
      "  Page MRR: 0.0000, Rank: -1\n",
      "  Text MRR: 0.0000, Rank: -1\n",
      "  Retrieved docs: 20\n",
      "\n",
      "  First retrieved doc (expanded):\n",
      "    Doc: 3M_2023Q2_10Q, Page: 71\n",
      "    Chunk text: Balance Sheet:\n",
      "3M’s strong balance sheet and liquidity provide the Company with significant flexibil...\n",
      "    Text similarity with evidence 0: 0.0000\n",
      "\n",
      "  Improvement:\n",
      "    Page MRR: +0.0000\n",
      "    Text MRR: +0.0000\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Example usage (uncomment to use):\n",
    "#results = load_and_inspect_result(\"hyde_detailed_ollama_nomic-embed-text_chunk512_k20_global.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e48c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Query expansion comparison report functions defined (v4 - with Recall/Precision rankings + CSV export)\n",
      "\n",
      "Usage:\n",
      "  quick_expansion_report(provider='ollama', model='nomic-embed-text', chunk_size=512)\n",
      "\n",
      "Outputs:\n",
      "  1. Text report with detailed metrics\n",
      "  2. Rankings by MRR, Recall, AND Precision (6 rankings total)\n",
      "  3. CSV file with all metrics, deltas, and percentages\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Enhanced Query Expansion Report with CSV Export\n",
    "# ============================================================================\n",
    "\n",
    "def generate_expansion_comparison_report(\n",
    "    provider: str,\n",
    "    model: str,\n",
    "    chunk_size: int,\n",
    "    k: int,\n",
    "    mode: str = None,  # None = both modes, or specify \"global\"/\"singledoc\"\n",
    "    output_dir: str = OUTPUT_DIR,\n",
    "    save_to_file: bool = True,\n",
    "    save_csv: bool = True  # NEW: Save CSV with detailed metrics\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive comparison report for all query expansion methods.\n",
    "    \n",
    "    Each expansion result file contains BOTH baseline (original query) and \n",
    "    expanded query metrics. This function compares them to show improvements.\n",
    "    \n",
    "    Args:\n",
    "        provider: Embedding provider (e.g., \"ollama\", \"voyage\")\n",
    "        model: Embedding model (e.g., \"nomic-embed-text\", \"voyage-finance-2\")\n",
    "        chunk_size: Chunk size (e.g., 512, 1024)\n",
    "        k: Number of documents retrieved (e.g., 20)\n",
    "        mode: Retrieval mode - None (both), \"global\", or \"singledoc\"\n",
    "        output_dir: Directory containing result files\n",
    "        save_to_file: Whether to save report to text file\n",
    "        save_csv: Whether to save detailed metrics to CSV file\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with all comparison data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SCANNING FOR QUERY EXPANSION RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"  Provider: {provider}\")\n",
    "    print(f\"  Model: {model}\")\n",
    "    print(f\"  Chunk Size: {chunk_size}\")\n",
    "    print(f\"  K: {k}\")\n",
    "    print(f\"  Mode: {mode if mode else 'both (global + singledoc)'}\")\n",
    "    print(f\"  Directory: {output_dir}\\n\")\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 1: Define expected expansion configs\n",
    "    # ========================================\n",
    "    expansion_configs = [\n",
    "        (\"hyde\", \"basic\"),\n",
    "        (\"hyde\", \"detailed\"),\n",
    "        (\"hyde\", \"financial_terminology\"),\n",
    "        (\"query_refinement\", \"clarification\"),\n",
    "        (\"query_refinement\", \"formal\"),\n",
    "        (\"query_refinement\", \"keyword_focused\"),\n",
    "        (\"term_expansion\", \"abbreviation_synonym\"),\n",
    "        (\"term_expansion\", \"context_addition\"),\n",
    "        (\"chain_of_thought\", \"step_by_step\"),\n",
    "        (\"chain_of_thought\", \"explicit_context\"),\n",
    "        (\"domain_adaptation\", \"accounting_perspective\"),\n",
    "        (\"domain_adaptation\", \"10k_language\"),\n",
    "    ]\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 2: Determine which modes to check\n",
    "    # ========================================\n",
    "    if mode is None:\n",
    "        modes_to_check = [\"global\", \"singledoc\"]\n",
    "    else:\n",
    "        modes_to_check = [mode]\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 3: Scan for files and load data\n",
    "    # ========================================\n",
    "    all_expansion_data = {}\n",
    "    \n",
    "    for check_mode in modes_to_check:\n",
    "        mode_data = {}\n",
    "        \n",
    "        for exp_type, exp_subtype in expansion_configs:\n",
    "            # Construct expected filename\n",
    "            filename = f\"{exp_type}_{exp_subtype}_{provider}_{model}_chunk{chunk_size}_k{k}_{check_mode}.json\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            if os.path.exists(filepath):\n",
    "                try:\n",
    "                    with open(filepath, 'r') as f:\n",
    "                        results = json.load(f)\n",
    "                    \n",
    "                    summary = results[0]['summary']\n",
    "                    \n",
    "                    mode_data[f\"{exp_type}_{exp_subtype}\"] = {\n",
    "                        'filename': filename,\n",
    "                        'summary': summary,\n",
    "                        'type': exp_type,\n",
    "                        'subtype': exp_subtype,\n",
    "                        'mode': check_mode\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"  ✓ Found: {filename}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠️  Error loading {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"  ⏭️  Missing: {filename}\")\n",
    "        \n",
    "        all_expansion_data[check_mode] = mode_data\n",
    "    \n",
    "    # Check if we found any data\n",
    "    total_found = sum(len(mode_data) for mode_data in all_expansion_data.values())\n",
    "    \n",
    "    if total_found == 0:\n",
    "        print(f\"\\n❌ No expansion result files found!\")\n",
    "        print(f\"\\nExpected filename format:\")\n",
    "        print(f\"  {{expansion_type}}_{{expansion_subtype}}_{provider}_{model}_chunk{chunk_size}_k{k}_{{mode}}.json\")\n",
    "        print(f\"\\nExample:\")\n",
    "        print(f\"  hyde_basic_{provider}_{model}_chunk{chunk_size}_k{k}_global.json\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n✓ Found {total_found} expansion result file(s)\")\n",
    "    \n",
    "    # ========================================\n",
    "    # STEP 4: Generate report for each mode\n",
    "    # ========================================\n",
    "    all_reports = []\n",
    "    csv_rows = []  # NEW: Collect CSV data\n",
    "    \n",
    "    for check_mode in modes_to_check:\n",
    "        mode_data = all_expansion_data[check_mode]\n",
    "        \n",
    "        if not mode_data:\n",
    "            print(f\"\\n⏭️  No data for mode: {check_mode}\")\n",
    "            continue\n",
    "        \n",
    "        # Build report for this mode\n",
    "        report_lines = []\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(f\"QUERY EXPANSION COMPARISON REPORT - MODE: {check_mode.upper()}\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        report_lines.append(f\"\\nConfiguration:\")\n",
    "        report_lines.append(f\"  Provider: {provider}\")\n",
    "        report_lines.append(f\"  Model: {model}\")\n",
    "        report_lines.append(f\"  Chunk Size: {chunk_size}\")\n",
    "        report_lines.append(f\"  K (retrieved): {k}\")\n",
    "        report_lines.append(f\"  Mode: {check_mode}\")\n",
    "        report_lines.append(f\"  Expansion methods found: {len(mode_data)}\")\n",
    "        \n",
    "        # ========================================\n",
    "        # Extract baseline and expansion metrics\n",
    "        # ========================================\n",
    "        # Get baseline from first method (they all have same baseline)\n",
    "        first_summary = list(mode_data.values())[0]['summary']\n",
    "        \n",
    "        baseline_metrics = {\n",
    "            'page_mrr': first_summary['average_page_mrr'],\n",
    "            'page_recall': first_summary['average_page_recall'],\n",
    "            'page_precision': first_summary['average_page_precision'],\n",
    "            'page_f1': first_summary['average_page_f1'],\n",
    "            'text_mrr': first_summary['average_text_mrr'],\n",
    "            'text_recall': first_summary['average_text_recall'],\n",
    "            'text_precision': first_summary['average_text_precision'],\n",
    "            'text_f1': first_summary['average_text_f1'],\n",
    "        }\n",
    "        \n",
    "        # ========================================\n",
    "        # Show baseline performance\n",
    "        # ========================================\n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"BASELINE PERFORMANCE (Original Queries - No Expansion)\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        report_lines.append(\"\\nPage-Based Metrics:\")\n",
    "        report_lines.append(f\"  MRR:       {baseline_metrics['page_mrr']:.4f}\")\n",
    "        report_lines.append(f\"  Recall:    {baseline_metrics['page_recall']:.4f}\")\n",
    "        report_lines.append(f\"  Precision: {baseline_metrics['page_precision']:.4f}\")\n",
    "        report_lines.append(f\"  F1:        {baseline_metrics['page_f1']:.4f}\")\n",
    "        \n",
    "        report_lines.append(\"\\nText-Based Metrics:\")\n",
    "        report_lines.append(f\"  MRR:       {baseline_metrics['text_mrr']:.4f}\")\n",
    "        report_lines.append(f\"  Recall:    {baseline_metrics['text_recall']:.4f}\")\n",
    "        report_lines.append(f\"  Precision: {baseline_metrics['text_precision']:.4f}\")\n",
    "        report_lines.append(f\"  F1:        {baseline_metrics['text_f1']:.4f}\")\n",
    "        \n",
    "        # ========================================\n",
    "        # Extract expansion metrics with improvements\n",
    "        # ========================================\n",
    "        metrics_data = {}\n",
    "        \n",
    "        for exp_key, exp_info in mode_data.items():\n",
    "            summary = exp_info['summary']\n",
    "            \n",
    "            # Extract expanded query metrics\n",
    "            expanded_metrics = {\n",
    "                'page_mrr': summary['average_expanded_page_mrr'],\n",
    "                'page_recall': summary['average_expanded_page_recall'],\n",
    "                'page_precision': summary['average_expanded_page_precision'],\n",
    "                'page_f1': summary['average_expanded_page_f1'],\n",
    "                'text_mrr': summary['average_expanded_text_mrr'],\n",
    "                'text_recall': summary['average_expanded_text_recall'],\n",
    "                'text_precision': summary['average_expanded_text_precision'],\n",
    "                'text_f1': summary['average_expanded_text_f1'],\n",
    "            }\n",
    "            \n",
    "            # Calculate improvements (delta and percentage)\n",
    "            improvements = {\n",
    "                'page_mrr': expanded_metrics['page_mrr'] - baseline_metrics['page_mrr'],\n",
    "                'page_recall': expanded_metrics['page_recall'] - baseline_metrics['page_recall'],\n",
    "                'page_precision': expanded_metrics['page_precision'] - baseline_metrics['page_precision'],\n",
    "                'page_f1': expanded_metrics['page_f1'] - baseline_metrics['page_f1'],\n",
    "                'text_mrr': expanded_metrics['text_mrr'] - baseline_metrics['text_mrr'],\n",
    "                'text_recall': expanded_metrics['text_recall'] - baseline_metrics['text_recall'],\n",
    "                'text_precision': expanded_metrics['text_precision'] - baseline_metrics['text_precision'],\n",
    "                'text_f1': expanded_metrics['text_f1'] - baseline_metrics['text_f1'],\n",
    "            }\n",
    "            \n",
    "            improvement_percentages = {\n",
    "                'page_mrr': (improvements['page_mrr'] / baseline_metrics['page_mrr'] * 100) if baseline_metrics['page_mrr'] > 0 else 0,\n",
    "                'page_recall': (improvements['page_recall'] / baseline_metrics['page_recall'] * 100) if baseline_metrics['page_recall'] > 0 else 0,\n",
    "                'page_precision': (improvements['page_precision'] / baseline_metrics['page_precision'] * 100) if baseline_metrics['page_precision'] > 0 else 0,\n",
    "                'page_f1': (improvements['page_f1'] / baseline_metrics['page_f1'] * 100) if baseline_metrics['page_f1'] > 0 else 0,\n",
    "                'text_mrr': (improvements['text_mrr'] / baseline_metrics['text_mrr'] * 100) if baseline_metrics['text_mrr'] > 0 else 0,\n",
    "                'text_recall': (improvements['text_recall'] / baseline_metrics['text_recall'] * 100) if baseline_metrics['text_recall'] > 0 else 0,\n",
    "                'text_precision': (improvements['text_precision'] / baseline_metrics['text_precision'] * 100) if baseline_metrics['text_precision'] > 0 else 0,\n",
    "                'text_f1': (improvements['text_f1'] / baseline_metrics['text_f1'] * 100) if baseline_metrics['text_f1'] > 0 else 0,\n",
    "            }\n",
    "            \n",
    "            metrics_data[exp_key] = {\n",
    "                'type': exp_info['type'],\n",
    "                'subtype': exp_info['subtype'],\n",
    "                'filename': exp_info['filename'],\n",
    "                'metrics': expanded_metrics,\n",
    "                'improvements': improvements,\n",
    "                'improvement_percentages': improvement_percentages\n",
    "            }\n",
    "        \n",
    "        # ========================================\n",
    "        # Detailed Results\n",
    "        # ========================================\n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"EXPANSION METHODS - DETAILED RESULTS\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        # Sort by page MRR improvement (descending)\n",
    "        sorted_by_page_mrr_imp = sorted(\n",
    "            metrics_data.items(),\n",
    "            key=lambda x: x[1]['improvements']['page_mrr'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        for exp_key, data in sorted_by_page_mrr_imp:\n",
    "            report_lines.append(\"\\n\" + \"-\"*80)\n",
    "            report_lines.append(f\"Method: {data['type']} / {data['subtype']}\")\n",
    "            report_lines.append(\"-\"*80)\n",
    "            \n",
    "            report_lines.append(\"\\nPage-Based Metrics:\")\n",
    "            report_lines.append(f\"  MRR:       {data['metrics']['page_mrr']:.4f} (Δ {data['improvements']['page_mrr']:+.4f}, {data['improvement_percentages']['page_mrr']:+.2f}%)\")\n",
    "            report_lines.append(f\"  Recall:    {data['metrics']['page_recall']:.4f} (Δ {data['improvements']['page_recall']:+.4f}, {data['improvement_percentages']['page_recall']:+.2f}%)\")\n",
    "            report_lines.append(f\"  Precision: {data['metrics']['page_precision']:.4f} (Δ {data['improvements']['page_precision']:+.4f}, {data['improvement_percentages']['page_precision']:+.2f}%)\")\n",
    "            report_lines.append(f\"  F1:        {data['metrics']['page_f1']:.4f} (Δ {data['improvements']['page_f1']:+.4f}, {data['improvement_percentages']['page_f1']:+.2f}%)\")\n",
    "            \n",
    "            report_lines.append(\"\\nText-Based Metrics:\")\n",
    "            report_lines.append(f\"  MRR:       {data['metrics']['text_mrr']:.4f} (Δ {data['improvements']['text_mrr']:+.4f}, {data['improvement_percentages']['text_mrr']:+.2f}%)\")\n",
    "            report_lines.append(f\"  Recall:    {data['metrics']['text_recall']:.4f} (Δ {data['improvements']['text_recall']:+.4f}, {data['improvement_percentages']['text_recall']:+.2f}%)\")\n",
    "            report_lines.append(f\"  Precision: {data['metrics']['text_precision']:.4f} (Δ {data['improvements']['text_precision']:+.4f}, {data['improvement_percentages']['text_precision']:+.2f}%)\")\n",
    "            report_lines.append(f\"  F1:        {data['metrics']['text_f1']:.4f} (Δ {data['improvements']['text_f1']:+.4f}, {data['improvement_percentages']['text_f1']:+.2f}%)\")\n",
    "        \n",
    "        # ========================================\n",
    "        # NEW: Rankings for MRR, Recall, AND Precision\n",
    "        # ========================================\n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"RANKING BY PAGE MRR IMPROVEMENT\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        report_lines.append(\"\\nRank | Method                                    | Page MRR | Δ MRR    | %\")\n",
    "        report_lines.append(\"-\"*80)\n",
    "        \n",
    "        for rank, (exp_key, data) in enumerate(sorted_by_page_mrr_imp, 1):\n",
    "            method_name = f\"{data['type']}/{data['subtype']}\"\n",
    "            report_lines.append(\n",
    "                f\"{rank:4d} | {method_name:42s} | {data['metrics']['page_mrr']:.4f}   | \"\n",
    "                f\"{data['improvements']['page_mrr']:+.4f}   | {data['improvement_percentages']['page_mrr']:+.2f}%\"\n",
    "            )\n",
    "        \n",
    "        # NEW: Recall ranking\n",
    "        sorted_by_page_recall_imp = sorted(\n",
    "            metrics_data.items(),\n",
    "            key=lambda x: x[1]['improvements']['page_recall'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"RANKING BY PAGE RECALL IMPROVEMENT\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        report_lines.append(\"\\nRank | Method                                    | Page Recall | Δ Recall | %\")\n",
    "        report_lines.append(\"-\"*80)\n",
    "        \n",
    "        for rank, (exp_key, data) in enumerate(sorted_by_page_recall_imp, 1):\n",
    "            method_name = f\"{data['type']}/{data['subtype']}\"\n",
    "            report_lines.append(\n",
    "                f\"{rank:4d} | {method_name:42s} | {data['metrics']['page_recall']:.4f}      | \"\n",
    "                f\"{data['improvements']['page_recall']:+.4f}     | {data['improvement_percentages']['page_recall']:+.2f}%\"\n",
    "            )\n",
    "        \n",
    "        # NEW: Precision ranking\n",
    "        sorted_by_page_precision_imp = sorted(\n",
    "            metrics_data.items(),\n",
    "            key=lambda x: x[1]['improvements']['page_precision'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"RANKING BY PAGE PRECISION IMPROVEMENT\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        report_lines.append(\"\\nRank | Method                                    | Page Precision | Δ Precision | %\")\n",
    "        report_lines.append(\"-\"*80)\n",
    "        \n",
    "        for rank, (exp_key, data) in enumerate(sorted_by_page_precision_imp, 1):\n",
    "            method_name = f\"{data['type']}/{data['subtype']}\"\n",
    "            report_lines.append(\n",
    "                f\"{rank:4d} | {method_name:42s} | {data['metrics']['page_precision']:.4f}         | \"\n",
    "                f\"{data['improvements']['page_precision']:+.4f}        | {data['improvement_percentages']['page_precision']:+.2f}%\"\n",
    "            )\n",
    "        \n",
    "        # Text-based rankings\n",
    "        sorted_by_text_mrr_imp = sorted(\n",
    "            metrics_data.items(),\n",
    "            key=lambda x: x[1]['improvements']['text_mrr'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"RANKING BY TEXT MRR IMPROVEMENT\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        report_lines.append(\"\\nRank | Method                                    | Text MRR | Δ MRR    | %\")\n",
    "        report_lines.append(\"-\"*80)\n",
    "        \n",
    "        for rank, (exp_key, data) in enumerate(sorted_by_text_mrr_imp, 1):\n",
    "            method_name = f\"{data['type']}/{data['subtype']}\"\n",
    "            report_lines.append(\n",
    "                f\"{rank:4d} | {method_name:42s} | {data['metrics']['text_mrr']:.4f}   | \"\n",
    "                f\"{data['improvements']['text_mrr']:+.4f}   | {data['improvement_percentages']['text_mrr']:+.2f}%\"\n",
    "            )\n",
    "        \n",
    "        # NEW: Text Recall ranking\n",
    "        sorted_by_text_recall_imp = sorted(\n",
    "            metrics_data.items(),\n",
    "            key=lambda x: x[1]['improvements']['text_recall'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"RANKING BY TEXT RECALL IMPROVEMENT\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        report_lines.append(\"\\nRank | Method                                    | Text Recall | Δ Recall | %\")\n",
    "        report_lines.append(\"-\"*80)\n",
    "        \n",
    "        for rank, (exp_key, data) in enumerate(sorted_by_text_recall_imp, 1):\n",
    "            method_name = f\"{data['type']}/{data['subtype']}\"\n",
    "            report_lines.append(\n",
    "                f\"{rank:4d} | {method_name:42s} | {data['metrics']['text_recall']:.4f}      | \"\n",
    "                f\"{data['improvements']['text_recall']:+.4f}     | {data['improvement_percentages']['text_recall']:+.2f}%\"\n",
    "            )\n",
    "        \n",
    "        # NEW: Text Precision ranking\n",
    "        sorted_by_text_precision_imp = sorted(\n",
    "            metrics_data.items(),\n",
    "            key=lambda x: x[1]['improvements']['text_precision'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"RANKING BY TEXT PRECISION IMPROVEMENT\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        report_lines.append(\"\\nRank | Method                                    | Text Precision | Δ Precision | %\")\n",
    "        report_lines.append(\"-\"*80)\n",
    "        \n",
    "        for rank, (exp_key, data) in enumerate(sorted_by_text_precision_imp, 1):\n",
    "            method_name = f\"{data['type']}/{data['subtype']}\"\n",
    "            report_lines.append(\n",
    "                f\"{rank:4d} | {method_name:42s} | {data['metrics']['text_precision']:.4f}         | \"\n",
    "                f\"{data['improvements']['text_precision']:+.4f}        | {data['improvement_percentages']['text_precision']:+.2f}%\"\n",
    "            )\n",
    "        \n",
    "        # ========================================\n",
    "        # Category Analysis (keep existing)\n",
    "        # ========================================\n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"ANALYSIS BY EXPANSION CATEGORY\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        # Group by category\n",
    "        categories = {}\n",
    "        for exp_key, data in metrics_data.items():\n",
    "            cat = data['type']\n",
    "            if cat not in categories:\n",
    "                categories[cat] = []\n",
    "            categories[cat].append(data)\n",
    "        \n",
    "        for category in sorted(categories.keys()):\n",
    "            methods = categories[category]\n",
    "            avg_page_mrr_imp = sum(m['improvements']['page_mrr'] for m in methods) / len(methods)\n",
    "            avg_text_mrr_imp = sum(m['improvements']['text_mrr'] for m in methods) / len(methods)\n",
    "            \n",
    "            report_lines.append(f\"\\nCategory: {category.upper().replace('_', ' ')}\")\n",
    "            report_lines.append(f\"  Number of variants: {len(methods)}\")\n",
    "            report_lines.append(f\"  Avg Page MRR improvement: {avg_page_mrr_imp:+.4f}\")\n",
    "            report_lines.append(f\"  Avg Text MRR improvement: {avg_text_mrr_imp:+.4f}\")\n",
    "            report_lines.append(f\"  Variants:\")\n",
    "            for method in methods:\n",
    "                report_lines.append(\n",
    "                    f\"    - {method['subtype']:30s} \"\n",
    "                    f\"Page: {method['improvements']['page_mrr']:+.4f}, Text: {method['improvements']['text_mrr']:+.4f}\"\n",
    "                )\n",
    "        \n",
    "        # ========================================\n",
    "        # Best and Worst Performers (keep existing)\n",
    "        # ========================================\n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"BEST AND WORST PERFORMERS\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        best_page = sorted_by_page_mrr_imp[0]\n",
    "        worst_page = sorted_by_page_mrr_imp[-1]\n",
    "        best_text = sorted_by_text_mrr_imp[0]\n",
    "        worst_text = sorted_by_text_mrr_imp[-1]\n",
    "        \n",
    "        report_lines.append(f\"\\nBest Page MRR Improvement:\")\n",
    "        report_lines.append(f\"  Method: {best_page[1]['type']}/{best_page[1]['subtype']}\")\n",
    "        report_lines.append(f\"  MRR: {best_page[1]['metrics']['page_mrr']:.4f} (Δ {best_page[1]['improvements']['page_mrr']:+.4f}, {best_page[1]['improvement_percentages']['page_mrr']:+.2f}%)\")\n",
    "        \n",
    "        report_lines.append(f\"\\nWorst Page MRR Improvement:\")\n",
    "        report_lines.append(f\"  Method: {worst_page[1]['type']}/{worst_page[1]['subtype']}\")\n",
    "        report_lines.append(f\"  MRR: {worst_page[1]['metrics']['page_mrr']:.4f} (Δ {worst_page[1]['improvements']['page_mrr']:+.4f}, {worst_page[1]['improvement_percentages']['page_mrr']:+.2f}%)\")\n",
    "        \n",
    "        report_lines.append(f\"\\nBest Text MRR Improvement:\")\n",
    "        report_lines.append(f\"  Method: {best_text[1]['type']}/{best_text[1]['subtype']}\")\n",
    "        report_lines.append(f\"  MRR: {best_text[1]['metrics']['text_mrr']:.4f} (Δ {best_text[1]['improvements']['text_mrr']:+.4f}, {best_text[1]['improvement_percentages']['text_mrr']:+.2f}%)\")\n",
    "        \n",
    "        report_lines.append(f\"\\nWorst Text MRR Improvement:\")\n",
    "        report_lines.append(f\"  Method: {worst_text[1]['type']}/{worst_text[1]['subtype']}\")\n",
    "        report_lines.append(f\"  MRR: {worst_text[1]['metrics']['text_mrr']:.4f} (Δ {worst_text[1]['improvements']['text_mrr']:+.4f}, {worst_text[1]['improvement_percentages']['text_mrr']:+.2f}%)\")\n",
    "        \n",
    "        # ========================================\n",
    "        # Key Insights (keep existing)\n",
    "        # ========================================\n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(\"KEY INSIGHTS\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        positive_page = sum(1 for _, data in metrics_data.items() if data['improvements']['page_mrr'] > 0)\n",
    "        positive_text = sum(1 for _, data in metrics_data.items() if data['improvements']['text_mrr'] > 0)\n",
    "        total = len(metrics_data)\n",
    "        \n",
    "        report_lines.append(f\"\\n• {positive_page}/{total} ({positive_page/total*100:.1f}%) methods improved Page MRR over baseline\")\n",
    "        report_lines.append(f\"• {positive_text}/{total} ({positive_text/total*100:.1f}%) methods improved Text MRR over baseline\")\n",
    "        \n",
    "        avg_page_improvement = sum(data['improvements']['page_mrr'] for data in metrics_data.values()) / total\n",
    "        avg_text_improvement = sum(data['improvements']['text_mrr'] for data in metrics_data.values()) / total\n",
    "        \n",
    "        report_lines.append(f\"• Average Page MRR change: {avg_page_improvement:+.4f} ({avg_page_improvement/baseline_metrics['page_mrr']*100:+.2f}%)\")\n",
    "        report_lines.append(f\"• Average Text MRR change: {avg_text_improvement:+.4f} ({avg_text_improvement/baseline_metrics['text_mrr']*100:+.2f}%)\")\n",
    "        \n",
    "        report_lines.append(\"\\n\" + \"=\"*80)\n",
    "        report_lines.append(f\"END OF REPORT - MODE: {check_mode.upper()}\")\n",
    "        report_lines.append(\"=\"*80)\n",
    "        \n",
    "        # ========================================\n",
    "        # NEW: Prepare CSV rows for this mode\n",
    "        # ========================================\n",
    "        for rank, (exp_key, data) in enumerate(sorted_by_page_mrr_imp, 1):\n",
    "            csv_row = {\n",
    "                'method_type': data['type'],\n",
    "                'method_subtype': data['subtype'],\n",
    "                'method_name': f\"{data['type']}/{data['subtype']}\",\n",
    "                'rank_page_mrr': rank,\n",
    "                'mode': check_mode,\n",
    "                # Baseline metrics\n",
    "                'baseline_page_mrr': baseline_metrics['page_mrr'],\n",
    "                'baseline_page_recall': baseline_metrics['page_recall'],\n",
    "                'baseline_page_precision': baseline_metrics['page_precision'],\n",
    "                'baseline_page_f1': baseline_metrics['page_f1'],\n",
    "                'baseline_text_mrr': baseline_metrics['text_mrr'],\n",
    "                'baseline_text_recall': baseline_metrics['text_recall'],\n",
    "                'baseline_text_precision': baseline_metrics['text_precision'],\n",
    "                'baseline_text_f1': baseline_metrics['text_f1'],\n",
    "                # Expanded metrics\n",
    "                'expanded_page_mrr': data['metrics']['page_mrr'],\n",
    "                'expanded_page_recall': data['metrics']['page_recall'],\n",
    "                'expanded_page_precision': data['metrics']['page_precision'],\n",
    "                'expanded_page_f1': data['metrics']['page_f1'],\n",
    "                'expanded_text_mrr': data['metrics']['text_mrr'],\n",
    "                'expanded_text_recall': data['metrics']['text_recall'],\n",
    "                'expanded_text_precision': data['metrics']['text_precision'],\n",
    "                'expanded_text_f1': data['metrics']['text_f1'],\n",
    "                # Deltas\n",
    "                'delta_page_mrr': data['improvements']['page_mrr'],\n",
    "                'delta_page_recall': data['improvements']['page_recall'],\n",
    "                'delta_page_precision': data['improvements']['page_precision'],\n",
    "                'delta_page_f1': data['improvements']['page_f1'],\n",
    "                'delta_text_mrr': data['improvements']['text_mrr'],\n",
    "                'delta_text_recall': data['improvements']['text_recall'],\n",
    "                'delta_text_precision': data['improvements']['text_precision'],\n",
    "                'delta_text_f1': data['improvements']['text_f1'],\n",
    "                # Percentages\n",
    "                'pct_page_mrr': data['improvement_percentages']['page_mrr'],\n",
    "                'pct_page_recall': data['improvement_percentages']['page_recall'],\n",
    "                'pct_page_precision': data['improvement_percentages']['page_precision'],\n",
    "                'pct_page_f1': data['improvement_percentages']['page_f1'],\n",
    "                'pct_text_mrr': data['improvement_percentages']['text_mrr'],\n",
    "                'pct_text_recall': data['improvement_percentages']['text_recall'],\n",
    "                'pct_text_precision': data['improvement_percentages']['text_precision'],\n",
    "                'pct_text_f1': data['improvement_percentages']['text_f1'],\n",
    "            }\n",
    "            csv_rows.append(csv_row)\n",
    "        \n",
    "        # Store this mode's report\n",
    "        all_reports.append({\n",
    "            'mode': check_mode,\n",
    "            'report_text': \"\\n\".join(report_lines),\n",
    "            'baseline_metrics': baseline_metrics,\n",
    "            'metrics_data': metrics_data\n",
    "        })\n",
    "    \n",
    "    # ========================================\n",
    "    # Print and save all reports\n",
    "    # ========================================\n",
    "    full_report = \"\\n\\n\".join([r['report_text'] for r in all_reports])\n",
    "    print(full_report)\n",
    "    \n",
    "    if save_to_file:\n",
    "        mode_str = mode if mode else \"both\"\n",
    "        report_filename = f\"expansion_report_{provider}_{model}_chunk{chunk_size}_k{k}_{mode_str}.txt\"\n",
    "        report_path = os.path.join(output_dir, report_filename)\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(full_report)\n",
    "        \n",
    "        print(f\"\\n✓ Report saved to: {report_filename}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # NEW: Save CSV file\n",
    "    # ========================================\n",
    "    if save_csv and csv_rows:\n",
    "        import csv\n",
    "        \n",
    "        mode_str = mode if mode else \"both\"\n",
    "        csv_filename = f\"expansion_metrics_{provider}_{model}_chunk{chunk_size}_k{k}_{mode_str}.csv\"\n",
    "        csv_path = os.path.join(output_dir, csv_filename)\n",
    "        \n",
    "        # Write CSV\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = [\n",
    "                'method_type', 'method_subtype', 'method_name', 'rank_page_mrr', 'mode',\n",
    "                # Baseline metrics\n",
    "                'baseline_page_mrr', 'baseline_page_recall', 'baseline_page_precision', 'baseline_page_f1',\n",
    "                'baseline_text_mrr', 'baseline_text_recall', 'baseline_text_precision', 'baseline_text_f1',\n",
    "                # Expanded metrics\n",
    "                'expanded_page_mrr', 'expanded_page_recall', 'expanded_page_precision', 'expanded_page_f1',\n",
    "                'expanded_text_mrr', 'expanded_text_recall', 'expanded_text_precision', 'expanded_text_f1',\n",
    "                # Deltas\n",
    "                'delta_page_mrr', 'delta_page_recall', 'delta_page_precision', 'delta_page_f1',\n",
    "                'delta_text_mrr', 'delta_text_recall', 'delta_text_precision', 'delta_text_f1',\n",
    "                # Percentages\n",
    "                'pct_page_mrr', 'pct_page_recall', 'pct_page_precision', 'pct_page_f1',\n",
    "                'pct_text_mrr', 'pct_text_recall', 'pct_text_precision', 'pct_text_f1',\n",
    "            ]\n",
    "            \n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(csv_rows)\n",
    "        \n",
    "        print(f\"✓ CSV saved to: {csv_filename}\")\n",
    "        print(f\"  Rows: {len(csv_rows)}\")\n",
    "        print(f\"  Columns: {len(fieldnames)}\")\n",
    "    \n",
    "    return {\n",
    "        'configuration': {\n",
    "            'provider': provider,\n",
    "            'model': model,\n",
    "            'chunk_size': chunk_size,\n",
    "            'k': k,\n",
    "            'mode': mode\n",
    "        },\n",
    "        'reports': all_reports,\n",
    "        'csv_data': csv_rows\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Shortcut function\n",
    "# ============================================================================\n",
    "\n",
    "def quick_expansion_report(\n",
    "    provider: str = \"ollama\",\n",
    "    model: str = \"nomic-embed-text\",\n",
    "    chunk_size: int = 512,\n",
    "    k: int = 20,\n",
    "    mode: str = None,  # None = both modes\n",
    "    output_dir: str = OUTPUT_DIR,\n",
    "    save_csv: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Quick shortcut to generate expansion comparison report.\n",
    "    \n",
    "    Example usage:\n",
    "        quick_expansion_report()  # Both global and singledoc with CSV\n",
    "        quick_expansion_report(mode=\"global\")  # Only global with CSV\n",
    "        quick_expansion_report(chunk_size=1024, save_csv=False)  # No CSV\n",
    "    \"\"\"\n",
    "    return generate_expansion_comparison_report(\n",
    "        provider=provider,\n",
    "        model=model,\n",
    "        chunk_size=chunk_size,\n",
    "        k=k,\n",
    "        mode=mode,\n",
    "        output_dir=output_dir,\n",
    "        save_to_file=True,\n",
    "        save_csv=save_csv\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"✓ Query expansion comparison report functions defined (v4 - with Recall/Precision rankings + CSV export)\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  quick_expansion_report(provider='ollama', model='nomic-embed-text', chunk_size=512)\")\n",
    "print(\"\\nOutputs:\")\n",
    "print(\"  1. Text report with detailed metrics\")\n",
    "print(\"  2. Rankings by MRR, Recall, AND Precision (6 rankings total)\")\n",
    "print(\"  3. CSV file with all metrics, deltas, and percentages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4d102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SCANNING FOR QUERY EXPANSION RESULTS\n",
      "================================================================================\n",
      "  Provider: ollama\n",
      "  Model: nomic-embed-text\n",
      "  Chunk Size: 512\n",
      "  K: 20\n",
      "  Mode: both (global + singledoc)\n",
      "  Directory: ../../evaluation_results/query_enhancement\n",
      "\n",
      "  ✓ Found: hyde_basic_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_detailed_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_financial_terminology_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_clarification_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_formal_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_keyword_focused_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: term_expansion_abbreviation_synonym_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: term_expansion_context_addition_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: chain_of_thought_step_by_step_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: chain_of_thought_explicit_context_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: domain_adaptation_accounting_perspective_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: domain_adaptation_10k_language_ollama_nomic-embed-text_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_basic_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: hyde_detailed_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: hyde_financial_terminology_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_clarification_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_formal_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_keyword_focused_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: term_expansion_abbreviation_synonym_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: term_expansion_context_addition_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: chain_of_thought_step_by_step_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: chain_of_thought_explicit_context_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: domain_adaptation_accounting_perspective_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "  ✓ Found: domain_adaptation_10k_language_ollama_nomic-embed-text_chunk512_k20_singledoc.json\n",
      "\n",
      "✓ Found 24 expansion result file(s)\n",
      "\n",
      "================================================================================\n",
      "QUERY EXPANSION COMPARISON REPORT - MODE: GLOBAL\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Provider: ollama\n",
      "  Model: nomic-embed-text\n",
      "  Chunk Size: 512\n",
      "  K (retrieved): 20\n",
      "  Mode: global\n",
      "  Expansion methods found: 12\n",
      "\n",
      "================================================================================\n",
      "BASELINE PERFORMANCE (Original Queries - No Expansion)\n",
      "================================================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2456\n",
      "  Recall:    0.5156\n",
      "  Precision: 0.0373\n",
      "  F1:        0.0687\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1921\n",
      "  Recall:    0.4533\n",
      "  Precision: 0.0427\n",
      "  F1:        0.0748\n",
      "\n",
      "================================================================================\n",
      "EXPANSION METHODS - DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / formal\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3173 (Δ +0.0717, +29.18%)\n",
      "  Recall:    0.6089 (Δ +0.0933, +18.10%)\n",
      "  Precision: 0.0427 (Δ +0.0053, +14.29%)\n",
      "  F1:        0.0790 (Δ +0.0102, +14.91%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2496 (Δ +0.0575, +29.96%)\n",
      "  Recall:    0.5033 (Δ +0.0500, +11.03%)\n",
      "  Precision: 0.0517 (Δ +0.0090, +21.09%)\n",
      "  F1:        0.0891 (Δ +0.0143, +19.17%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / accounting_perspective\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2987 (Δ +0.0531, +21.60%)\n",
      "  Recall:    0.5589 (Δ +0.0433, +8.41%)\n",
      "  Precision: 0.0410 (Δ +0.0037, +9.82%)\n",
      "  F1:        0.0756 (Δ +0.0069, +10.01%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2375 (Δ +0.0454, +23.65%)\n",
      "  Recall:    0.4367 (Δ -0.0167, -3.68%)\n",
      "  Precision: 0.0473 (Δ +0.0047, +10.94%)\n",
      "  F1:        0.0813 (Δ +0.0065, +8.67%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / clarification\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2951 (Δ +0.0495, +20.15%)\n",
      "  Recall:    0.5556 (Δ +0.0400, +7.76%)\n",
      "  Precision: 0.0410 (Δ +0.0037, +9.82%)\n",
      "  F1:        0.0756 (Δ +0.0068, +9.96%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2448 (Δ +0.0528, +27.47%)\n",
      "  Recall:    0.4533 (Δ +0.0000, +0.00%)\n",
      "  Precision: 0.0503 (Δ +0.0077, +17.97%)\n",
      "  F1:        0.0866 (Δ +0.0118, +15.74%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / abbreviation_synonym\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2815 (Δ +0.0359, +14.60%)\n",
      "  Recall:    0.5489 (Δ +0.0333, +6.47%)\n",
      "  Precision: 0.0383 (Δ +0.0010, +2.68%)\n",
      "  F1:        0.0708 (Δ +0.0021, +3.04%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2325 (Δ +0.0405, +21.07%)\n",
      "  Recall:    0.4700 (Δ +0.0167, +3.68%)\n",
      "  Precision: 0.0463 (Δ +0.0037, +8.59%)\n",
      "  F1:        0.0806 (Δ +0.0059, +7.84%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / basic\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2755 (Δ +0.0298, +12.13%)\n",
      "  Recall:    0.5422 (Δ +0.0267, +5.17%)\n",
      "  Precision: 0.0397 (Δ +0.0023, +6.25%)\n",
      "  F1:        0.0730 (Δ +0.0043, +6.25%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1976 (Δ +0.0055, +2.87%)\n",
      "  Recall:    0.4200 (Δ -0.0333, -7.35%)\n",
      "  Precision: 0.0470 (Δ +0.0043, +10.16%)\n",
      "  F1:        0.0807 (Δ +0.0059, +7.85%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / detailed\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2663 (Δ +0.0206, +8.39%)\n",
      "  Recall:    0.5500 (Δ +0.0344, +6.68%)\n",
      "  Precision: 0.0403 (Δ +0.0030, +8.04%)\n",
      "  F1:        0.0744 (Δ +0.0057, +8.24%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1896 (Δ -0.0024, -1.27%)\n",
      "  Recall:    0.4467 (Δ -0.0067, -1.47%)\n",
      "  Precision: 0.0477 (Δ +0.0050, +11.72%)\n",
      "  F1:        0.0820 (Δ +0.0072, +9.67%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / explicit_context\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2564 (Δ +0.0107, +4.37%)\n",
      "  Recall:    0.5189 (Δ +0.0033, +0.65%)\n",
      "  Precision: 0.0380 (Δ +0.0007, +1.79%)\n",
      "  F1:        0.0700 (Δ +0.0013, +1.83%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2131 (Δ +0.0210, +10.94%)\n",
      "  Recall:    0.3933 (Δ -0.0600, -13.24%)\n",
      "  Precision: 0.0417 (Δ -0.0010, -2.34%)\n",
      "  F1:        0.0722 (Δ -0.0026, -3.49%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / financial_terminology\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2510 (Δ +0.0054, +2.18%)\n",
      "  Recall:    0.5267 (Δ +0.0111, +2.16%)\n",
      "  Precision: 0.0393 (Δ +0.0020, +5.36%)\n",
      "  F1:        0.0724 (Δ +0.0037, +5.35%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1946 (Δ +0.0025, +1.31%)\n",
      "  Recall:    0.4167 (Δ -0.0367, -8.09%)\n",
      "  Precision: 0.0440 (Δ +0.0013, +3.12%)\n",
      "  F1:        0.0757 (Δ +0.0009, +1.23%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / context_addition\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2412 (Δ -0.0044, -1.81%)\n",
      "  Recall:    0.5356 (Δ +0.0200, +3.88%)\n",
      "  Precision: 0.0383 (Δ +0.0010, +2.68%)\n",
      "  F1:        0.0706 (Δ +0.0019, +2.73%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1963 (Δ +0.0042, +2.19%)\n",
      "  Recall:    0.4300 (Δ -0.0233, -5.15%)\n",
      "  Precision: 0.0427 (Δ +0.0000, +0.00%)\n",
      "  F1:        0.0745 (Δ -0.0003, -0.34%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / 10k_language\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2380 (Δ -0.0076, -3.11%)\n",
      "  Recall:    0.5689 (Δ +0.0533, +10.34%)\n",
      "  Precision: 0.0403 (Δ +0.0030, +8.04%)\n",
      "  F1:        0.0745 (Δ +0.0058, +8.45%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1967 (Δ +0.0046, +2.40%)\n",
      "  Recall:    0.4433 (Δ -0.0100, -2.21%)\n",
      "  Precision: 0.0463 (Δ +0.0037, +8.59%)\n",
      "  F1:        0.0803 (Δ +0.0055, +7.31%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / keyword_focused\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2276 (Δ -0.0180, -7.34%)\n",
      "  Recall:    0.5056 (Δ -0.0100, -1.94%)\n",
      "  Precision: 0.0387 (Δ +0.0013, +3.57%)\n",
      "  F1:        0.0711 (Δ +0.0024, +3.42%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1882 (Δ -0.0039, -2.01%)\n",
      "  Recall:    0.4400 (Δ -0.0133, -2.94%)\n",
      "  Precision: 0.0470 (Δ +0.0043, +10.16%)\n",
      "  F1:        0.0812 (Δ +0.0064, +8.57%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / step_by_step\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.2169 (Δ -0.0288, -11.71%)\n",
      "  Recall:    0.5589 (Δ +0.0433, +8.41%)\n",
      "  Precision: 0.0390 (Δ +0.0017, +4.46%)\n",
      "  F1:        0.0721 (Δ +0.0034, +4.89%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.1805 (Δ -0.0116, -6.02%)\n",
      "  Recall:    0.4300 (Δ -0.0233, -5.15%)\n",
      "  Precision: 0.0450 (Δ +0.0023, +5.47%)\n",
      "  F1:        0.0778 (Δ +0.0030, +3.97%)\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.3173   | +0.0717   | +29.18%\n",
      "   2 | domain_adaptation/accounting_perspective   | 0.2987   | +0.0531   | +21.60%\n",
      "   3 | query_refinement/clarification             | 0.2951   | +0.0495   | +20.15%\n",
      "   4 | term_expansion/abbreviation_synonym        | 0.2815   | +0.0359   | +14.60%\n",
      "   5 | hyde/basic                                 | 0.2755   | +0.0298   | +12.13%\n",
      "   6 | hyde/detailed                              | 0.2663   | +0.0206   | +8.39%\n",
      "   7 | chain_of_thought/explicit_context          | 0.2564   | +0.0107   | +4.37%\n",
      "   8 | hyde/financial_terminology                 | 0.2510   | +0.0054   | +2.18%\n",
      "   9 | term_expansion/context_addition            | 0.2412   | -0.0044   | -1.81%\n",
      "  10 | domain_adaptation/10k_language             | 0.2380   | -0.0076   | -3.11%\n",
      "  11 | query_refinement/keyword_focused           | 0.2276   | -0.0180   | -7.34%\n",
      "  12 | chain_of_thought/step_by_step              | 0.2169   | -0.0288   | -11.71%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.6089      | +0.0933     | +18.10%\n",
      "   2 | domain_adaptation/10k_language             | 0.5689      | +0.0533     | +10.34%\n",
      "   3 | chain_of_thought/step_by_step              | 0.5589      | +0.0433     | +8.41%\n",
      "   4 | domain_adaptation/accounting_perspective   | 0.5589      | +0.0433     | +8.41%\n",
      "   5 | query_refinement/clarification             | 0.5556      | +0.0400     | +7.76%\n",
      "   6 | hyde/detailed                              | 0.5500      | +0.0344     | +6.68%\n",
      "   7 | term_expansion/abbreviation_synonym        | 0.5489      | +0.0333     | +6.47%\n",
      "   8 | hyde/basic                                 | 0.5422      | +0.0267     | +5.17%\n",
      "   9 | term_expansion/context_addition            | 0.5356      | +0.0200     | +3.88%\n",
      "  10 | hyde/financial_terminology                 | 0.5267      | +0.0111     | +2.16%\n",
      "  11 | chain_of_thought/explicit_context          | 0.5189      | +0.0033     | +0.65%\n",
      "  12 | query_refinement/keyword_focused           | 0.5056      | -0.0100     | -1.94%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.0427         | +0.0053        | +14.29%\n",
      "   2 | query_refinement/clarification             | 0.0410         | +0.0037        | +9.82%\n",
      "   3 | domain_adaptation/accounting_perspective   | 0.0410         | +0.0037        | +9.82%\n",
      "   4 | hyde/detailed                              | 0.0403         | +0.0030        | +8.04%\n",
      "   5 | domain_adaptation/10k_language             | 0.0403         | +0.0030        | +8.04%\n",
      "   6 | hyde/basic                                 | 0.0397         | +0.0023        | +6.25%\n",
      "   7 | hyde/financial_terminology                 | 0.0393         | +0.0020        | +5.36%\n",
      "   8 | chain_of_thought/step_by_step              | 0.0390         | +0.0017        | +4.46%\n",
      "   9 | query_refinement/keyword_focused           | 0.0387         | +0.0013        | +3.57%\n",
      "  10 | term_expansion/abbreviation_synonym        | 0.0383         | +0.0010        | +2.68%\n",
      "  11 | term_expansion/context_addition            | 0.0383         | +0.0010        | +2.68%\n",
      "  12 | chain_of_thought/explicit_context          | 0.0380         | +0.0007        | +1.79%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.2496   | +0.0575   | +29.96%\n",
      "   2 | query_refinement/clarification             | 0.2448   | +0.0528   | +27.47%\n",
      "   3 | domain_adaptation/accounting_perspective   | 0.2375   | +0.0454   | +23.65%\n",
      "   4 | term_expansion/abbreviation_synonym        | 0.2325   | +0.0405   | +21.07%\n",
      "   5 | chain_of_thought/explicit_context          | 0.2131   | +0.0210   | +10.94%\n",
      "   6 | hyde/basic                                 | 0.1976   | +0.0055   | +2.87%\n",
      "   7 | domain_adaptation/10k_language             | 0.1967   | +0.0046   | +2.40%\n",
      "   8 | term_expansion/context_addition            | 0.1963   | +0.0042   | +2.19%\n",
      "   9 | hyde/financial_terminology                 | 0.1946   | +0.0025   | +1.31%\n",
      "  10 | hyde/detailed                              | 0.1896   | -0.0024   | -1.27%\n",
      "  11 | query_refinement/keyword_focused           | 0.1882   | -0.0039   | -2.01%\n",
      "  12 | chain_of_thought/step_by_step              | 0.1805   | -0.0116   | -6.02%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.5033      | +0.0500     | +11.03%\n",
      "   2 | term_expansion/abbreviation_synonym        | 0.4700      | +0.0167     | +3.68%\n",
      "   3 | query_refinement/clarification             | 0.4533      | +0.0000     | +0.00%\n",
      "   4 | hyde/detailed                              | 0.4467      | -0.0067     | -1.47%\n",
      "   5 | domain_adaptation/10k_language             | 0.4433      | -0.0100     | -2.21%\n",
      "   6 | query_refinement/keyword_focused           | 0.4400      | -0.0133     | -2.94%\n",
      "   7 | domain_adaptation/accounting_perspective   | 0.4367      | -0.0167     | -3.68%\n",
      "   8 | term_expansion/context_addition            | 0.4300      | -0.0233     | -5.15%\n",
      "   9 | chain_of_thought/step_by_step              | 0.4300      | -0.0233     | -5.15%\n",
      "  10 | hyde/basic                                 | 0.4200      | -0.0333     | -7.35%\n",
      "  11 | hyde/financial_terminology                 | 0.4167      | -0.0367     | -8.09%\n",
      "  12 | chain_of_thought/explicit_context          | 0.3933      | -0.0600     | -13.24%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.0517         | +0.0090        | +21.09%\n",
      "   2 | query_refinement/clarification             | 0.0503         | +0.0077        | +17.97%\n",
      "   3 | hyde/detailed                              | 0.0477         | +0.0050        | +11.72%\n",
      "   4 | domain_adaptation/accounting_perspective   | 0.0473         | +0.0047        | +10.94%\n",
      "   5 | hyde/basic                                 | 0.0470         | +0.0043        | +10.16%\n",
      "   6 | query_refinement/keyword_focused           | 0.0470         | +0.0043        | +10.16%\n",
      "   7 | term_expansion/abbreviation_synonym        | 0.0463         | +0.0037        | +8.59%\n",
      "   8 | domain_adaptation/10k_language             | 0.0463         | +0.0037        | +8.59%\n",
      "   9 | chain_of_thought/step_by_step              | 0.0450         | +0.0023        | +5.47%\n",
      "  10 | hyde/financial_terminology                 | 0.0440         | +0.0013        | +3.12%\n",
      "  11 | term_expansion/context_addition            | 0.0427         | +0.0000        | +0.00%\n",
      "  12 | chain_of_thought/explicit_context          | 0.0417         | -0.0010        | -2.34%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS BY EXPANSION CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Category: CHAIN OF THOUGHT\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0090\n",
      "  Avg Text MRR improvement: +0.0047\n",
      "  Variants:\n",
      "    - step_by_step                   Page: -0.0288, Text: -0.0116\n",
      "    - explicit_context               Page: +0.0107, Text: +0.0210\n",
      "\n",
      "Category: DOMAIN ADAPTATION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: +0.0227\n",
      "  Avg Text MRR improvement: +0.0250\n",
      "  Variants:\n",
      "    - accounting_perspective         Page: +0.0531, Text: +0.0454\n",
      "    - 10k_language                   Page: -0.0076, Text: +0.0046\n",
      "\n",
      "Category: HYDE\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: +0.0186\n",
      "  Avg Text MRR improvement: +0.0019\n",
      "  Variants:\n",
      "    - basic                          Page: +0.0298, Text: +0.0055\n",
      "    - detailed                       Page: +0.0206, Text: -0.0024\n",
      "    - financial_terminology          Page: +0.0054, Text: +0.0025\n",
      "\n",
      "Category: QUERY REFINEMENT\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: +0.0344\n",
      "  Avg Text MRR improvement: +0.0355\n",
      "  Variants:\n",
      "    - clarification                  Page: +0.0495, Text: +0.0528\n",
      "    - formal                         Page: +0.0717, Text: +0.0575\n",
      "    - keyword_focused                Page: -0.0180, Text: -0.0039\n",
      "\n",
      "Category: TERM EXPANSION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: +0.0157\n",
      "  Avg Text MRR improvement: +0.0223\n",
      "  Variants:\n",
      "    - abbreviation_synonym           Page: +0.0359, Text: +0.0405\n",
      "    - context_addition               Page: -0.0044, Text: +0.0042\n",
      "\n",
      "================================================================================\n",
      "BEST AND WORST PERFORMERS\n",
      "================================================================================\n",
      "\n",
      "Best Page MRR Improvement:\n",
      "  Method: query_refinement/formal\n",
      "  MRR: 0.3173 (Δ +0.0717, +29.18%)\n",
      "\n",
      "Worst Page MRR Improvement:\n",
      "  Method: chain_of_thought/step_by_step\n",
      "  MRR: 0.2169 (Δ -0.0288, -11.71%)\n",
      "\n",
      "Best Text MRR Improvement:\n",
      "  Method: query_refinement/formal\n",
      "  MRR: 0.2496 (Δ +0.0575, +29.96%)\n",
      "\n",
      "Worst Text MRR Improvement:\n",
      "  Method: chain_of_thought/step_by_step\n",
      "  MRR: 0.1805 (Δ -0.0116, -6.02%)\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "• 8/12 (66.7%) methods improved Page MRR over baseline\n",
      "• 9/12 (75.0%) methods improved Text MRR over baseline\n",
      "• Average Page MRR change: +0.0181 (+7.39%)\n",
      "• Average Text MRR change: +0.0180 (+9.38%)\n",
      "\n",
      "================================================================================\n",
      "END OF REPORT - MODE: GLOBAL\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY EXPANSION COMPARISON REPORT - MODE: SINGLEDOC\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Provider: ollama\n",
      "  Model: nomic-embed-text\n",
      "  Chunk Size: 512\n",
      "  K (retrieved): 20\n",
      "  Mode: singledoc\n",
      "  Expansion methods found: 12\n",
      "\n",
      "================================================================================\n",
      "BASELINE PERFORMANCE (Original Queries - No Expansion)\n",
      "================================================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4396\n",
      "  Recall:    0.8000\n",
      "  Precision: 0.1019\n",
      "  F1:        0.1591\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3518\n",
      "  Recall:    0.6056\n",
      "  Precision: 0.0946\n",
      "  F1:        0.1473\n",
      "\n",
      "================================================================================\n",
      "EXPANSION METHODS - DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / formal\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4783 (Δ +0.0387, +8.80%)\n",
      "  Recall:    0.8133 (Δ +0.0133, +1.67%)\n",
      "  Precision: 0.0922 (Δ -0.0097, -9.56%)\n",
      "  F1:        0.1519 (Δ -0.0072, -4.53%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3870 (Δ +0.0352, +10.00%)\n",
      "  Recall:    0.6411 (Δ +0.0356, +5.87%)\n",
      "  Precision: 0.0920 (Δ -0.0027, -2.80%)\n",
      "  F1:        0.1498 (Δ +0.0025, +1.71%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / clarification\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4687 (Δ +0.0291, +6.62%)\n",
      "  Recall:    0.8233 (Δ +0.0233, +2.92%)\n",
      "  Precision: 0.0915 (Δ -0.0104, -10.19%)\n",
      "  F1:        0.1517 (Δ -0.0074, -4.65%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3848 (Δ +0.0330, +9.37%)\n",
      "  Recall:    0.6300 (Δ +0.0244, +4.04%)\n",
      "  Precision: 0.0920 (Δ -0.0027, -2.82%)\n",
      "  F1:        0.1495 (Δ +0.0021, +1.45%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / abbreviation_synonym\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4615 (Δ +0.0219, +4.98%)\n",
      "  Recall:    0.8189 (Δ +0.0189, +2.36%)\n",
      "  Precision: 0.0991 (Δ -0.0028, -2.70%)\n",
      "  F1:        0.1611 (Δ +0.0020, +1.27%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3787 (Δ +0.0268, +7.62%)\n",
      "  Recall:    0.6567 (Δ +0.0511, +8.44%)\n",
      "  Precision: 0.0980 (Δ +0.0034, +3.56%)\n",
      "  F1:        0.1586 (Δ +0.0113, +7.67%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / accounting_perspective\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4553 (Δ +0.0156, +3.56%)\n",
      "  Recall:    0.8044 (Δ +0.0044, +0.56%)\n",
      "  Precision: 0.0924 (Δ -0.0095, -9.30%)\n",
      "  F1:        0.1523 (Δ -0.0068, -4.30%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3720 (Δ +0.0202, +5.74%)\n",
      "  Recall:    0.6367 (Δ +0.0311, +5.14%)\n",
      "  Precision: 0.0931 (Δ -0.0016, -1.67%)\n",
      "  F1:        0.1520 (Δ +0.0047, +3.16%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / explicit_context\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4408 (Δ +0.0012, +0.27%)\n",
      "  Recall:    0.7922 (Δ -0.0078, -0.97%)\n",
      "  Precision: 0.0909 (Δ -0.0110, -10.80%)\n",
      "  F1:        0.1511 (Δ -0.0080, -5.04%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3631 (Δ +0.0113, +3.21%)\n",
      "  Recall:    0.6078 (Δ +0.0022, +0.37%)\n",
      "  Precision: 0.0881 (Δ -0.0066, -6.92%)\n",
      "  F1:        0.1459 (Δ -0.0014, -0.95%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / keyword_focused\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4289 (Δ -0.0107, -2.43%)\n",
      "  Recall:    0.7711 (Δ -0.0289, -3.61%)\n",
      "  Precision: 0.0901 (Δ -0.0118, -11.56%)\n",
      "  F1:        0.1482 (Δ -0.0109, -6.84%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3587 (Δ +0.0069, +1.96%)\n",
      "  Recall:    0.6044 (Δ -0.0011, -0.18%)\n",
      "  Precision: 0.0902 (Δ -0.0045, -4.70%)\n",
      "  F1:        0.1453 (Δ -0.0020, -1.39%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / context_addition\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4279 (Δ -0.0117, -2.66%)\n",
      "  Recall:    0.7978 (Δ -0.0022, -0.28%)\n",
      "  Precision: 0.0930 (Δ -0.0089, -8.78%)\n",
      "  F1:        0.1520 (Δ -0.0071, -4.49%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3572 (Δ +0.0054, +1.52%)\n",
      "  Recall:    0.6189 (Δ +0.0133, +2.20%)\n",
      "  Precision: 0.0890 (Δ -0.0056, -5.94%)\n",
      "  F1:        0.1444 (Δ -0.0029, -1.96%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / financial_terminology\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4266 (Δ -0.0130, -2.95%)\n",
      "  Recall:    0.7822 (Δ -0.0178, -2.22%)\n",
      "  Precision: 0.0859 (Δ -0.0160, -15.69%)\n",
      "  F1:        0.1452 (Δ -0.0139, -8.75%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3309 (Δ -0.0210, -5.96%)\n",
      "  Recall:    0.5889 (Δ -0.0167, -2.75%)\n",
      "  Precision: 0.0817 (Δ -0.0129, -13.67%)\n",
      "  F1:        0.1351 (Δ -0.0122, -8.29%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / basic\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4249 (Δ -0.0147, -3.34%)\n",
      "  Recall:    0.7800 (Δ -0.0200, -2.50%)\n",
      "  Precision: 0.0875 (Δ -0.0144, -14.16%)\n",
      "  F1:        0.1441 (Δ -0.0150, -9.42%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3202 (Δ -0.0316, -8.99%)\n",
      "  Recall:    0.5856 (Δ -0.0200, -3.30%)\n",
      "  Precision: 0.0855 (Δ -0.0092, -9.69%)\n",
      "  F1:        0.1383 (Δ -0.0090, -6.10%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / step_by_step\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4246 (Δ -0.0150, -3.41%)\n",
      "  Recall:    0.7611 (Δ -0.0389, -4.86%)\n",
      "  Precision: 0.0873 (Δ -0.0146, -14.35%)\n",
      "  F1:        0.1451 (Δ -0.0141, -8.84%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3452 (Δ -0.0067, -1.89%)\n",
      "  Recall:    0.5844 (Δ -0.0211, -3.49%)\n",
      "  Precision: 0.0880 (Δ -0.0067, -7.04%)\n",
      "  F1:        0.1438 (Δ -0.0035, -2.36%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / detailed\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4239 (Δ -0.0157, -3.57%)\n",
      "  Recall:    0.7522 (Δ -0.0478, -5.97%)\n",
      "  Precision: 0.0833 (Δ -0.0186, -18.22%)\n",
      "  F1:        0.1367 (Δ -0.0224, -14.11%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3218 (Δ -0.0300, -8.54%)\n",
      "  Recall:    0.5844 (Δ -0.0211, -3.49%)\n",
      "  Precision: 0.0836 (Δ -0.0110, -11.66%)\n",
      "  F1:        0.1358 (Δ -0.0115, -7.78%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / 10k_language\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4157 (Δ -0.0239, -5.44%)\n",
      "  Recall:    0.7878 (Δ -0.0122, -1.53%)\n",
      "  Precision: 0.0911 (Δ -0.0108, -10.59%)\n",
      "  F1:        0.1471 (Δ -0.0121, -7.58%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3396 (Δ -0.0123, -3.49%)\n",
      "  Recall:    0.5956 (Δ -0.0100, -1.65%)\n",
      "  Precision: 0.0860 (Δ -0.0087, -9.18%)\n",
      "  F1:        0.1389 (Δ -0.0085, -5.75%)\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.4783   | +0.0387   | +8.80%\n",
      "   2 | query_refinement/clarification             | 0.4687   | +0.0291   | +6.62%\n",
      "   3 | term_expansion/abbreviation_synonym        | 0.4615   | +0.0219   | +4.98%\n",
      "   4 | domain_adaptation/accounting_perspective   | 0.4553   | +0.0156   | +3.56%\n",
      "   5 | chain_of_thought/explicit_context          | 0.4408   | +0.0012   | +0.27%\n",
      "   6 | query_refinement/keyword_focused           | 0.4289   | -0.0107   | -2.43%\n",
      "   7 | term_expansion/context_addition            | 0.4279   | -0.0117   | -2.66%\n",
      "   8 | hyde/financial_terminology                 | 0.4266   | -0.0130   | -2.95%\n",
      "   9 | hyde/basic                                 | 0.4249   | -0.0147   | -3.34%\n",
      "  10 | chain_of_thought/step_by_step              | 0.4246   | -0.0150   | -3.41%\n",
      "  11 | hyde/detailed                              | 0.4239   | -0.0157   | -3.57%\n",
      "  12 | domain_adaptation/10k_language             | 0.4157   | -0.0239   | -5.44%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/clarification             | 0.8233      | +0.0233     | +2.92%\n",
      "   2 | term_expansion/abbreviation_synonym        | 0.8189      | +0.0189     | +2.36%\n",
      "   3 | query_refinement/formal                    | 0.8133      | +0.0133     | +1.67%\n",
      "   4 | domain_adaptation/accounting_perspective   | 0.8044      | +0.0044     | +0.56%\n",
      "   5 | term_expansion/context_addition            | 0.7978      | -0.0022     | -0.28%\n",
      "   6 | chain_of_thought/explicit_context          | 0.7922      | -0.0078     | -0.97%\n",
      "   7 | domain_adaptation/10k_language             | 0.7878      | -0.0122     | -1.53%\n",
      "   8 | hyde/financial_terminology                 | 0.7822      | -0.0178     | -2.22%\n",
      "   9 | hyde/basic                                 | 0.7800      | -0.0200     | -2.50%\n",
      "  10 | query_refinement/keyword_focused           | 0.7711      | -0.0289     | -3.61%\n",
      "  11 | chain_of_thought/step_by_step              | 0.7611      | -0.0389     | -4.86%\n",
      "  12 | hyde/detailed                              | 0.7522      | -0.0478     | -5.97%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.0991         | -0.0028        | -2.70%\n",
      "   2 | term_expansion/context_addition            | 0.0930         | -0.0089        | -8.78%\n",
      "   3 | domain_adaptation/accounting_perspective   | 0.0924         | -0.0095        | -9.30%\n",
      "   4 | query_refinement/formal                    | 0.0922         | -0.0097        | -9.56%\n",
      "   5 | query_refinement/clarification             | 0.0915         | -0.0104        | -10.19%\n",
      "   6 | domain_adaptation/10k_language             | 0.0911         | -0.0108        | -10.59%\n",
      "   7 | chain_of_thought/explicit_context          | 0.0909         | -0.0110        | -10.80%\n",
      "   8 | query_refinement/keyword_focused           | 0.0901         | -0.0118        | -11.56%\n",
      "   9 | hyde/basic                                 | 0.0875         | -0.0144        | -14.16%\n",
      "  10 | chain_of_thought/step_by_step              | 0.0873         | -0.0146        | -14.35%\n",
      "  11 | hyde/financial_terminology                 | 0.0859         | -0.0160        | -15.69%\n",
      "  12 | hyde/detailed                              | 0.0833         | -0.0186        | -18.22%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.3870   | +0.0352   | +10.00%\n",
      "   2 | query_refinement/clarification             | 0.3848   | +0.0330   | +9.37%\n",
      "   3 | term_expansion/abbreviation_synonym        | 0.3787   | +0.0268   | +7.62%\n",
      "   4 | domain_adaptation/accounting_perspective   | 0.3720   | +0.0202   | +5.74%\n",
      "   5 | chain_of_thought/explicit_context          | 0.3631   | +0.0113   | +3.21%\n",
      "   6 | query_refinement/keyword_focused           | 0.3587   | +0.0069   | +1.96%\n",
      "   7 | term_expansion/context_addition            | 0.3572   | +0.0054   | +1.52%\n",
      "   8 | chain_of_thought/step_by_step              | 0.3452   | -0.0067   | -1.89%\n",
      "   9 | domain_adaptation/10k_language             | 0.3396   | -0.0123   | -3.49%\n",
      "  10 | hyde/financial_terminology                 | 0.3309   | -0.0210   | -5.96%\n",
      "  11 | hyde/detailed                              | 0.3218   | -0.0300   | -8.54%\n",
      "  12 | hyde/basic                                 | 0.3202   | -0.0316   | -8.99%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.6567      | +0.0511     | +8.44%\n",
      "   2 | query_refinement/formal                    | 0.6411      | +0.0356     | +5.87%\n",
      "   3 | domain_adaptation/accounting_perspective   | 0.6367      | +0.0311     | +5.14%\n",
      "   4 | query_refinement/clarification             | 0.6300      | +0.0244     | +4.04%\n",
      "   5 | term_expansion/context_addition            | 0.6189      | +0.0133     | +2.20%\n",
      "   6 | chain_of_thought/explicit_context          | 0.6078      | +0.0022     | +0.37%\n",
      "   7 | query_refinement/keyword_focused           | 0.6044      | -0.0011     | -0.18%\n",
      "   8 | domain_adaptation/10k_language             | 0.5956      | -0.0100     | -1.65%\n",
      "   9 | hyde/financial_terminology                 | 0.5889      | -0.0167     | -2.75%\n",
      "  10 | hyde/basic                                 | 0.5856      | -0.0200     | -3.30%\n",
      "  11 | hyde/detailed                              | 0.5844      | -0.0211     | -3.49%\n",
      "  12 | chain_of_thought/step_by_step              | 0.5844      | -0.0211     | -3.49%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.0980         | +0.0034        | +3.56%\n",
      "   2 | domain_adaptation/accounting_perspective   | 0.0931         | -0.0016        | -1.67%\n",
      "   3 | query_refinement/formal                    | 0.0920         | -0.0027        | -2.80%\n",
      "   4 | query_refinement/clarification             | 0.0920         | -0.0027        | -2.82%\n",
      "   5 | query_refinement/keyword_focused           | 0.0902         | -0.0045        | -4.70%\n",
      "   6 | term_expansion/context_addition            | 0.0890         | -0.0056        | -5.94%\n",
      "   7 | chain_of_thought/explicit_context          | 0.0881         | -0.0066        | -6.92%\n",
      "   8 | chain_of_thought/step_by_step              | 0.0880         | -0.0067        | -7.04%\n",
      "   9 | domain_adaptation/10k_language             | 0.0860         | -0.0087        | -9.18%\n",
      "  10 | hyde/basic                                 | 0.0855         | -0.0092        | -9.69%\n",
      "  11 | hyde/detailed                              | 0.0836         | -0.0110        | -11.66%\n",
      "  12 | hyde/financial_terminology                 | 0.0817         | -0.0129        | -13.67%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS BY EXPANSION CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Category: CHAIN OF THOUGHT\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0069\n",
      "  Avg Text MRR improvement: +0.0023\n",
      "  Variants:\n",
      "    - step_by_step                   Page: -0.0150, Text: -0.0067\n",
      "    - explicit_context               Page: +0.0012, Text: +0.0113\n",
      "\n",
      "Category: DOMAIN ADAPTATION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0041\n",
      "  Avg Text MRR improvement: +0.0039\n",
      "  Variants:\n",
      "    - accounting_perspective         Page: +0.0156, Text: +0.0202\n",
      "    - 10k_language                   Page: -0.0239, Text: -0.0123\n",
      "\n",
      "Category: HYDE\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: -0.0144\n",
      "  Avg Text MRR improvement: -0.0275\n",
      "  Variants:\n",
      "    - basic                          Page: -0.0147, Text: -0.0316\n",
      "    - detailed                       Page: -0.0157, Text: -0.0300\n",
      "    - financial_terminology          Page: -0.0130, Text: -0.0210\n",
      "\n",
      "Category: QUERY REFINEMENT\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: +0.0190\n",
      "  Avg Text MRR improvement: +0.0250\n",
      "  Variants:\n",
      "    - clarification                  Page: +0.0291, Text: +0.0330\n",
      "    - formal                         Page: +0.0387, Text: +0.0352\n",
      "    - keyword_focused                Page: -0.0107, Text: +0.0069\n",
      "\n",
      "Category: TERM EXPANSION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: +0.0051\n",
      "  Avg Text MRR improvement: +0.0161\n",
      "  Variants:\n",
      "    - abbreviation_synonym           Page: +0.0219, Text: +0.0268\n",
      "    - context_addition               Page: -0.0117, Text: +0.0054\n",
      "\n",
      "================================================================================\n",
      "BEST AND WORST PERFORMERS\n",
      "================================================================================\n",
      "\n",
      "Best Page MRR Improvement:\n",
      "  Method: query_refinement/formal\n",
      "  MRR: 0.4783 (Δ +0.0387, +8.80%)\n",
      "\n",
      "Worst Page MRR Improvement:\n",
      "  Method: domain_adaptation/10k_language\n",
      "  MRR: 0.4157 (Δ -0.0239, -5.44%)\n",
      "\n",
      "Best Text MRR Improvement:\n",
      "  Method: query_refinement/formal\n",
      "  MRR: 0.3870 (Δ +0.0352, +10.00%)\n",
      "\n",
      "Worst Text MRR Improvement:\n",
      "  Method: hyde/basic\n",
      "  MRR: 0.3202 (Δ -0.0316, -8.99%)\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "• 5/12 (41.7%) methods improved Page MRR over baseline\n",
      "• 7/12 (58.3%) methods improved Text MRR over baseline\n",
      "• Average Page MRR change: +0.0002 (+0.04%)\n",
      "• Average Text MRR change: +0.0031 (+0.88%)\n",
      "\n",
      "================================================================================\n",
      "END OF REPORT - MODE: SINGLEDOC\n",
      "================================================================================\n",
      "\n",
      "✓ Report saved to: expansion_report_ollama_nomic-embed-text_chunk512_k20_both.txt\n",
      "✓ CSV saved to: expansion_metrics_ollama_nomic-embed-text_chunk512_k20_both.csv\n",
      "  Rows: 24\n",
      "  Columns: 37\n",
      "\n",
      "================================================================================\n",
      "SCANNING FOR QUERY EXPANSION RESULTS\n",
      "================================================================================\n",
      "  Provider: voyage\n",
      "  Model: voyage-finance-2\n",
      "  Chunk Size: 512\n",
      "  K: 20\n",
      "  Mode: both (global + singledoc)\n",
      "  Directory: ../../evaluation_results/query_enhancement\n",
      "\n",
      "  ✓ Found: hyde_basic_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_detailed_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_financial_terminology_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_clarification_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_formal_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_keyword_focused_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: term_expansion_abbreviation_synonym_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: term_expansion_context_addition_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: chain_of_thought_step_by_step_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: chain_of_thought_explicit_context_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: domain_adaptation_accounting_perspective_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: domain_adaptation_10k_language_voyage_voyage-finance-2_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_basic_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: hyde_detailed_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: hyde_financial_terminology_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_clarification_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_formal_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_keyword_focused_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: term_expansion_abbreviation_synonym_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: term_expansion_context_addition_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: chain_of_thought_step_by_step_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: chain_of_thought_explicit_context_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: domain_adaptation_accounting_perspective_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "  ✓ Found: domain_adaptation_10k_language_voyage_voyage-finance-2_chunk512_k20_singledoc.json\n",
      "\n",
      "✓ Found 24 expansion result file(s)\n",
      "\n",
      "================================================================================\n",
      "QUERY EXPANSION COMPARISON REPORT - MODE: GLOBAL\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Provider: voyage\n",
      "  Model: voyage-finance-2\n",
      "  Chunk Size: 512\n",
      "  K (retrieved): 20\n",
      "  Mode: global\n",
      "  Expansion methods found: 12\n",
      "\n",
      "================================================================================\n",
      "BASELINE PERFORMANCE (Original Queries - No Expansion)\n",
      "================================================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4016\n",
      "  Recall:    0.7389\n",
      "  Precision: 0.0577\n",
      "  F1:        0.1058\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2858\n",
      "  Recall:    0.5533\n",
      "  Precision: 0.0530\n",
      "  F1:        0.0936\n",
      "\n",
      "================================================================================\n",
      "EXPANSION METHODS - DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / clarification\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4205 (Δ +0.0189, +4.70%)\n",
      "  Recall:    0.7767 (Δ +0.0378, +5.11%)\n",
      "  Precision: 0.0593 (Δ +0.0017, +2.89%)\n",
      "  F1:        0.1088 (Δ +0.0031, +2.91%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3237 (Δ +0.0380, +13.29%)\n",
      "  Recall:    0.5756 (Δ +0.0222, +4.02%)\n",
      "  Precision: 0.0567 (Δ +0.0037, +6.92%)\n",
      "  F1:        0.0999 (Δ +0.0063, +6.73%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / explicit_context\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4131 (Δ +0.0114, +2.84%)\n",
      "  Recall:    0.7378 (Δ -0.0011, -0.15%)\n",
      "  Precision: 0.0577 (Δ +0.0000, +0.00%)\n",
      "  F1:        0.1055 (Δ -0.0003, -0.28%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3161 (Δ +0.0303, +10.61%)\n",
      "  Recall:    0.5644 (Δ +0.0111, +2.01%)\n",
      "  Precision: 0.0577 (Δ +0.0047, +8.81%)\n",
      "  F1:        0.1013 (Δ +0.0077, +8.27%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / step_by_step\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4040 (Δ +0.0024, +0.59%)\n",
      "  Recall:    0.7500 (Δ +0.0111, +1.50%)\n",
      "  Precision: 0.0547 (Δ -0.0030, -5.20%)\n",
      "  F1:        0.1007 (Δ -0.0051, -4.83%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2950 (Δ +0.0092, +3.23%)\n",
      "  Recall:    0.5633 (Δ +0.0100, +1.81%)\n",
      "  Precision: 0.0510 (Δ -0.0020, -3.77%)\n",
      "  F1:        0.0909 (Δ -0.0027, -2.87%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / context_addition\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4019 (Δ +0.0003, +0.07%)\n",
      "  Recall:    0.7189 (Δ -0.0200, -2.71%)\n",
      "  Precision: 0.0553 (Δ -0.0023, -4.05%)\n",
      "  F1:        0.1016 (Δ -0.0042, -3.98%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2876 (Δ +0.0019, +0.65%)\n",
      "  Recall:    0.5633 (Δ +0.0100, +1.81%)\n",
      "  Precision: 0.0527 (Δ -0.0003, -0.63%)\n",
      "  F1:        0.0936 (Δ +0.0000, +0.01%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / financial_terminology\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3967 (Δ -0.0049, -1.23%)\n",
      "  Recall:    0.7822 (Δ +0.0433, +5.86%)\n",
      "  Precision: 0.0570 (Δ -0.0007, -1.16%)\n",
      "  F1:        0.1050 (Δ -0.0008, -0.76%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2769 (Δ -0.0088, -3.09%)\n",
      "  Recall:    0.5867 (Δ +0.0333, +6.02%)\n",
      "  Precision: 0.0503 (Δ -0.0027, -5.03%)\n",
      "  F1:        0.0904 (Δ -0.0032, -3.41%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / 10k_language\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3913 (Δ -0.0104, -2.58%)\n",
      "  Recall:    0.7500 (Δ +0.0111, +1.50%)\n",
      "  Precision: 0.0543 (Δ -0.0033, -5.78%)\n",
      "  F1:        0.1002 (Δ -0.0056, -5.26%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2938 (Δ +0.0080, +2.82%)\n",
      "  Recall:    0.5600 (Δ +0.0067, +1.20%)\n",
      "  Precision: 0.0537 (Δ +0.0007, +1.26%)\n",
      "  F1:        0.0946 (Δ +0.0010, +1.06%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / detailed\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3844 (Δ -0.0173, -4.30%)\n",
      "  Recall:    0.7767 (Δ +0.0378, +5.11%)\n",
      "  Precision: 0.0583 (Δ +0.0007, +1.16%)\n",
      "  F1:        0.1072 (Δ +0.0015, +1.39%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2677 (Δ -0.0181, -6.34%)\n",
      "  Recall:    0.5789 (Δ +0.0256, +4.62%)\n",
      "  Precision: 0.0517 (Δ -0.0013, -2.52%)\n",
      "  F1:        0.0922 (Δ -0.0014, -1.49%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / abbreviation_synonym\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3791 (Δ -0.0226, -5.61%)\n",
      "  Recall:    0.7489 (Δ +0.0100, +1.35%)\n",
      "  Precision: 0.0570 (Δ -0.0007, -1.16%)\n",
      "  F1:        0.1046 (Δ -0.0012, -1.15%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2846 (Δ -0.0011, -0.39%)\n",
      "  Recall:    0.5600 (Δ +0.0067, +1.20%)\n",
      "  Precision: 0.0520 (Δ -0.0010, -1.89%)\n",
      "  F1:        0.0928 (Δ -0.0008, -0.82%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / basic\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3715 (Δ -0.0302, -7.51%)\n",
      "  Recall:    0.7400 (Δ +0.0011, +0.15%)\n",
      "  Precision: 0.0520 (Δ -0.0057, -9.83%)\n",
      "  F1:        0.0960 (Δ -0.0098, -9.25%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2565 (Δ -0.0292, -10.23%)\n",
      "  Recall:    0.5367 (Δ -0.0167, -3.01%)\n",
      "  Precision: 0.0460 (Δ -0.0070, -13.21%)\n",
      "  F1:        0.0827 (Δ -0.0109, -11.64%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / keyword_focused\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3689 (Δ -0.0327, -8.15%)\n",
      "  Recall:    0.7422 (Δ +0.0033, +0.45%)\n",
      "  Precision: 0.0557 (Δ -0.0020, -3.47%)\n",
      "  F1:        0.1023 (Δ -0.0034, -3.25%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2685 (Δ -0.0173, -6.05%)\n",
      "  Recall:    0.5533 (Δ +0.0000, +0.00%)\n",
      "  Precision: 0.0507 (Δ -0.0023, -4.40%)\n",
      "  F1:        0.0904 (Δ -0.0031, -3.35%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / formal\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3593 (Δ -0.0424, -10.55%)\n",
      "  Recall:    0.7167 (Δ -0.0222, -3.01%)\n",
      "  Precision: 0.0533 (Δ -0.0043, -7.51%)\n",
      "  F1:        0.0981 (Δ -0.0077, -7.26%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2608 (Δ -0.0250, -8.75%)\n",
      "  Recall:    0.5433 (Δ -0.0100, -1.81%)\n",
      "  Precision: 0.0513 (Δ -0.0017, -3.14%)\n",
      "  F1:        0.0911 (Δ -0.0025, -2.68%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / accounting_perspective\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3567 (Δ -0.0450, -11.20%)\n",
      "  Recall:    0.7322 (Δ -0.0067, -0.90%)\n",
      "  Precision: 0.0553 (Δ -0.0023, -4.05%)\n",
      "  F1:        0.1017 (Δ -0.0040, -3.83%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2561 (Δ -0.0297, -10.39%)\n",
      "  Recall:    0.5400 (Δ -0.0133, -2.41%)\n",
      "  Precision: 0.0513 (Δ -0.0017, -3.14%)\n",
      "  F1:        0.0913 (Δ -0.0023, -2.42%)\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/clarification             | 0.4205   | +0.0189   | +4.70%\n",
      "   2 | chain_of_thought/explicit_context          | 0.4131   | +0.0114   | +2.84%\n",
      "   3 | chain_of_thought/step_by_step              | 0.4040   | +0.0024   | +0.59%\n",
      "   4 | term_expansion/context_addition            | 0.4019   | +0.0003   | +0.07%\n",
      "   5 | hyde/financial_terminology                 | 0.3967   | -0.0049   | -1.23%\n",
      "   6 | domain_adaptation/10k_language             | 0.3913   | -0.0104   | -2.58%\n",
      "   7 | hyde/detailed                              | 0.3844   | -0.0173   | -4.30%\n",
      "   8 | term_expansion/abbreviation_synonym        | 0.3791   | -0.0226   | -5.61%\n",
      "   9 | hyde/basic                                 | 0.3715   | -0.0302   | -7.51%\n",
      "  10 | query_refinement/keyword_focused           | 0.3689   | -0.0327   | -8.15%\n",
      "  11 | query_refinement/formal                    | 0.3593   | -0.0424   | -10.55%\n",
      "  12 | domain_adaptation/accounting_perspective   | 0.3567   | -0.0450   | -11.20%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | hyde/financial_terminology                 | 0.7822      | +0.0433     | +5.86%\n",
      "   2 | hyde/detailed                              | 0.7767      | +0.0378     | +5.11%\n",
      "   3 | query_refinement/clarification             | 0.7767      | +0.0378     | +5.11%\n",
      "   4 | chain_of_thought/step_by_step              | 0.7500      | +0.0111     | +1.50%\n",
      "   5 | domain_adaptation/10k_language             | 0.7500      | +0.0111     | +1.50%\n",
      "   6 | term_expansion/abbreviation_synonym        | 0.7489      | +0.0100     | +1.35%\n",
      "   7 | query_refinement/keyword_focused           | 0.7422      | +0.0033     | +0.45%\n",
      "   8 | hyde/basic                                 | 0.7400      | +0.0011     | +0.15%\n",
      "   9 | chain_of_thought/explicit_context          | 0.7378      | -0.0011     | -0.15%\n",
      "  10 | domain_adaptation/accounting_perspective   | 0.7322      | -0.0067     | -0.90%\n",
      "  11 | term_expansion/context_addition            | 0.7189      | -0.0200     | -2.71%\n",
      "  12 | query_refinement/formal                    | 0.7167      | -0.0222     | -3.01%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/clarification             | 0.0593         | +0.0017        | +2.89%\n",
      "   2 | hyde/detailed                              | 0.0583         | +0.0007        | +1.16%\n",
      "   3 | chain_of_thought/explicit_context          | 0.0577         | +0.0000        | +0.00%\n",
      "   4 | hyde/financial_terminology                 | 0.0570         | -0.0007        | -1.16%\n",
      "   5 | term_expansion/abbreviation_synonym        | 0.0570         | -0.0007        | -1.16%\n",
      "   6 | query_refinement/keyword_focused           | 0.0557         | -0.0020        | -3.47%\n",
      "   7 | term_expansion/context_addition            | 0.0553         | -0.0023        | -4.05%\n",
      "   8 | domain_adaptation/accounting_perspective   | 0.0553         | -0.0023        | -4.05%\n",
      "   9 | chain_of_thought/step_by_step              | 0.0547         | -0.0030        | -5.20%\n",
      "  10 | domain_adaptation/10k_language             | 0.0543         | -0.0033        | -5.78%\n",
      "  11 | query_refinement/formal                    | 0.0533         | -0.0043        | -7.51%\n",
      "  12 | hyde/basic                                 | 0.0520         | -0.0057        | -9.83%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/clarification             | 0.3237   | +0.0380   | +13.29%\n",
      "   2 | chain_of_thought/explicit_context          | 0.3161   | +0.0303   | +10.61%\n",
      "   3 | chain_of_thought/step_by_step              | 0.2950   | +0.0092   | +3.23%\n",
      "   4 | domain_adaptation/10k_language             | 0.2938   | +0.0080   | +2.82%\n",
      "   5 | term_expansion/context_addition            | 0.2876   | +0.0019   | +0.65%\n",
      "   6 | term_expansion/abbreviation_synonym        | 0.2846   | -0.0011   | -0.39%\n",
      "   7 | hyde/financial_terminology                 | 0.2769   | -0.0088   | -3.09%\n",
      "   8 | query_refinement/keyword_focused           | 0.2685   | -0.0173   | -6.05%\n",
      "   9 | hyde/detailed                              | 0.2677   | -0.0181   | -6.34%\n",
      "  10 | query_refinement/formal                    | 0.2608   | -0.0250   | -8.75%\n",
      "  11 | hyde/basic                                 | 0.2565   | -0.0292   | -10.23%\n",
      "  12 | domain_adaptation/accounting_perspective   | 0.2561   | -0.0297   | -10.39%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | hyde/financial_terminology                 | 0.5867      | +0.0333     | +6.02%\n",
      "   2 | hyde/detailed                              | 0.5789      | +0.0256     | +4.62%\n",
      "   3 | query_refinement/clarification             | 0.5756      | +0.0222     | +4.02%\n",
      "   4 | chain_of_thought/explicit_context          | 0.5644      | +0.0111     | +2.01%\n",
      "   5 | term_expansion/context_addition            | 0.5633      | +0.0100     | +1.81%\n",
      "   6 | chain_of_thought/step_by_step              | 0.5633      | +0.0100     | +1.81%\n",
      "   7 | term_expansion/abbreviation_synonym        | 0.5600      | +0.0067     | +1.20%\n",
      "   8 | domain_adaptation/10k_language             | 0.5600      | +0.0067     | +1.20%\n",
      "   9 | query_refinement/keyword_focused           | 0.5533      | +0.0000     | +0.00%\n",
      "  10 | query_refinement/formal                    | 0.5433      | -0.0100     | -1.81%\n",
      "  11 | domain_adaptation/accounting_perspective   | 0.5400      | -0.0133     | -2.41%\n",
      "  12 | hyde/basic                                 | 0.5367      | -0.0167     | -3.01%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | chain_of_thought/explicit_context          | 0.0577         | +0.0047        | +8.81%\n",
      "   2 | query_refinement/clarification             | 0.0567         | +0.0037        | +6.92%\n",
      "   3 | domain_adaptation/10k_language             | 0.0537         | +0.0007        | +1.26%\n",
      "   4 | term_expansion/context_addition            | 0.0527         | -0.0003        | -0.63%\n",
      "   5 | term_expansion/abbreviation_synonym        | 0.0520         | -0.0010        | -1.89%\n",
      "   6 | hyde/detailed                              | 0.0517         | -0.0013        | -2.52%\n",
      "   7 | query_refinement/formal                    | 0.0513         | -0.0017        | -3.14%\n",
      "   8 | domain_adaptation/accounting_perspective   | 0.0513         | -0.0017        | -3.14%\n",
      "   9 | chain_of_thought/step_by_step              | 0.0510         | -0.0020        | -3.77%\n",
      "  10 | query_refinement/keyword_focused           | 0.0507         | -0.0023        | -4.40%\n",
      "  11 | hyde/financial_terminology                 | 0.0503         | -0.0027        | -5.03%\n",
      "  12 | hyde/basic                                 | 0.0460         | -0.0070        | -13.21%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS BY EXPANSION CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Category: CHAIN OF THOUGHT\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: +0.0069\n",
      "  Avg Text MRR improvement: +0.0198\n",
      "  Variants:\n",
      "    - step_by_step                   Page: +0.0024, Text: +0.0092\n",
      "    - explicit_context               Page: +0.0114, Text: +0.0303\n",
      "\n",
      "Category: DOMAIN ADAPTATION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0277\n",
      "  Avg Text MRR improvement: -0.0108\n",
      "  Variants:\n",
      "    - accounting_perspective         Page: -0.0450, Text: -0.0297\n",
      "    - 10k_language                   Page: -0.0104, Text: +0.0080\n",
      "\n",
      "Category: HYDE\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: -0.0175\n",
      "  Avg Text MRR improvement: -0.0187\n",
      "  Variants:\n",
      "    - basic                          Page: -0.0302, Text: -0.0292\n",
      "    - detailed                       Page: -0.0173, Text: -0.0181\n",
      "    - financial_terminology          Page: -0.0049, Text: -0.0088\n",
      "\n",
      "Category: QUERY REFINEMENT\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: -0.0187\n",
      "  Avg Text MRR improvement: -0.0014\n",
      "  Variants:\n",
      "    - clarification                  Page: +0.0189, Text: +0.0380\n",
      "    - formal                         Page: -0.0424, Text: -0.0250\n",
      "    - keyword_focused                Page: -0.0327, Text: -0.0173\n",
      "\n",
      "Category: TERM EXPANSION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0111\n",
      "  Avg Text MRR improvement: +0.0004\n",
      "  Variants:\n",
      "    - abbreviation_synonym           Page: -0.0226, Text: -0.0011\n",
      "    - context_addition               Page: +0.0003, Text: +0.0019\n",
      "\n",
      "================================================================================\n",
      "BEST AND WORST PERFORMERS\n",
      "================================================================================\n",
      "\n",
      "Best Page MRR Improvement:\n",
      "  Method: query_refinement/clarification\n",
      "  MRR: 0.4205 (Δ +0.0189, +4.70%)\n",
      "\n",
      "Worst Page MRR Improvement:\n",
      "  Method: domain_adaptation/accounting_perspective\n",
      "  MRR: 0.3567 (Δ -0.0450, -11.20%)\n",
      "\n",
      "Best Text MRR Improvement:\n",
      "  Method: query_refinement/clarification\n",
      "  MRR: 0.3237 (Δ +0.0380, +13.29%)\n",
      "\n",
      "Worst Text MRR Improvement:\n",
      "  Method: domain_adaptation/accounting_perspective\n",
      "  MRR: 0.2561 (Δ -0.0297, -10.39%)\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "• 4/12 (33.3%) methods improved Page MRR over baseline\n",
      "• 5/12 (41.7%) methods improved Text MRR over baseline\n",
      "• Average Page MRR change: -0.0144 (-3.58%)\n",
      "• Average Text MRR change: -0.0035 (-1.22%)\n",
      "\n",
      "================================================================================\n",
      "END OF REPORT - MODE: GLOBAL\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY EXPANSION COMPARISON REPORT - MODE: SINGLEDOC\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Provider: voyage\n",
      "  Model: voyage-finance-2\n",
      "  Chunk Size: 512\n",
      "  K (retrieved): 20\n",
      "  Mode: singledoc\n",
      "  Expansion methods found: 12\n",
      "\n",
      "================================================================================\n",
      "BASELINE PERFORMANCE (Original Queries - No Expansion)\n",
      "================================================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4690\n",
      "  Recall:    0.8156\n",
      "  Precision: 0.0847\n",
      "  F1:        0.1453\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3192\n",
      "  Recall:    0.6233\n",
      "  Precision: 0.0694\n",
      "  F1:        0.1201\n",
      "\n",
      "================================================================================\n",
      "EXPANSION METHODS - DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / financial_terminology\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5140 (Δ +0.0450, +9.60%)\n",
      "  Recall:    0.9022 (Δ +0.0867, +10.63%)\n",
      "  Precision: 0.0946 (Δ +0.0099, +11.65%)\n",
      "  F1:        0.1629 (Δ +0.0176, +12.13%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3638 (Δ +0.0446, +13.98%)\n",
      "  Recall:    0.6767 (Δ +0.0533, +8.56%)\n",
      "  Precision: 0.0726 (Δ +0.0032, +4.54%)\n",
      "  F1:        0.1264 (Δ +0.0063, +5.27%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / explicit_context\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4935 (Δ +0.0245, +5.22%)\n",
      "  Recall:    0.8189 (Δ +0.0033, +0.41%)\n",
      "  Precision: 0.0823 (Δ -0.0024, -2.86%)\n",
      "  F1:        0.1412 (Δ -0.0041, -2.83%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3755 (Δ +0.0563, +17.64%)\n",
      "  Recall:    0.6211 (Δ -0.0022, -0.36%)\n",
      "  Precision: 0.0722 (Δ +0.0028, +4.00%)\n",
      "  F1:        0.1245 (Δ +0.0044, +3.67%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / clarification\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4923 (Δ +0.0233, +4.96%)\n",
      "  Recall:    0.8467 (Δ +0.0311, +3.81%)\n",
      "  Precision: 0.0840 (Δ -0.0008, -0.91%)\n",
      "  F1:        0.1441 (Δ -0.0012, -0.82%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3713 (Δ +0.0521, +16.31%)\n",
      "  Recall:    0.6278 (Δ +0.0044, +0.71%)\n",
      "  Precision: 0.0702 (Δ +0.0008, +1.15%)\n",
      "  F1:        0.1214 (Δ +0.0013, +1.08%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / 10k_language\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4872 (Δ +0.0182, +3.87%)\n",
      "  Recall:    0.8422 (Δ +0.0267, +3.27%)\n",
      "  Precision: 0.0914 (Δ +0.0067, +7.93%)\n",
      "  F1:        0.1522 (Δ +0.0070, +4.79%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3576 (Δ +0.0384, +12.03%)\n",
      "  Recall:    0.6356 (Δ +0.0122, +1.96%)\n",
      "  Precision: 0.0756 (Δ +0.0062, +8.87%)\n",
      "  F1:        0.1287 (Δ +0.0086, +7.18%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / step_by_step\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4821 (Δ +0.0131, +2.79%)\n",
      "  Recall:    0.8533 (Δ +0.0378, +4.63%)\n",
      "  Precision: 0.0818 (Δ -0.0029, -3.41%)\n",
      "  F1:        0.1418 (Δ -0.0035, -2.40%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3470 (Δ +0.0278, +8.72%)\n",
      "  Recall:    0.6422 (Δ +0.0189, +3.03%)\n",
      "  Precision: 0.0687 (Δ -0.0007, -0.96%)\n",
      "  F1:        0.1198 (Δ -0.0003, -0.25%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / detailed\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4800 (Δ +0.0110, +2.34%)\n",
      "  Recall:    0.8833 (Δ +0.0678, +8.31%)\n",
      "  Precision: 0.0891 (Δ +0.0044, +5.19%)\n",
      "  F1:        0.1536 (Δ +0.0083, +5.71%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3296 (Δ +0.0104, +3.25%)\n",
      "  Recall:    0.6622 (Δ +0.0389, +6.24%)\n",
      "  Precision: 0.0716 (Δ +0.0022, +3.16%)\n",
      "  F1:        0.1240 (Δ +0.0040, +3.29%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / context_addition\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4623 (Δ -0.0067, -1.43%)\n",
      "  Recall:    0.8333 (Δ +0.0178, +2.18%)\n",
      "  Precision: 0.0831 (Δ -0.0016, -1.94%)\n",
      "  F1:        0.1430 (Δ -0.0023, -1.56%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3212 (Δ +0.0020, +0.62%)\n",
      "  Recall:    0.6267 (Δ +0.0033, +0.53%)\n",
      "  Precision: 0.0689 (Δ -0.0005, -0.75%)\n",
      "  F1:        0.1191 (Δ -0.0009, -0.77%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / basic\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4546 (Δ -0.0144, -3.07%)\n",
      "  Recall:    0.8678 (Δ +0.0522, +6.40%)\n",
      "  Precision: 0.0873 (Δ +0.0025, +2.98%)\n",
      "  F1:        0.1505 (Δ +0.0052, +3.59%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3136 (Δ -0.0056, -1.74%)\n",
      "  Recall:    0.6456 (Δ +0.0222, +3.57%)\n",
      "  Precision: 0.0668 (Δ -0.0026, -3.79%)\n",
      "  F1:        0.1172 (Δ -0.0028, -2.36%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / keyword_focused\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4507 (Δ -0.0184, -3.91%)\n",
      "  Recall:    0.8267 (Δ +0.0111, +1.36%)\n",
      "  Precision: 0.0816 (Δ -0.0032, -3.73%)\n",
      "  F1:        0.1401 (Δ -0.0052, -3.57%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3262 (Δ +0.0070, +2.18%)\n",
      "  Recall:    0.6033 (Δ -0.0200, -3.21%)\n",
      "  Precision: 0.0648 (Δ -0.0046, -6.68%)\n",
      "  F1:        0.1133 (Δ -0.0068, -5.68%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / abbreviation_synonym\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4449 (Δ -0.0241, -5.14%)\n",
      "  Recall:    0.8622 (Δ +0.0467, +5.72%)\n",
      "  Precision: 0.0855 (Δ +0.0007, +0.86%)\n",
      "  F1:        0.1472 (Δ +0.0019, +1.34%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3201 (Δ +0.0009, +0.29%)\n",
      "  Recall:    0.6433 (Δ +0.0200, +3.21%)\n",
      "  Precision: 0.0678 (Δ -0.0016, -2.24%)\n",
      "  F1:        0.1185 (Δ -0.0016, -1.31%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / formal\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4282 (Δ -0.0409, -8.71%)\n",
      "  Recall:    0.8222 (Δ +0.0067, +0.82%)\n",
      "  Precision: 0.0801 (Δ -0.0047, -5.49%)\n",
      "  F1:        0.1380 (Δ -0.0073, -5.02%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3010 (Δ -0.0182, -5.69%)\n",
      "  Recall:    0.6100 (Δ -0.0133, -2.14%)\n",
      "  Precision: 0.0655 (Δ -0.0039, -5.60%)\n",
      "  F1:        0.1139 (Δ -0.0061, -5.12%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / accounting_perspective\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4276 (Δ -0.0415, -8.84%)\n",
      "  Recall:    0.8378 (Δ +0.0222, +2.72%)\n",
      "  Precision: 0.0828 (Δ -0.0020, -2.31%)\n",
      "  F1:        0.1433 (Δ -0.0019, -1.34%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2990 (Δ -0.0202, -6.32%)\n",
      "  Recall:    0.6200 (Δ -0.0033, -0.53%)\n",
      "  Precision: 0.0678 (Δ -0.0016, -2.29%)\n",
      "  F1:        0.1186 (Δ -0.0015, -1.22%)\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | hyde/financial_terminology                 | 0.5140   | +0.0450   | +9.60%\n",
      "   2 | chain_of_thought/explicit_context          | 0.4935   | +0.0245   | +5.22%\n",
      "   3 | query_refinement/clarification             | 0.4923   | +0.0233   | +4.96%\n",
      "   4 | domain_adaptation/10k_language             | 0.4872   | +0.0182   | +3.87%\n",
      "   5 | chain_of_thought/step_by_step              | 0.4821   | +0.0131   | +2.79%\n",
      "   6 | hyde/detailed                              | 0.4800   | +0.0110   | +2.34%\n",
      "   7 | term_expansion/context_addition            | 0.4623   | -0.0067   | -1.43%\n",
      "   8 | hyde/basic                                 | 0.4546   | -0.0144   | -3.07%\n",
      "   9 | query_refinement/keyword_focused           | 0.4507   | -0.0184   | -3.91%\n",
      "  10 | term_expansion/abbreviation_synonym        | 0.4449   | -0.0241   | -5.14%\n",
      "  11 | query_refinement/formal                    | 0.4282   | -0.0409   | -8.71%\n",
      "  12 | domain_adaptation/accounting_perspective   | 0.4276   | -0.0415   | -8.84%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | hyde/financial_terminology                 | 0.9022      | +0.0867     | +10.63%\n",
      "   2 | hyde/detailed                              | 0.8833      | +0.0678     | +8.31%\n",
      "   3 | hyde/basic                                 | 0.8678      | +0.0522     | +6.40%\n",
      "   4 | term_expansion/abbreviation_synonym        | 0.8622      | +0.0467     | +5.72%\n",
      "   5 | chain_of_thought/step_by_step              | 0.8533      | +0.0378     | +4.63%\n",
      "   6 | query_refinement/clarification             | 0.8467      | +0.0311     | +3.81%\n",
      "   7 | domain_adaptation/10k_language             | 0.8422      | +0.0267     | +3.27%\n",
      "   8 | domain_adaptation/accounting_perspective   | 0.8378      | +0.0222     | +2.72%\n",
      "   9 | term_expansion/context_addition            | 0.8333      | +0.0178     | +2.18%\n",
      "  10 | query_refinement/keyword_focused           | 0.8267      | +0.0111     | +1.36%\n",
      "  11 | query_refinement/formal                    | 0.8222      | +0.0067     | +0.82%\n",
      "  12 | chain_of_thought/explicit_context          | 0.8189      | +0.0033     | +0.41%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | hyde/financial_terminology                 | 0.0946         | +0.0099        | +11.65%\n",
      "   2 | domain_adaptation/10k_language             | 0.0914         | +0.0067        | +7.93%\n",
      "   3 | hyde/detailed                              | 0.0891         | +0.0044        | +5.19%\n",
      "   4 | hyde/basic                                 | 0.0873         | +0.0025        | +2.98%\n",
      "   5 | term_expansion/abbreviation_synonym        | 0.0855         | +0.0007        | +0.86%\n",
      "   6 | query_refinement/clarification             | 0.0840         | -0.0008        | -0.91%\n",
      "   7 | term_expansion/context_addition            | 0.0831         | -0.0016        | -1.94%\n",
      "   8 | domain_adaptation/accounting_perspective   | 0.0828         | -0.0020        | -2.31%\n",
      "   9 | chain_of_thought/explicit_context          | 0.0823         | -0.0024        | -2.86%\n",
      "  10 | chain_of_thought/step_by_step              | 0.0818         | -0.0029        | -3.41%\n",
      "  11 | query_refinement/keyword_focused           | 0.0816         | -0.0032        | -3.73%\n",
      "  12 | query_refinement/formal                    | 0.0801         | -0.0047        | -5.49%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | chain_of_thought/explicit_context          | 0.3755   | +0.0563   | +17.64%\n",
      "   2 | query_refinement/clarification             | 0.3713   | +0.0521   | +16.31%\n",
      "   3 | hyde/financial_terminology                 | 0.3638   | +0.0446   | +13.98%\n",
      "   4 | domain_adaptation/10k_language             | 0.3576   | +0.0384   | +12.03%\n",
      "   5 | chain_of_thought/step_by_step              | 0.3470   | +0.0278   | +8.72%\n",
      "   6 | hyde/detailed                              | 0.3296   | +0.0104   | +3.25%\n",
      "   7 | query_refinement/keyword_focused           | 0.3262   | +0.0070   | +2.18%\n",
      "   8 | term_expansion/context_addition            | 0.3212   | +0.0020   | +0.62%\n",
      "   9 | term_expansion/abbreviation_synonym        | 0.3201   | +0.0009   | +0.29%\n",
      "  10 | hyde/basic                                 | 0.3136   | -0.0056   | -1.74%\n",
      "  11 | query_refinement/formal                    | 0.3010   | -0.0182   | -5.69%\n",
      "  12 | domain_adaptation/accounting_perspective   | 0.2990   | -0.0202   | -6.32%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | hyde/financial_terminology                 | 0.6767      | +0.0533     | +8.56%\n",
      "   2 | hyde/detailed                              | 0.6622      | +0.0389     | +6.24%\n",
      "   3 | hyde/basic                                 | 0.6456      | +0.0222     | +3.57%\n",
      "   4 | term_expansion/abbreviation_synonym        | 0.6433      | +0.0200     | +3.21%\n",
      "   5 | chain_of_thought/step_by_step              | 0.6422      | +0.0189     | +3.03%\n",
      "   6 | domain_adaptation/10k_language             | 0.6356      | +0.0122     | +1.96%\n",
      "   7 | query_refinement/clarification             | 0.6278      | +0.0044     | +0.71%\n",
      "   8 | term_expansion/context_addition            | 0.6267      | +0.0033     | +0.53%\n",
      "   9 | chain_of_thought/explicit_context          | 0.6211      | -0.0022     | -0.36%\n",
      "  10 | domain_adaptation/accounting_perspective   | 0.6200      | -0.0033     | -0.53%\n",
      "  11 | query_refinement/formal                    | 0.6100      | -0.0133     | -2.14%\n",
      "  12 | query_refinement/keyword_focused           | 0.6033      | -0.0200     | -3.21%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | domain_adaptation/10k_language             | 0.0756         | +0.0062        | +8.87%\n",
      "   2 | hyde/financial_terminology                 | 0.0726         | +0.0032        | +4.54%\n",
      "   3 | chain_of_thought/explicit_context          | 0.0722         | +0.0028        | +4.00%\n",
      "   4 | hyde/detailed                              | 0.0716         | +0.0022        | +3.16%\n",
      "   5 | query_refinement/clarification             | 0.0702         | +0.0008        | +1.15%\n",
      "   6 | term_expansion/context_addition            | 0.0689         | -0.0005        | -0.75%\n",
      "   7 | chain_of_thought/step_by_step              | 0.0687         | -0.0007        | -0.96%\n",
      "   8 | term_expansion/abbreviation_synonym        | 0.0678         | -0.0016        | -2.24%\n",
      "   9 | domain_adaptation/accounting_perspective   | 0.0678         | -0.0016        | -2.29%\n",
      "  10 | hyde/basic                                 | 0.0668         | -0.0026        | -3.79%\n",
      "  11 | query_refinement/formal                    | 0.0655         | -0.0039        | -5.60%\n",
      "  12 | query_refinement/keyword_focused           | 0.0648         | -0.0046        | -6.68%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS BY EXPANSION CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Category: CHAIN OF THOUGHT\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: +0.0188\n",
      "  Avg Text MRR improvement: +0.0421\n",
      "  Variants:\n",
      "    - step_by_step                   Page: +0.0131, Text: +0.0278\n",
      "    - explicit_context               Page: +0.0245, Text: +0.0563\n",
      "\n",
      "Category: DOMAIN ADAPTATION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0117\n",
      "  Avg Text MRR improvement: +0.0091\n",
      "  Variants:\n",
      "    - accounting_perspective         Page: -0.0415, Text: -0.0202\n",
      "    - 10k_language                   Page: +0.0182, Text: +0.0384\n",
      "\n",
      "Category: HYDE\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: +0.0139\n",
      "  Avg Text MRR improvement: +0.0165\n",
      "  Variants:\n",
      "    - basic                          Page: -0.0144, Text: -0.0056\n",
      "    - detailed                       Page: +0.0110, Text: +0.0104\n",
      "    - financial_terminology          Page: +0.0450, Text: +0.0446\n",
      "\n",
      "Category: QUERY REFINEMENT\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: -0.0120\n",
      "  Avg Text MRR improvement: +0.0136\n",
      "  Variants:\n",
      "    - clarification                  Page: +0.0233, Text: +0.0521\n",
      "    - formal                         Page: -0.0409, Text: -0.0182\n",
      "    - keyword_focused                Page: -0.0184, Text: +0.0070\n",
      "\n",
      "Category: TERM EXPANSION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0154\n",
      "  Avg Text MRR improvement: +0.0014\n",
      "  Variants:\n",
      "    - abbreviation_synonym           Page: -0.0241, Text: +0.0009\n",
      "    - context_addition               Page: -0.0067, Text: +0.0020\n",
      "\n",
      "================================================================================\n",
      "BEST AND WORST PERFORMERS\n",
      "================================================================================\n",
      "\n",
      "Best Page MRR Improvement:\n",
      "  Method: hyde/financial_terminology\n",
      "  MRR: 0.5140 (Δ +0.0450, +9.60%)\n",
      "\n",
      "Worst Page MRR Improvement:\n",
      "  Method: domain_adaptation/accounting_perspective\n",
      "  MRR: 0.4276 (Δ -0.0415, -8.84%)\n",
      "\n",
      "Best Text MRR Improvement:\n",
      "  Method: chain_of_thought/explicit_context\n",
      "  MRR: 0.3755 (Δ +0.0563, +17.64%)\n",
      "\n",
      "Worst Text MRR Improvement:\n",
      "  Method: domain_adaptation/accounting_perspective\n",
      "  MRR: 0.2990 (Δ -0.0202, -6.32%)\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "• 6/12 (50.0%) methods improved Page MRR over baseline\n",
      "• 9/12 (75.0%) methods improved Text MRR over baseline\n",
      "• Average Page MRR change: -0.0009 (-0.19%)\n",
      "• Average Text MRR change: +0.0163 (+5.11%)\n",
      "\n",
      "================================================================================\n",
      "END OF REPORT - MODE: SINGLEDOC\n",
      "================================================================================\n",
      "\n",
      "✓ Report saved to: expansion_report_voyage_voyage-finance-2_chunk512_k20_both.txt\n",
      "✓ CSV saved to: expansion_metrics_voyage_voyage-finance-2_chunk512_k20_both.csv\n",
      "  Rows: 24\n",
      "  Columns: 37\n",
      "\n",
      "================================================================================\n",
      "SCANNING FOR QUERY EXPANSION RESULTS\n",
      "================================================================================\n",
      "  Provider: voyage\n",
      "  Model: voyage-3-large\n",
      "  Chunk Size: 512\n",
      "  K: 20\n",
      "  Mode: both (global + singledoc)\n",
      "  Directory: ../../evaluation_results/query_enhancement\n",
      "\n",
      "  ✓ Found: hyde_basic_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_detailed_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_formal_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_global.json\n",
      "  ✓ Found: hyde_basic_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: hyde_detailed_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_formal_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "  ✓ Found: domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_singledoc.json\n",
      "\n",
      "✓ Found 24 expansion result file(s)\n",
      "\n",
      "================================================================================\n",
      "QUERY EXPANSION COMPARISON REPORT - MODE: GLOBAL\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Provider: voyage\n",
      "  Model: voyage-3-large\n",
      "  Chunk Size: 512\n",
      "  K (retrieved): 20\n",
      "  Mode: global\n",
      "  Expansion methods found: 12\n",
      "\n",
      "================================================================================\n",
      "BASELINE PERFORMANCE (Original Queries - No Expansion)\n",
      "================================================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5177\n",
      "  Recall:    0.8267\n",
      "  Precision: 0.0640\n",
      "  F1:        0.1173\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3774\n",
      "  Recall:    0.6322\n",
      "  Precision: 0.0533\n",
      "  F1:        0.0958\n",
      "\n",
      "================================================================================\n",
      "EXPANSION METHODS - DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / abbreviation_synonym\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5633 (Δ +0.0456, +8.80%)\n",
      "  Recall:    0.8478 (Δ +0.0211, +2.55%)\n",
      "  Precision: 0.0643 (Δ +0.0003, +0.52%)\n",
      "  F1:        0.1180 (Δ +0.0007, +0.59%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4143 (Δ +0.0369, +9.78%)\n",
      "  Recall:    0.6256 (Δ -0.0067, -1.05%)\n",
      "  Precision: 0.0533 (Δ +0.0000, +0.00%)\n",
      "  F1:        0.0956 (Δ -0.0002, -0.23%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / formal\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5594 (Δ +0.0417, +8.04%)\n",
      "  Recall:    0.8356 (Δ +0.0089, +1.08%)\n",
      "  Precision: 0.0637 (Δ -0.0003, -0.52%)\n",
      "  F1:        0.1168 (Δ -0.0005, -0.43%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4090 (Δ +0.0315, +8.36%)\n",
      "  Recall:    0.6256 (Δ -0.0067, -1.05%)\n",
      "  Precision: 0.0553 (Δ +0.0020, +3.75%)\n",
      "  F1:        0.0989 (Δ +0.0031, +3.23%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / context_addition\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5283 (Δ +0.0106, +2.05%)\n",
      "  Recall:    0.8278 (Δ +0.0011, +0.13%)\n",
      "  Precision: 0.0637 (Δ -0.0003, -0.52%)\n",
      "  F1:        0.1165 (Δ -0.0008, -0.69%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3878 (Δ +0.0104, +2.75%)\n",
      "  Recall:    0.6256 (Δ -0.0067, -1.05%)\n",
      "  Precision: 0.0517 (Δ -0.0017, -3.13%)\n",
      "  F1:        0.0931 (Δ -0.0027, -2.77%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / clarification\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5220 (Δ +0.0043, +0.83%)\n",
      "  Recall:    0.8189 (Δ -0.0078, -0.94%)\n",
      "  Precision: 0.0627 (Δ -0.0013, -2.08%)\n",
      "  F1:        0.1150 (Δ -0.0023, -1.97%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3820 (Δ +0.0045, +1.20%)\n",
      "  Recall:    0.6156 (Δ -0.0167, -2.64%)\n",
      "  Precision: 0.0530 (Δ -0.0003, -0.63%)\n",
      "  F1:        0.0948 (Δ -0.0010, -1.02%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / explicit_context\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5190 (Δ +0.0013, +0.25%)\n",
      "  Recall:    0.8289 (Δ +0.0022, +0.27%)\n",
      "  Precision: 0.0640 (Δ +0.0000, +0.00%)\n",
      "  F1:        0.1173 (Δ -0.0000, -0.01%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3931 (Δ +0.0157, +4.15%)\n",
      "  Recall:    0.6222 (Δ -0.0100, -1.58%)\n",
      "  Precision: 0.0523 (Δ -0.0010, -1.88%)\n",
      "  F1:        0.0941 (Δ -0.0017, -1.75%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / accounting_perspective\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5088 (Δ -0.0089, -1.72%)\n",
      "  Recall:    0.8500 (Δ +0.0233, +2.82%)\n",
      "  Precision: 0.0637 (Δ -0.0003, -0.52%)\n",
      "  F1:        0.1171 (Δ -0.0002, -0.18%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3686 (Δ -0.0088, -2.34%)\n",
      "  Recall:    0.6344 (Δ +0.0022, +0.35%)\n",
      "  Precision: 0.0540 (Δ +0.0007, +1.25%)\n",
      "  F1:        0.0968 (Δ +0.0010, +1.09%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / 10k_language\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4928 (Δ -0.0249, -4.82%)\n",
      "  Recall:    0.7956 (Δ -0.0311, -3.76%)\n",
      "  Precision: 0.0587 (Δ -0.0053, -8.33%)\n",
      "  F1:        0.1080 (Δ -0.0094, -8.00%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3593 (Δ -0.0181, -4.80%)\n",
      "  Recall:    0.5956 (Δ -0.0367, -5.80%)\n",
      "  Precision: 0.0507 (Δ -0.0027, -5.00%)\n",
      "  F1:        0.0911 (Δ -0.0047, -4.93%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / keyword_focused\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4727 (Δ -0.0451, -8.70%)\n",
      "  Recall:    0.8222 (Δ -0.0044, -0.54%)\n",
      "  Precision: 0.0627 (Δ -0.0013, -2.08%)\n",
      "  F1:        0.1150 (Δ -0.0023, -1.95%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3543 (Δ -0.0231, -6.12%)\n",
      "  Recall:    0.6389 (Δ +0.0067, +1.05%)\n",
      "  Precision: 0.0540 (Δ +0.0007, +1.25%)\n",
      "  F1:        0.0969 (Δ +0.0011, +1.13%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / basic\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4130 (Δ -0.1048, -20.24%)\n",
      "  Recall:    0.7322 (Δ -0.0944, -11.42%)\n",
      "  Precision: 0.0573 (Δ -0.0067, -10.42%)\n",
      "  F1:        0.1049 (Δ -0.0125, -10.63%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2736 (Δ -0.1038, -27.49%)\n",
      "  Recall:    0.5500 (Δ -0.0822, -13.01%)\n",
      "  Precision: 0.0397 (Δ -0.0137, -25.62%)\n",
      "  F1:        0.0730 (Δ -0.0228, -23.81%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / financial_terminology\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3939 (Δ -0.1239, -23.93%)\n",
      "  Recall:    0.7144 (Δ -0.1122, -13.58%)\n",
      "  Precision: 0.0553 (Δ -0.0087, -13.54%)\n",
      "  F1:        0.1016 (Δ -0.0158, -13.44%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2469 (Δ -0.1305, -34.59%)\n",
      "  Recall:    0.5233 (Δ -0.1089, -17.22%)\n",
      "  Precision: 0.0350 (Δ -0.0183, -34.38%)\n",
      "  F1:        0.0648 (Δ -0.0310, -32.34%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / detailed\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3837 (Δ -0.1340, -25.88%)\n",
      "  Recall:    0.7311 (Δ -0.0956, -11.56%)\n",
      "  Precision: 0.0560 (Δ -0.0080, -12.50%)\n",
      "  F1:        0.1028 (Δ -0.0145, -12.37%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2413 (Δ -0.1362, -36.08%)\n",
      "  Recall:    0.5333 (Δ -0.0989, -15.64%)\n",
      "  Precision: 0.0377 (Δ -0.0157, -29.38%)\n",
      "  F1:        0.0694 (Δ -0.0264, -27.61%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / step_by_step\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.3768 (Δ -0.1410, -27.23%)\n",
      "  Recall:    0.7322 (Δ -0.0944, -11.42%)\n",
      "  Precision: 0.0553 (Δ -0.0087, -13.54%)\n",
      "  F1:        0.1017 (Δ -0.0157, -13.36%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.2456 (Δ -0.1318, -34.93%)\n",
      "  Recall:    0.5500 (Δ -0.0822, -13.01%)\n",
      "  Precision: 0.0393 (Δ -0.0140, -26.25%)\n",
      "  F1:        0.0723 (Δ -0.0235, -24.55%)\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.5633   | +0.0456   | +8.80%\n",
      "   2 | query_refinement/formal                    | 0.5594   | +0.0417   | +8.04%\n",
      "   3 | term_expansion/context_addition            | 0.5283   | +0.0106   | +2.05%\n",
      "   4 | query_refinement/clarification             | 0.5220   | +0.0043   | +0.83%\n",
      "   5 | chain_of_thought/explicit_context          | 0.5190   | +0.0013   | +0.25%\n",
      "   6 | domain_adaptation/accounting_perspective   | 0.5088   | -0.0089   | -1.72%\n",
      "   7 | domain_adaptation/10k_language             | 0.4928   | -0.0249   | -4.82%\n",
      "   8 | query_refinement/keyword_focused           | 0.4727   | -0.0451   | -8.70%\n",
      "   9 | hyde/basic                                 | 0.4130   | -0.1048   | -20.24%\n",
      "  10 | hyde/financial_terminology                 | 0.3939   | -0.1239   | -23.93%\n",
      "  11 | hyde/detailed                              | 0.3837   | -0.1340   | -25.88%\n",
      "  12 | chain_of_thought/step_by_step              | 0.3768   | -0.1410   | -27.23%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | domain_adaptation/accounting_perspective   | 0.8500      | +0.0233     | +2.82%\n",
      "   2 | term_expansion/abbreviation_synonym        | 0.8478      | +0.0211     | +2.55%\n",
      "   3 | query_refinement/formal                    | 0.8356      | +0.0089     | +1.08%\n",
      "   4 | chain_of_thought/explicit_context          | 0.8289      | +0.0022     | +0.27%\n",
      "   5 | term_expansion/context_addition            | 0.8278      | +0.0011     | +0.13%\n",
      "   6 | query_refinement/keyword_focused           | 0.8222      | -0.0044     | -0.54%\n",
      "   7 | query_refinement/clarification             | 0.8189      | -0.0078     | -0.94%\n",
      "   8 | domain_adaptation/10k_language             | 0.7956      | -0.0311     | -3.76%\n",
      "   9 | hyde/basic                                 | 0.7322      | -0.0944     | -11.42%\n",
      "  10 | chain_of_thought/step_by_step              | 0.7322      | -0.0944     | -11.42%\n",
      "  11 | hyde/detailed                              | 0.7311      | -0.0956     | -11.56%\n",
      "  12 | hyde/financial_terminology                 | 0.7144      | -0.1122     | -13.58%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.0643         | +0.0003        | +0.52%\n",
      "   2 | chain_of_thought/explicit_context          | 0.0640         | +0.0000        | +0.00%\n",
      "   3 | query_refinement/formal                    | 0.0637         | -0.0003        | -0.52%\n",
      "   4 | term_expansion/context_addition            | 0.0637         | -0.0003        | -0.52%\n",
      "   5 | domain_adaptation/accounting_perspective   | 0.0637         | -0.0003        | -0.52%\n",
      "   6 | query_refinement/clarification             | 0.0627         | -0.0013        | -2.08%\n",
      "   7 | query_refinement/keyword_focused           | 0.0627         | -0.0013        | -2.08%\n",
      "   8 | domain_adaptation/10k_language             | 0.0587         | -0.0053        | -8.33%\n",
      "   9 | hyde/basic                                 | 0.0573         | -0.0067        | -10.42%\n",
      "  10 | hyde/detailed                              | 0.0560         | -0.0080        | -12.50%\n",
      "  11 | hyde/financial_terminology                 | 0.0553         | -0.0087        | -13.54%\n",
      "  12 | chain_of_thought/step_by_step              | 0.0553         | -0.0087        | -13.54%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.4143   | +0.0369   | +9.78%\n",
      "   2 | query_refinement/formal                    | 0.4090   | +0.0315   | +8.36%\n",
      "   3 | chain_of_thought/explicit_context          | 0.3931   | +0.0157   | +4.15%\n",
      "   4 | term_expansion/context_addition            | 0.3878   | +0.0104   | +2.75%\n",
      "   5 | query_refinement/clarification             | 0.3820   | +0.0045   | +1.20%\n",
      "   6 | domain_adaptation/accounting_perspective   | 0.3686   | -0.0088   | -2.34%\n",
      "   7 | domain_adaptation/10k_language             | 0.3593   | -0.0181   | -4.80%\n",
      "   8 | query_refinement/keyword_focused           | 0.3543   | -0.0231   | -6.12%\n",
      "   9 | hyde/basic                                 | 0.2736   | -0.1038   | -27.49%\n",
      "  10 | hyde/financial_terminology                 | 0.2469   | -0.1305   | -34.59%\n",
      "  11 | chain_of_thought/step_by_step              | 0.2456   | -0.1318   | -34.93%\n",
      "  12 | hyde/detailed                              | 0.2413   | -0.1362   | -36.08%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/keyword_focused           | 0.6389      | +0.0067     | +1.05%\n",
      "   2 | domain_adaptation/accounting_perspective   | 0.6344      | +0.0022     | +0.35%\n",
      "   3 | query_refinement/formal                    | 0.6256      | -0.0067     | -1.05%\n",
      "   4 | term_expansion/abbreviation_synonym        | 0.6256      | -0.0067     | -1.05%\n",
      "   5 | term_expansion/context_addition            | 0.6256      | -0.0067     | -1.05%\n",
      "   6 | chain_of_thought/explicit_context          | 0.6222      | -0.0100     | -1.58%\n",
      "   7 | query_refinement/clarification             | 0.6156      | -0.0167     | -2.64%\n",
      "   8 | domain_adaptation/10k_language             | 0.5956      | -0.0367     | -5.80%\n",
      "   9 | hyde/basic                                 | 0.5500      | -0.0822     | -13.01%\n",
      "  10 | chain_of_thought/step_by_step              | 0.5500      | -0.0822     | -13.01%\n",
      "  11 | hyde/detailed                              | 0.5333      | -0.0989     | -15.64%\n",
      "  12 | hyde/financial_terminology                 | 0.5233      | -0.1089     | -17.22%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.0553         | +0.0020        | +3.75%\n",
      "   2 | query_refinement/keyword_focused           | 0.0540         | +0.0007        | +1.25%\n",
      "   3 | domain_adaptation/accounting_perspective   | 0.0540         | +0.0007        | +1.25%\n",
      "   4 | term_expansion/abbreviation_synonym        | 0.0533         | +0.0000        | +0.00%\n",
      "   5 | query_refinement/clarification             | 0.0530         | -0.0003        | -0.63%\n",
      "   6 | chain_of_thought/explicit_context          | 0.0523         | -0.0010        | -1.88%\n",
      "   7 | term_expansion/context_addition            | 0.0517         | -0.0017        | -3.13%\n",
      "   8 | domain_adaptation/10k_language             | 0.0507         | -0.0027        | -5.00%\n",
      "   9 | hyde/basic                                 | 0.0397         | -0.0137        | -25.62%\n",
      "  10 | chain_of_thought/step_by_step              | 0.0393         | -0.0140        | -26.25%\n",
      "  11 | hyde/detailed                              | 0.0377         | -0.0157        | -29.38%\n",
      "  12 | hyde/financial_terminology                 | 0.0350         | -0.0183        | -34.38%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS BY EXPANSION CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Category: CHAIN OF THOUGHT\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0698\n",
      "  Avg Text MRR improvement: -0.0581\n",
      "  Variants:\n",
      "    - step_by_step                   Page: -0.1410, Text: -0.1318\n",
      "    - explicit_context               Page: +0.0013, Text: +0.0157\n",
      "\n",
      "Category: DOMAIN ADAPTATION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0169\n",
      "  Avg Text MRR improvement: -0.0135\n",
      "  Variants:\n",
      "    - accounting_perspective         Page: -0.0089, Text: -0.0088\n",
      "    - 10k_language                   Page: -0.0249, Text: -0.0181\n",
      "\n",
      "Category: HYDE\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: -0.1209\n",
      "  Avg Text MRR improvement: -0.1235\n",
      "  Variants:\n",
      "    - basic                          Page: -0.1048, Text: -0.1038\n",
      "    - detailed                       Page: -0.1340, Text: -0.1362\n",
      "    - financial_terminology          Page: -0.1239, Text: -0.1305\n",
      "\n",
      "Category: QUERY REFINEMENT\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: +0.0003\n",
      "  Avg Text MRR improvement: +0.0043\n",
      "  Variants:\n",
      "    - clarification                  Page: +0.0043, Text: +0.0045\n",
      "    - formal                         Page: +0.0417, Text: +0.0315\n",
      "    - keyword_focused                Page: -0.0451, Text: -0.0231\n",
      "\n",
      "Category: TERM EXPANSION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: +0.0281\n",
      "  Avg Text MRR improvement: +0.0237\n",
      "  Variants:\n",
      "    - abbreviation_synonym           Page: +0.0456, Text: +0.0369\n",
      "    - context_addition               Page: +0.0106, Text: +0.0104\n",
      "\n",
      "================================================================================\n",
      "BEST AND WORST PERFORMERS\n",
      "================================================================================\n",
      "\n",
      "Best Page MRR Improvement:\n",
      "  Method: term_expansion/abbreviation_synonym\n",
      "  MRR: 0.5633 (Δ +0.0456, +8.80%)\n",
      "\n",
      "Worst Page MRR Improvement:\n",
      "  Method: chain_of_thought/step_by_step\n",
      "  MRR: 0.3768 (Δ -0.1410, -27.23%)\n",
      "\n",
      "Best Text MRR Improvement:\n",
      "  Method: term_expansion/abbreviation_synonym\n",
      "  MRR: 0.4143 (Δ +0.0369, +9.78%)\n",
      "\n",
      "Worst Text MRR Improvement:\n",
      "  Method: hyde/detailed\n",
      "  MRR: 0.2413 (Δ -0.1362, -36.08%)\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "• 5/12 (41.7%) methods improved Page MRR over baseline\n",
      "• 5/12 (41.7%) methods improved Text MRR over baseline\n",
      "• Average Page MRR change: -0.0399 (-7.71%)\n",
      "• Average Text MRR change: -0.0378 (-10.01%)\n",
      "\n",
      "================================================================================\n",
      "END OF REPORT - MODE: GLOBAL\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY EXPANSION COMPARISON REPORT - MODE: SINGLEDOC\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Provider: voyage\n",
      "  Model: voyage-3-large\n",
      "  Chunk Size: 512\n",
      "  K (retrieved): 20\n",
      "  Mode: singledoc\n",
      "  Expansion methods found: 12\n",
      "\n",
      "================================================================================\n",
      "BASELINE PERFORMANCE (Original Queries - No Expansion)\n",
      "================================================================================\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5935\n",
      "  Recall:    0.9267\n",
      "  Precision: 0.1011\n",
      "  F1:        0.1729\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4349\n",
      "  Recall:    0.7044\n",
      "  Precision: 0.0737\n",
      "  F1:        0.1286\n",
      "\n",
      "================================================================================\n",
      "EXPANSION METHODS - DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / abbreviation_synonym\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.6355 (Δ +0.0420, +7.08%)\n",
      "  Recall:    0.9111 (Δ -0.0156, -1.68%)\n",
      "  Precision: 0.0955 (Δ -0.0056, -5.58%)\n",
      "  F1:        0.1655 (Δ -0.0074, -4.30%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4678 (Δ +0.0328, +7.55%)\n",
      "  Recall:    0.6922 (Δ -0.0122, -1.74%)\n",
      "  Precision: 0.0726 (Δ -0.0010, -1.39%)\n",
      "  F1:        0.1270 (Δ -0.0015, -1.20%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / formal\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.6282 (Δ +0.0347, +5.85%)\n",
      "  Recall:    0.9300 (Δ +0.0033, +0.36%)\n",
      "  Precision: 0.0978 (Δ -0.0034, -3.35%)\n",
      "  F1:        0.1683 (Δ -0.0046, -2.65%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4567 (Δ +0.0217, +5.00%)\n",
      "  Recall:    0.6978 (Δ -0.0067, -0.95%)\n",
      "  Precision: 0.0751 (Δ +0.0014, +1.94%)\n",
      "  F1:        0.1306 (Δ +0.0020, +1.58%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / clarification\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.6007 (Δ +0.0072, +1.21%)\n",
      "  Recall:    0.9144 (Δ -0.0122, -1.32%)\n",
      "  Precision: 0.0969 (Δ -0.0042, -4.16%)\n",
      "  F1:        0.1656 (Δ -0.0073, -4.22%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4415 (Δ +0.0065, +1.50%)\n",
      "  Recall:    0.6844 (Δ -0.0200, -2.84%)\n",
      "  Precision: 0.0732 (Δ -0.0005, -0.63%)\n",
      "  F1:        0.1273 (Δ -0.0012, -0.94%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / accounting_perspective\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5959 (Δ +0.0024, +0.41%)\n",
      "  Recall:    0.9200 (Δ -0.0067, -0.72%)\n",
      "  Precision: 0.0983 (Δ -0.0028, -2.78%)\n",
      "  F1:        0.1698 (Δ -0.0031, -1.80%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4315 (Δ -0.0034, -0.79%)\n",
      "  Recall:    0.6911 (Δ -0.0133, -1.89%)\n",
      "  Precision: 0.0759 (Δ +0.0022, +3.04%)\n",
      "  F1:        0.1321 (Δ +0.0035, +2.74%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: term_expansion / context_addition\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5880 (Δ -0.0055, -0.92%)\n",
      "  Recall:    0.9300 (Δ +0.0033, +0.36%)\n",
      "  Precision: 0.1028 (Δ +0.0016, +1.61%)\n",
      "  F1:        0.1753 (Δ +0.0024, +1.38%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4361 (Δ +0.0012, +0.27%)\n",
      "  Recall:    0.7111 (Δ +0.0067, +0.95%)\n",
      "  Precision: 0.0736 (Δ -0.0000, -0.03%)\n",
      "  F1:        0.1288 (Δ +0.0002, +0.19%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / explicit_context\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5879 (Δ -0.0056, -0.94%)\n",
      "  Recall:    0.8967 (Δ -0.0300, -3.24%)\n",
      "  Precision: 0.0960 (Δ -0.0052, -5.13%)\n",
      "  F1:        0.1636 (Δ -0.0093, -5.40%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4427 (Δ +0.0077, +1.77%)\n",
      "  Recall:    0.6844 (Δ -0.0200, -2.84%)\n",
      "  Precision: 0.0728 (Δ -0.0008, -1.11%)\n",
      "  F1:        0.1267 (Δ -0.0019, -1.45%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: domain_adaptation / 10k_language\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5708 (Δ -0.0227, -3.82%)\n",
      "  Recall:    0.9078 (Δ -0.0189, -2.04%)\n",
      "  Precision: 0.0948 (Δ -0.0064, -6.31%)\n",
      "  F1:        0.1636 (Δ -0.0093, -5.39%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4164 (Δ -0.0186, -4.27%)\n",
      "  Recall:    0.6778 (Δ -0.0267, -3.79%)\n",
      "  Precision: 0.0728 (Δ -0.0009, -1.20%)\n",
      "  F1:        0.1269 (Δ -0.0016, -1.27%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: query_refinement / keyword_focused\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5650 (Δ -0.0285, -4.81%)\n",
      "  Recall:    0.9211 (Δ -0.0056, -0.60%)\n",
      "  Precision: 0.0974 (Δ -0.0037, -3.66%)\n",
      "  F1:        0.1678 (Δ -0.0051, -2.94%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.4172 (Δ -0.0178, -4.09%)\n",
      "  Recall:    0.7000 (Δ -0.0044, -0.63%)\n",
      "  Precision: 0.0748 (Δ +0.0011, +1.48%)\n",
      "  F1:        0.1301 (Δ +0.0015, +1.17%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / basic\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.5171 (Δ -0.0764, -12.88%)\n",
      "  Recall:    0.8756 (Δ -0.0511, -5.52%)\n",
      "  Precision: 0.0964 (Δ -0.0048, -4.72%)\n",
      "  F1:        0.1650 (Δ -0.0079, -4.54%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3568 (Δ -0.0782, -17.97%)\n",
      "  Recall:    0.6578 (Δ -0.0467, -6.62%)\n",
      "  Precision: 0.0624 (Δ -0.0112, -15.23%)\n",
      "  F1:        0.1106 (Δ -0.0179, -13.95%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / financial_terminology\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4964 (Δ -0.0971, -16.36%)\n",
      "  Recall:    0.8567 (Δ -0.0700, -7.55%)\n",
      "  Precision: 0.0964 (Δ -0.0048, -4.72%)\n",
      "  F1:        0.1643 (Δ -0.0086, -4.98%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3191 (Δ -0.1159, -26.64%)\n",
      "  Recall:    0.6489 (Δ -0.0556, -7.89%)\n",
      "  Precision: 0.0591 (Δ -0.0146, -19.79%)\n",
      "  F1:        0.1053 (Δ -0.0233, -18.13%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: hyde / detailed\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4947 (Δ -0.0988, -16.65%)\n",
      "  Recall:    0.8433 (Δ -0.0833, -8.99%)\n",
      "  Precision: 0.0890 (Δ -0.0122, -12.03%)\n",
      "  F1:        0.1551 (Δ -0.0178, -10.29%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3147 (Δ -0.1202, -27.64%)\n",
      "  Recall:    0.6144 (Δ -0.0900, -12.78%)\n",
      "  Precision: 0.0584 (Δ -0.0153, -20.72%)\n",
      "  F1:        0.1034 (Δ -0.0252, -19.58%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: chain_of_thought / step_by_step\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Page-Based Metrics:\n",
      "  MRR:       0.4717 (Δ -0.1218, -20.53%)\n",
      "  Recall:    0.8544 (Δ -0.0722, -7.79%)\n",
      "  Precision: 0.0909 (Δ -0.0103, -10.18%)\n",
      "  F1:        0.1572 (Δ -0.0157, -9.09%)\n",
      "\n",
      "Text-Based Metrics:\n",
      "  MRR:       0.3182 (Δ -0.1168, -26.85%)\n",
      "  Recall:    0.6478 (Δ -0.0567, -8.04%)\n",
      "  Precision: 0.0624 (Δ -0.0113, -15.31%)\n",
      "  F1:        0.1105 (Δ -0.0181, -14.05%)\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.6355   | +0.0420   | +7.08%\n",
      "   2 | query_refinement/formal                    | 0.6282   | +0.0347   | +5.85%\n",
      "   3 | query_refinement/clarification             | 0.6007   | +0.0072   | +1.21%\n",
      "   4 | domain_adaptation/accounting_perspective   | 0.5959   | +0.0024   | +0.41%\n",
      "   5 | term_expansion/context_addition            | 0.5880   | -0.0055   | -0.92%\n",
      "   6 | chain_of_thought/explicit_context          | 0.5879   | -0.0056   | -0.94%\n",
      "   7 | domain_adaptation/10k_language             | 0.5708   | -0.0227   | -3.82%\n",
      "   8 | query_refinement/keyword_focused           | 0.5650   | -0.0285   | -4.81%\n",
      "   9 | hyde/basic                                 | 0.5171   | -0.0764   | -12.88%\n",
      "  10 | hyde/financial_terminology                 | 0.4964   | -0.0971   | -16.36%\n",
      "  11 | hyde/detailed                              | 0.4947   | -0.0988   | -16.65%\n",
      "  12 | chain_of_thought/step_by_step              | 0.4717   | -0.1218   | -20.53%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | query_refinement/formal                    | 0.9300      | +0.0033     | +0.36%\n",
      "   2 | term_expansion/context_addition            | 0.9300      | +0.0033     | +0.36%\n",
      "   3 | query_refinement/keyword_focused           | 0.9211      | -0.0056     | -0.60%\n",
      "   4 | domain_adaptation/accounting_perspective   | 0.9200      | -0.0067     | -0.72%\n",
      "   5 | query_refinement/clarification             | 0.9144      | -0.0122     | -1.32%\n",
      "   6 | term_expansion/abbreviation_synonym        | 0.9111      | -0.0156     | -1.68%\n",
      "   7 | domain_adaptation/10k_language             | 0.9078      | -0.0189     | -2.04%\n",
      "   8 | chain_of_thought/explicit_context          | 0.8967      | -0.0300     | -3.24%\n",
      "   9 | hyde/basic                                 | 0.8756      | -0.0511     | -5.52%\n",
      "  10 | hyde/financial_terminology                 | 0.8567      | -0.0700     | -7.55%\n",
      "  11 | chain_of_thought/step_by_step              | 0.8544      | -0.0722     | -7.79%\n",
      "  12 | hyde/detailed                              | 0.8433      | -0.0833     | -8.99%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY PAGE PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Page Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/context_addition            | 0.1028         | +0.0016        | +1.61%\n",
      "   2 | domain_adaptation/accounting_perspective   | 0.0983         | -0.0028        | -2.78%\n",
      "   3 | query_refinement/formal                    | 0.0978         | -0.0034        | -3.35%\n",
      "   4 | query_refinement/keyword_focused           | 0.0974         | -0.0037        | -3.66%\n",
      "   5 | query_refinement/clarification             | 0.0969         | -0.0042        | -4.16%\n",
      "   6 | hyde/financial_terminology                 | 0.0964         | -0.0048        | -4.72%\n",
      "   7 | hyde/basic                                 | 0.0964         | -0.0048        | -4.72%\n",
      "   8 | chain_of_thought/explicit_context          | 0.0960         | -0.0052        | -5.13%\n",
      "   9 | term_expansion/abbreviation_synonym        | 0.0955         | -0.0056        | -5.58%\n",
      "  10 | domain_adaptation/10k_language             | 0.0948         | -0.0064        | -6.31%\n",
      "  11 | chain_of_thought/step_by_step              | 0.0909         | -0.0103        | -10.18%\n",
      "  12 | hyde/detailed                              | 0.0890         | -0.0122        | -12.03%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT MRR IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text MRR | Δ MRR    | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/abbreviation_synonym        | 0.4678   | +0.0328   | +7.55%\n",
      "   2 | query_refinement/formal                    | 0.4567   | +0.0217   | +5.00%\n",
      "   3 | chain_of_thought/explicit_context          | 0.4427   | +0.0077   | +1.77%\n",
      "   4 | query_refinement/clarification             | 0.4415   | +0.0065   | +1.50%\n",
      "   5 | term_expansion/context_addition            | 0.4361   | +0.0012   | +0.27%\n",
      "   6 | domain_adaptation/accounting_perspective   | 0.4315   | -0.0034   | -0.79%\n",
      "   7 | query_refinement/keyword_focused           | 0.4172   | -0.0178   | -4.09%\n",
      "   8 | domain_adaptation/10k_language             | 0.4164   | -0.0186   | -4.27%\n",
      "   9 | hyde/basic                                 | 0.3568   | -0.0782   | -17.97%\n",
      "  10 | hyde/financial_terminology                 | 0.3191   | -0.1159   | -26.64%\n",
      "  11 | chain_of_thought/step_by_step              | 0.3182   | -0.1168   | -26.85%\n",
      "  12 | hyde/detailed                              | 0.3147   | -0.1202   | -27.64%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT RECALL IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Recall | Δ Recall | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | term_expansion/context_addition            | 0.7111      | +0.0067     | +0.95%\n",
      "   2 | query_refinement/keyword_focused           | 0.7000      | -0.0044     | -0.63%\n",
      "   3 | query_refinement/formal                    | 0.6978      | -0.0067     | -0.95%\n",
      "   4 | term_expansion/abbreviation_synonym        | 0.6922      | -0.0122     | -1.74%\n",
      "   5 | domain_adaptation/accounting_perspective   | 0.6911      | -0.0133     | -1.89%\n",
      "   6 | query_refinement/clarification             | 0.6844      | -0.0200     | -2.84%\n",
      "   7 | chain_of_thought/explicit_context          | 0.6844      | -0.0200     | -2.84%\n",
      "   8 | domain_adaptation/10k_language             | 0.6778      | -0.0267     | -3.79%\n",
      "   9 | hyde/basic                                 | 0.6578      | -0.0467     | -6.62%\n",
      "  10 | hyde/financial_terminology                 | 0.6489      | -0.0556     | -7.89%\n",
      "  11 | chain_of_thought/step_by_step              | 0.6478      | -0.0567     | -8.04%\n",
      "  12 | hyde/detailed                              | 0.6144      | -0.0900     | -12.78%\n",
      "\n",
      "================================================================================\n",
      "RANKING BY TEXT PRECISION IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "Rank | Method                                    | Text Precision | Δ Precision | %\n",
      "--------------------------------------------------------------------------------\n",
      "   1 | domain_adaptation/accounting_perspective   | 0.0759         | +0.0022        | +3.04%\n",
      "   2 | query_refinement/formal                    | 0.0751         | +0.0014        | +1.94%\n",
      "   3 | query_refinement/keyword_focused           | 0.0748         | +0.0011        | +1.48%\n",
      "   4 | term_expansion/context_addition            | 0.0736         | -0.0000        | -0.03%\n",
      "   5 | query_refinement/clarification             | 0.0732         | -0.0005        | -0.63%\n",
      "   6 | chain_of_thought/explicit_context          | 0.0728         | -0.0008        | -1.11%\n",
      "   7 | domain_adaptation/10k_language             | 0.0728         | -0.0009        | -1.20%\n",
      "   8 | term_expansion/abbreviation_synonym        | 0.0726         | -0.0010        | -1.39%\n",
      "   9 | hyde/basic                                 | 0.0624         | -0.0112        | -15.23%\n",
      "  10 | chain_of_thought/step_by_step              | 0.0624         | -0.0113        | -15.31%\n",
      "  11 | hyde/financial_terminology                 | 0.0591         | -0.0146        | -19.79%\n",
      "  12 | hyde/detailed                              | 0.0584         | -0.0153        | -20.72%\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS BY EXPANSION CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Category: CHAIN OF THOUGHT\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0637\n",
      "  Avg Text MRR improvement: -0.0545\n",
      "  Variants:\n",
      "    - step_by_step                   Page: -0.1218, Text: -0.1168\n",
      "    - explicit_context               Page: -0.0056, Text: +0.0077\n",
      "\n",
      "Category: DOMAIN ADAPTATION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: -0.0101\n",
      "  Avg Text MRR improvement: -0.0110\n",
      "  Variants:\n",
      "    - accounting_perspective         Page: +0.0024, Text: -0.0034\n",
      "    - 10k_language                   Page: -0.0227, Text: -0.0186\n",
      "\n",
      "Category: HYDE\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: -0.0908\n",
      "  Avg Text MRR improvement: -0.1048\n",
      "  Variants:\n",
      "    - basic                          Page: -0.0764, Text: -0.0782\n",
      "    - detailed                       Page: -0.0988, Text: -0.1202\n",
      "    - financial_terminology          Page: -0.0971, Text: -0.1159\n",
      "\n",
      "Category: QUERY REFINEMENT\n",
      "  Number of variants: 3\n",
      "  Avg Page MRR improvement: +0.0044\n",
      "  Avg Text MRR improvement: +0.0035\n",
      "  Variants:\n",
      "    - clarification                  Page: +0.0072, Text: +0.0065\n",
      "    - formal                         Page: +0.0347, Text: +0.0217\n",
      "    - keyword_focused                Page: -0.0285, Text: -0.0178\n",
      "\n",
      "Category: TERM EXPANSION\n",
      "  Number of variants: 2\n",
      "  Avg Page MRR improvement: +0.0183\n",
      "  Avg Text MRR improvement: +0.0170\n",
      "  Variants:\n",
      "    - abbreviation_synonym           Page: +0.0420, Text: +0.0328\n",
      "    - context_addition               Page: -0.0055, Text: +0.0012\n",
      "\n",
      "================================================================================\n",
      "BEST AND WORST PERFORMERS\n",
      "================================================================================\n",
      "\n",
      "Best Page MRR Improvement:\n",
      "  Method: term_expansion/abbreviation_synonym\n",
      "  MRR: 0.6355 (Δ +0.0420, +7.08%)\n",
      "\n",
      "Worst Page MRR Improvement:\n",
      "  Method: chain_of_thought/step_by_step\n",
      "  MRR: 0.4717 (Δ -0.1218, -20.53%)\n",
      "\n",
      "Best Text MRR Improvement:\n",
      "  Method: term_expansion/abbreviation_synonym\n",
      "  MRR: 0.4678 (Δ +0.0328, +7.55%)\n",
      "\n",
      "Worst Text MRR Improvement:\n",
      "  Method: hyde/detailed\n",
      "  MRR: 0.3147 (Δ -0.1202, -27.64%)\n",
      "\n",
      "================================================================================\n",
      "KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "• 4/12 (33.3%) methods improved Page MRR over baseline\n",
      "• 5/12 (41.7%) methods improved Text MRR over baseline\n",
      "• Average Page MRR change: -0.0308 (-5.20%)\n",
      "• Average Text MRR change: -0.0334 (-7.68%)\n",
      "\n",
      "================================================================================\n",
      "END OF REPORT - MODE: SINGLEDOC\n",
      "================================================================================\n",
      "\n",
      "✓ Report saved to: expansion_report_voyage_voyage-3-large_chunk512_k20_both.txt\n",
      "✓ CSV saved to: expansion_metrics_voyage_voyage-3-large_chunk512_k20_both.csv\n",
      "  Rows: 24\n",
      "  Columns: 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'configuration': {'provider': 'voyage',\n",
       "  'model': 'voyage-3-large',\n",
       "  'chunk_size': 512,\n",
       "  'k': 20,\n",
       "  'mode': None},\n",
       " 'reports': [{'mode': 'global',\n",
       "   'report_text': '\\n================================================================================\\nQUERY EXPANSION COMPARISON REPORT - MODE: GLOBAL\\n================================================================================\\n\\nConfiguration:\\n  Provider: voyage\\n  Model: voyage-3-large\\n  Chunk Size: 512\\n  K (retrieved): 20\\n  Mode: global\\n  Expansion methods found: 12\\n\\n================================================================================\\nBASELINE PERFORMANCE (Original Queries - No Expansion)\\n================================================================================\\n\\nPage-Based Metrics:\\n  MRR:       0.5177\\n  Recall:    0.8267\\n  Precision: 0.0640\\n  F1:        0.1173\\n\\nText-Based Metrics:\\n  MRR:       0.3774\\n  Recall:    0.6322\\n  Precision: 0.0533\\n  F1:        0.0958\\n\\n================================================================================\\nEXPANSION METHODS - DETAILED RESULTS\\n================================================================================\\n\\n--------------------------------------------------------------------------------\\nMethod: term_expansion / abbreviation_synonym\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5633 (Δ +0.0456, +8.80%)\\n  Recall:    0.8478 (Δ +0.0211, +2.55%)\\n  Precision: 0.0643 (Δ +0.0003, +0.52%)\\n  F1:        0.1180 (Δ +0.0007, +0.59%)\\n\\nText-Based Metrics:\\n  MRR:       0.4143 (Δ +0.0369, +9.78%)\\n  Recall:    0.6256 (Δ -0.0067, -1.05%)\\n  Precision: 0.0533 (Δ +0.0000, +0.00%)\\n  F1:        0.0956 (Δ -0.0002, -0.23%)\\n\\n--------------------------------------------------------------------------------\\nMethod: query_refinement / formal\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5594 (Δ +0.0417, +8.04%)\\n  Recall:    0.8356 (Δ +0.0089, +1.08%)\\n  Precision: 0.0637 (Δ -0.0003, -0.52%)\\n  F1:        0.1168 (Δ -0.0005, -0.43%)\\n\\nText-Based Metrics:\\n  MRR:       0.4090 (Δ +0.0315, +8.36%)\\n  Recall:    0.6256 (Δ -0.0067, -1.05%)\\n  Precision: 0.0553 (Δ +0.0020, +3.75%)\\n  F1:        0.0989 (Δ +0.0031, +3.23%)\\n\\n--------------------------------------------------------------------------------\\nMethod: term_expansion / context_addition\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5283 (Δ +0.0106, +2.05%)\\n  Recall:    0.8278 (Δ +0.0011, +0.13%)\\n  Precision: 0.0637 (Δ -0.0003, -0.52%)\\n  F1:        0.1165 (Δ -0.0008, -0.69%)\\n\\nText-Based Metrics:\\n  MRR:       0.3878 (Δ +0.0104, +2.75%)\\n  Recall:    0.6256 (Δ -0.0067, -1.05%)\\n  Precision: 0.0517 (Δ -0.0017, -3.13%)\\n  F1:        0.0931 (Δ -0.0027, -2.77%)\\n\\n--------------------------------------------------------------------------------\\nMethod: query_refinement / clarification\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5220 (Δ +0.0043, +0.83%)\\n  Recall:    0.8189 (Δ -0.0078, -0.94%)\\n  Precision: 0.0627 (Δ -0.0013, -2.08%)\\n  F1:        0.1150 (Δ -0.0023, -1.97%)\\n\\nText-Based Metrics:\\n  MRR:       0.3820 (Δ +0.0045, +1.20%)\\n  Recall:    0.6156 (Δ -0.0167, -2.64%)\\n  Precision: 0.0530 (Δ -0.0003, -0.63%)\\n  F1:        0.0948 (Δ -0.0010, -1.02%)\\n\\n--------------------------------------------------------------------------------\\nMethod: chain_of_thought / explicit_context\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5190 (Δ +0.0013, +0.25%)\\n  Recall:    0.8289 (Δ +0.0022, +0.27%)\\n  Precision: 0.0640 (Δ +0.0000, +0.00%)\\n  F1:        0.1173 (Δ -0.0000, -0.01%)\\n\\nText-Based Metrics:\\n  MRR:       0.3931 (Δ +0.0157, +4.15%)\\n  Recall:    0.6222 (Δ -0.0100, -1.58%)\\n  Precision: 0.0523 (Δ -0.0010, -1.88%)\\n  F1:        0.0941 (Δ -0.0017, -1.75%)\\n\\n--------------------------------------------------------------------------------\\nMethod: domain_adaptation / accounting_perspective\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5088 (Δ -0.0089, -1.72%)\\n  Recall:    0.8500 (Δ +0.0233, +2.82%)\\n  Precision: 0.0637 (Δ -0.0003, -0.52%)\\n  F1:        0.1171 (Δ -0.0002, -0.18%)\\n\\nText-Based Metrics:\\n  MRR:       0.3686 (Δ -0.0088, -2.34%)\\n  Recall:    0.6344 (Δ +0.0022, +0.35%)\\n  Precision: 0.0540 (Δ +0.0007, +1.25%)\\n  F1:        0.0968 (Δ +0.0010, +1.09%)\\n\\n--------------------------------------------------------------------------------\\nMethod: domain_adaptation / 10k_language\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.4928 (Δ -0.0249, -4.82%)\\n  Recall:    0.7956 (Δ -0.0311, -3.76%)\\n  Precision: 0.0587 (Δ -0.0053, -8.33%)\\n  F1:        0.1080 (Δ -0.0094, -8.00%)\\n\\nText-Based Metrics:\\n  MRR:       0.3593 (Δ -0.0181, -4.80%)\\n  Recall:    0.5956 (Δ -0.0367, -5.80%)\\n  Precision: 0.0507 (Δ -0.0027, -5.00%)\\n  F1:        0.0911 (Δ -0.0047, -4.93%)\\n\\n--------------------------------------------------------------------------------\\nMethod: query_refinement / keyword_focused\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.4727 (Δ -0.0451, -8.70%)\\n  Recall:    0.8222 (Δ -0.0044, -0.54%)\\n  Precision: 0.0627 (Δ -0.0013, -2.08%)\\n  F1:        0.1150 (Δ -0.0023, -1.95%)\\n\\nText-Based Metrics:\\n  MRR:       0.3543 (Δ -0.0231, -6.12%)\\n  Recall:    0.6389 (Δ +0.0067, +1.05%)\\n  Precision: 0.0540 (Δ +0.0007, +1.25%)\\n  F1:        0.0969 (Δ +0.0011, +1.13%)\\n\\n--------------------------------------------------------------------------------\\nMethod: hyde / basic\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.4130 (Δ -0.1048, -20.24%)\\n  Recall:    0.7322 (Δ -0.0944, -11.42%)\\n  Precision: 0.0573 (Δ -0.0067, -10.42%)\\n  F1:        0.1049 (Δ -0.0125, -10.63%)\\n\\nText-Based Metrics:\\n  MRR:       0.2736 (Δ -0.1038, -27.49%)\\n  Recall:    0.5500 (Δ -0.0822, -13.01%)\\n  Precision: 0.0397 (Δ -0.0137, -25.62%)\\n  F1:        0.0730 (Δ -0.0228, -23.81%)\\n\\n--------------------------------------------------------------------------------\\nMethod: hyde / financial_terminology\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.3939 (Δ -0.1239, -23.93%)\\n  Recall:    0.7144 (Δ -0.1122, -13.58%)\\n  Precision: 0.0553 (Δ -0.0087, -13.54%)\\n  F1:        0.1016 (Δ -0.0158, -13.44%)\\n\\nText-Based Metrics:\\n  MRR:       0.2469 (Δ -0.1305, -34.59%)\\n  Recall:    0.5233 (Δ -0.1089, -17.22%)\\n  Precision: 0.0350 (Δ -0.0183, -34.38%)\\n  F1:        0.0648 (Δ -0.0310, -32.34%)\\n\\n--------------------------------------------------------------------------------\\nMethod: hyde / detailed\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.3837 (Δ -0.1340, -25.88%)\\n  Recall:    0.7311 (Δ -0.0956, -11.56%)\\n  Precision: 0.0560 (Δ -0.0080, -12.50%)\\n  F1:        0.1028 (Δ -0.0145, -12.37%)\\n\\nText-Based Metrics:\\n  MRR:       0.2413 (Δ -0.1362, -36.08%)\\n  Recall:    0.5333 (Δ -0.0989, -15.64%)\\n  Precision: 0.0377 (Δ -0.0157, -29.38%)\\n  F1:        0.0694 (Δ -0.0264, -27.61%)\\n\\n--------------------------------------------------------------------------------\\nMethod: chain_of_thought / step_by_step\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.3768 (Δ -0.1410, -27.23%)\\n  Recall:    0.7322 (Δ -0.0944, -11.42%)\\n  Precision: 0.0553 (Δ -0.0087, -13.54%)\\n  F1:        0.1017 (Δ -0.0157, -13.36%)\\n\\nText-Based Metrics:\\n  MRR:       0.2456 (Δ -0.1318, -34.93%)\\n  Recall:    0.5500 (Δ -0.0822, -13.01%)\\n  Precision: 0.0393 (Δ -0.0140, -26.25%)\\n  F1:        0.0723 (Δ -0.0235, -24.55%)\\n\\n================================================================================\\nRANKING BY PAGE MRR IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Page MRR | Δ MRR    | %\\n--------------------------------------------------------------------------------\\n   1 | term_expansion/abbreviation_synonym        | 0.5633   | +0.0456   | +8.80%\\n   2 | query_refinement/formal                    | 0.5594   | +0.0417   | +8.04%\\n   3 | term_expansion/context_addition            | 0.5283   | +0.0106   | +2.05%\\n   4 | query_refinement/clarification             | 0.5220   | +0.0043   | +0.83%\\n   5 | chain_of_thought/explicit_context          | 0.5190   | +0.0013   | +0.25%\\n   6 | domain_adaptation/accounting_perspective   | 0.5088   | -0.0089   | -1.72%\\n   7 | domain_adaptation/10k_language             | 0.4928   | -0.0249   | -4.82%\\n   8 | query_refinement/keyword_focused           | 0.4727   | -0.0451   | -8.70%\\n   9 | hyde/basic                                 | 0.4130   | -0.1048   | -20.24%\\n  10 | hyde/financial_terminology                 | 0.3939   | -0.1239   | -23.93%\\n  11 | hyde/detailed                              | 0.3837   | -0.1340   | -25.88%\\n  12 | chain_of_thought/step_by_step              | 0.3768   | -0.1410   | -27.23%\\n\\n================================================================================\\nRANKING BY PAGE RECALL IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Page Recall | Δ Recall | %\\n--------------------------------------------------------------------------------\\n   1 | domain_adaptation/accounting_perspective   | 0.8500      | +0.0233     | +2.82%\\n   2 | term_expansion/abbreviation_synonym        | 0.8478      | +0.0211     | +2.55%\\n   3 | query_refinement/formal                    | 0.8356      | +0.0089     | +1.08%\\n   4 | chain_of_thought/explicit_context          | 0.8289      | +0.0022     | +0.27%\\n   5 | term_expansion/context_addition            | 0.8278      | +0.0011     | +0.13%\\n   6 | query_refinement/keyword_focused           | 0.8222      | -0.0044     | -0.54%\\n   7 | query_refinement/clarification             | 0.8189      | -0.0078     | -0.94%\\n   8 | domain_adaptation/10k_language             | 0.7956      | -0.0311     | -3.76%\\n   9 | hyde/basic                                 | 0.7322      | -0.0944     | -11.42%\\n  10 | chain_of_thought/step_by_step              | 0.7322      | -0.0944     | -11.42%\\n  11 | hyde/detailed                              | 0.7311      | -0.0956     | -11.56%\\n  12 | hyde/financial_terminology                 | 0.7144      | -0.1122     | -13.58%\\n\\n================================================================================\\nRANKING BY PAGE PRECISION IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Page Precision | Δ Precision | %\\n--------------------------------------------------------------------------------\\n   1 | term_expansion/abbreviation_synonym        | 0.0643         | +0.0003        | +0.52%\\n   2 | chain_of_thought/explicit_context          | 0.0640         | +0.0000        | +0.00%\\n   3 | query_refinement/formal                    | 0.0637         | -0.0003        | -0.52%\\n   4 | term_expansion/context_addition            | 0.0637         | -0.0003        | -0.52%\\n   5 | domain_adaptation/accounting_perspective   | 0.0637         | -0.0003        | -0.52%\\n   6 | query_refinement/clarification             | 0.0627         | -0.0013        | -2.08%\\n   7 | query_refinement/keyword_focused           | 0.0627         | -0.0013        | -2.08%\\n   8 | domain_adaptation/10k_language             | 0.0587         | -0.0053        | -8.33%\\n   9 | hyde/basic                                 | 0.0573         | -0.0067        | -10.42%\\n  10 | hyde/detailed                              | 0.0560         | -0.0080        | -12.50%\\n  11 | hyde/financial_terminology                 | 0.0553         | -0.0087        | -13.54%\\n  12 | chain_of_thought/step_by_step              | 0.0553         | -0.0087        | -13.54%\\n\\n================================================================================\\nRANKING BY TEXT MRR IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Text MRR | Δ MRR    | %\\n--------------------------------------------------------------------------------\\n   1 | term_expansion/abbreviation_synonym        | 0.4143   | +0.0369   | +9.78%\\n   2 | query_refinement/formal                    | 0.4090   | +0.0315   | +8.36%\\n   3 | chain_of_thought/explicit_context          | 0.3931   | +0.0157   | +4.15%\\n   4 | term_expansion/context_addition            | 0.3878   | +0.0104   | +2.75%\\n   5 | query_refinement/clarification             | 0.3820   | +0.0045   | +1.20%\\n   6 | domain_adaptation/accounting_perspective   | 0.3686   | -0.0088   | -2.34%\\n   7 | domain_adaptation/10k_language             | 0.3593   | -0.0181   | -4.80%\\n   8 | query_refinement/keyword_focused           | 0.3543   | -0.0231   | -6.12%\\n   9 | hyde/basic                                 | 0.2736   | -0.1038   | -27.49%\\n  10 | hyde/financial_terminology                 | 0.2469   | -0.1305   | -34.59%\\n  11 | chain_of_thought/step_by_step              | 0.2456   | -0.1318   | -34.93%\\n  12 | hyde/detailed                              | 0.2413   | -0.1362   | -36.08%\\n\\n================================================================================\\nRANKING BY TEXT RECALL IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Text Recall | Δ Recall | %\\n--------------------------------------------------------------------------------\\n   1 | query_refinement/keyword_focused           | 0.6389      | +0.0067     | +1.05%\\n   2 | domain_adaptation/accounting_perspective   | 0.6344      | +0.0022     | +0.35%\\n   3 | query_refinement/formal                    | 0.6256      | -0.0067     | -1.05%\\n   4 | term_expansion/abbreviation_synonym        | 0.6256      | -0.0067     | -1.05%\\n   5 | term_expansion/context_addition            | 0.6256      | -0.0067     | -1.05%\\n   6 | chain_of_thought/explicit_context          | 0.6222      | -0.0100     | -1.58%\\n   7 | query_refinement/clarification             | 0.6156      | -0.0167     | -2.64%\\n   8 | domain_adaptation/10k_language             | 0.5956      | -0.0367     | -5.80%\\n   9 | hyde/basic                                 | 0.5500      | -0.0822     | -13.01%\\n  10 | chain_of_thought/step_by_step              | 0.5500      | -0.0822     | -13.01%\\n  11 | hyde/detailed                              | 0.5333      | -0.0989     | -15.64%\\n  12 | hyde/financial_terminology                 | 0.5233      | -0.1089     | -17.22%\\n\\n================================================================================\\nRANKING BY TEXT PRECISION IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Text Precision | Δ Precision | %\\n--------------------------------------------------------------------------------\\n   1 | query_refinement/formal                    | 0.0553         | +0.0020        | +3.75%\\n   2 | query_refinement/keyword_focused           | 0.0540         | +0.0007        | +1.25%\\n   3 | domain_adaptation/accounting_perspective   | 0.0540         | +0.0007        | +1.25%\\n   4 | term_expansion/abbreviation_synonym        | 0.0533         | +0.0000        | +0.00%\\n   5 | query_refinement/clarification             | 0.0530         | -0.0003        | -0.63%\\n   6 | chain_of_thought/explicit_context          | 0.0523         | -0.0010        | -1.88%\\n   7 | term_expansion/context_addition            | 0.0517         | -0.0017        | -3.13%\\n   8 | domain_adaptation/10k_language             | 0.0507         | -0.0027        | -5.00%\\n   9 | hyde/basic                                 | 0.0397         | -0.0137        | -25.62%\\n  10 | chain_of_thought/step_by_step              | 0.0393         | -0.0140        | -26.25%\\n  11 | hyde/detailed                              | 0.0377         | -0.0157        | -29.38%\\n  12 | hyde/financial_terminology                 | 0.0350         | -0.0183        | -34.38%\\n\\n================================================================================\\nANALYSIS BY EXPANSION CATEGORY\\n================================================================================\\n\\nCategory: CHAIN OF THOUGHT\\n  Number of variants: 2\\n  Avg Page MRR improvement: -0.0698\\n  Avg Text MRR improvement: -0.0581\\n  Variants:\\n    - step_by_step                   Page: -0.1410, Text: -0.1318\\n    - explicit_context               Page: +0.0013, Text: +0.0157\\n\\nCategory: DOMAIN ADAPTATION\\n  Number of variants: 2\\n  Avg Page MRR improvement: -0.0169\\n  Avg Text MRR improvement: -0.0135\\n  Variants:\\n    - accounting_perspective         Page: -0.0089, Text: -0.0088\\n    - 10k_language                   Page: -0.0249, Text: -0.0181\\n\\nCategory: HYDE\\n  Number of variants: 3\\n  Avg Page MRR improvement: -0.1209\\n  Avg Text MRR improvement: -0.1235\\n  Variants:\\n    - basic                          Page: -0.1048, Text: -0.1038\\n    - detailed                       Page: -0.1340, Text: -0.1362\\n    - financial_terminology          Page: -0.1239, Text: -0.1305\\n\\nCategory: QUERY REFINEMENT\\n  Number of variants: 3\\n  Avg Page MRR improvement: +0.0003\\n  Avg Text MRR improvement: +0.0043\\n  Variants:\\n    - clarification                  Page: +0.0043, Text: +0.0045\\n    - formal                         Page: +0.0417, Text: +0.0315\\n    - keyword_focused                Page: -0.0451, Text: -0.0231\\n\\nCategory: TERM EXPANSION\\n  Number of variants: 2\\n  Avg Page MRR improvement: +0.0281\\n  Avg Text MRR improvement: +0.0237\\n  Variants:\\n    - abbreviation_synonym           Page: +0.0456, Text: +0.0369\\n    - context_addition               Page: +0.0106, Text: +0.0104\\n\\n================================================================================\\nBEST AND WORST PERFORMERS\\n================================================================================\\n\\nBest Page MRR Improvement:\\n  Method: term_expansion/abbreviation_synonym\\n  MRR: 0.5633 (Δ +0.0456, +8.80%)\\n\\nWorst Page MRR Improvement:\\n  Method: chain_of_thought/step_by_step\\n  MRR: 0.3768 (Δ -0.1410, -27.23%)\\n\\nBest Text MRR Improvement:\\n  Method: term_expansion/abbreviation_synonym\\n  MRR: 0.4143 (Δ +0.0369, +9.78%)\\n\\nWorst Text MRR Improvement:\\n  Method: hyde/detailed\\n  MRR: 0.2413 (Δ -0.1362, -36.08%)\\n\\n================================================================================\\nKEY INSIGHTS\\n================================================================================\\n\\n• 5/12 (41.7%) methods improved Page MRR over baseline\\n• 5/12 (41.7%) methods improved Text MRR over baseline\\n• Average Page MRR change: -0.0399 (-7.71%)\\n• Average Text MRR change: -0.0378 (-10.01%)\\n\\n================================================================================\\nEND OF REPORT - MODE: GLOBAL\\n================================================================================',\n",
       "   'baseline_metrics': {'page_mrr': 0.5177197542166583,\n",
       "    'page_recall': 0.8266666666666667,\n",
       "    'page_precision': 0.064,\n",
       "    'page_f1': 0.11734063262880251,\n",
       "    'text_mrr': 0.3774196564529382,\n",
       "    'text_recall': 0.6322222222222222,\n",
       "    'text_precision': 0.05333333333333334,\n",
       "    'text_f1': 0.09579835623313884},\n",
       "   'metrics_data': {'hyde_basic': {'type': 'hyde',\n",
       "     'subtype': 'basic',\n",
       "     'filename': 'hyde_basic_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.4129570456776339,\n",
       "      'page_recall': 0.7322222222222222,\n",
       "      'page_precision': 0.05733333333333333,\n",
       "      'page_f1': 0.10486730660643703,\n",
       "      'text_mrr': 0.2736495448995449,\n",
       "      'text_recall': 0.55,\n",
       "      'text_precision': 0.03966666666666667,\n",
       "      'text_f1': 0.07298764037894473},\n",
       "     'improvements': {'page_mrr': -0.10476270853902436,\n",
       "      'page_recall': -0.09444444444444444,\n",
       "      'page_precision': -0.006666666666666668,\n",
       "      'page_f1': -0.012473326022365477,\n",
       "      'text_mrr': -0.10377011155339327,\n",
       "      'text_recall': -0.0822222222222222,\n",
       "      'text_precision': -0.013666666666666667,\n",
       "      'text_f1': -0.022810715854194114},\n",
       "     'improvement_percentages': {'page_mrr': -20.235408768115633,\n",
       "      'page_recall': -11.424731182795698,\n",
       "      'page_precision': -10.416666666666668,\n",
       "      'page_f1': -10.630014295068465,\n",
       "      'text_mrr': -27.49462296920212,\n",
       "      'text_recall': -13.00527240773286,\n",
       "      'text_precision': -25.624999999999996,\n",
       "      'text_f1': -23.811176674765704}},\n",
       "    'hyde_detailed': {'type': 'hyde',\n",
       "     'subtype': 'detailed',\n",
       "     'filename': 'hyde_detailed_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.38371980728250077,\n",
       "      'page_recall': 0.7311111111111112,\n",
       "      'page_precision': 0.056,\n",
       "      'page_f1': 0.10282075412510196,\n",
       "      'text_mrr': 0.2412645653566706,\n",
       "      'text_recall': 0.5333333333333333,\n",
       "      'text_precision': 0.03766666666666667,\n",
       "      'text_f1': 0.06935190413451284},\n",
       "     'improvements': {'page_mrr': -0.1339999469341575,\n",
       "      'page_recall': -0.0955555555555555,\n",
       "      'page_precision': -0.008,\n",
       "      'page_f1': -0.014519878503700553,\n",
       "      'text_mrr': -0.13615509109626758,\n",
       "      'text_recall': -0.09888888888888892,\n",
       "      'text_precision': -0.01566666666666667,\n",
       "      'text_f1': -0.026446452098626005},\n",
       "     'improvement_percentages': {'page_mrr': -25.88271856400528,\n",
       "      'page_recall': -11.55913978494623,\n",
       "      'page_precision': -12.5,\n",
       "      'page_f1': -12.374126658778977,\n",
       "      'text_mrr': -36.075251717379814,\n",
       "      'text_recall': -15.641476274165205,\n",
       "      'text_precision': -29.375,\n",
       "      'text_f1': -27.606373573117292}},\n",
       "    'hyde_financial_terminology': {'type': 'hyde',\n",
       "     'subtype': 'financial_terminology',\n",
       "     'filename': 'hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.3938531797579785,\n",
       "      'page_recall': 0.7144444444444444,\n",
       "      'page_precision': 0.05533333333333334,\n",
       "      'page_f1': 0.10156597026162242,\n",
       "      'text_mrr': 0.24688075091403264,\n",
       "      'text_recall': 0.5233333333333333,\n",
       "      'text_precision': 0.035,\n",
       "      'text_f1': 0.06482025221155656},\n",
       "     'improvements': {'page_mrr': -0.12386657445867977,\n",
       "      'page_recall': -0.11222222222222222,\n",
       "      'page_precision': -0.008666666666666663,\n",
       "      'page_f1': -0.015774662367180087,\n",
       "      'text_mrr': -0.13053890553890554,\n",
       "      'text_recall': -0.10888888888888892,\n",
       "      'text_precision': -0.018333333333333333,\n",
       "      'text_f1': -0.030978104021582284},\n",
       "     'improvement_percentages': {'page_mrr': -23.925410118085505,\n",
       "      'page_recall': -13.5752688172043,\n",
       "      'page_precision': -13.54166666666666,\n",
       "      'page_f1': -13.44347819998716,\n",
       "      'text_mrr': -34.58720374178045,\n",
       "      'text_recall': -17.22319859402461,\n",
       "      'text_precision': -34.375,\n",
       "      'text_f1': -32.33678033701611}},\n",
       "    'query_refinement_clarification': {'type': 'query_refinement',\n",
       "     'subtype': 'clarification',\n",
       "     'filename': 'query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.5220091814503579,\n",
       "      'page_recall': 0.8188888888888889,\n",
       "      'page_precision': 0.06266666666666666,\n",
       "      'page_f1': 0.11503216590173113,\n",
       "      'text_mrr': 0.38195226926496273,\n",
       "      'text_recall': 0.6155555555555555,\n",
       "      'text_precision': 0.053,\n",
       "      'text_f1': 0.09481867461577606},\n",
       "     'improvements': {'page_mrr': 0.0042894272336996275,\n",
       "      'page_recall': -0.007777777777777772,\n",
       "      'page_precision': -0.0013333333333333391,\n",
       "      'page_f1': -0.0023084667270713843,\n",
       "      'text_mrr': 0.00453261281202455,\n",
       "      'text_recall': -0.01666666666666672,\n",
       "      'text_precision': -0.00033333333333333826,\n",
       "      'text_f1': -0.000979681617362782},\n",
       "     'improvement_percentages': {'page_mrr': 0.8285229989320755,\n",
       "      'page_recall': -0.9408602150537628,\n",
       "      'page_precision': -2.0833333333333424,\n",
       "      'page_f1': -1.9673208464573648,\n",
       "      'text_mrr': 1.2009477340483294,\n",
       "      'text_recall': -2.6362038664323455,\n",
       "      'text_precision': -0.6250000000000092,\n",
       "      'text_f1': -1.0226497153861265}},\n",
       "    'query_refinement_formal': {'type': 'query_refinement',\n",
       "     'subtype': 'formal',\n",
       "     'filename': 'query_refinement_formal_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.5593700863406745,\n",
       "      'page_recall': 0.8355555555555555,\n",
       "      'page_precision': 0.06366666666666668,\n",
       "      'page_f1': 0.11683591770548292,\n",
       "      'text_mrr': 0.40895395929606454,\n",
       "      'text_recall': 0.6255555555555555,\n",
       "      'text_precision': 0.05533333333333334,\n",
       "      'text_f1': 0.09888919346890361},\n",
       "     'improvements': {'page_mrr': 0.041650332124016254,\n",
       "      'page_recall': 0.008888888888888835,\n",
       "      'page_precision': -0.0003333333333333244,\n",
       "      'page_f1': -0.0005047149233195908,\n",
       "      'text_mrr': 0.03153430284312636,\n",
       "      'text_recall': -0.00666666666666671,\n",
       "      'text_precision': 0.0020000000000000018,\n",
       "      'text_f1': 0.003090837235764768},\n",
       "     'improvement_percentages': {'page_mrr': 8.04495709981856,\n",
       "      'page_recall': 1.0752688172042946,\n",
       "      'page_precision': -0.5208333333333194,\n",
       "      'page_f1': -0.4301280059706301,\n",
       "      'text_mrr': 8.355235956571988,\n",
       "      'text_recall': -1.0544815465729418,\n",
       "      'text_precision': 3.7500000000000036,\n",
       "      'text_f1': 3.2263990294810267}},\n",
       "    'query_refinement_keyword_focused': {'type': 'query_refinement',\n",
       "     'subtype': 'keyword_focused',\n",
       "     'filename': 'query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.47265950034371085,\n",
       "      'page_recall': 0.8222222222222222,\n",
       "      'page_precision': 0.06266666666666666,\n",
       "      'page_f1': 0.1150479954827781,\n",
       "      'text_mrr': 0.3543193617241605,\n",
       "      'text_recall': 0.6388888888888888,\n",
       "      'text_precision': 0.054,\n",
       "      'text_f1': 0.09688505268215412},\n",
       "     'improvements': {'page_mrr': -0.04506025387294743,\n",
       "      'page_recall': -0.004444444444444473,\n",
       "      'page_precision': -0.0013333333333333391,\n",
       "      'page_f1': -0.002292637146024415,\n",
       "      'text_mrr': -0.02310029472877767,\n",
       "      'text_recall': 0.006666666666666599,\n",
       "      'text_precision': 0.0006666666666666626,\n",
       "      'text_f1': 0.0010866964490152814},\n",
       "     'improvement_percentages': {'page_mrr': -8.703599487163931,\n",
       "      'page_recall': -0.537634408602154,\n",
       "      'page_precision': -2.0833333333333424,\n",
       "      'page_f1': -1.953830565475972,\n",
       "      'text_mrr': -6.120586019784619,\n",
       "      'text_recall': 1.0544815465729243,\n",
       "      'text_precision': 1.2499999999999925,\n",
       "      'text_f1': 1.1343581369712148}},\n",
       "    'term_expansion_abbreviation_synonym': {'type': 'term_expansion',\n",
       "     'subtype': 'abbreviation_synonym',\n",
       "     'filename': 'term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.5632757208678262,\n",
       "      'page_recall': 0.8477777777777779,\n",
       "      'page_precision': 0.06433333333333334,\n",
       "      'page_f1': 0.11802921715965194,\n",
       "      'text_mrr': 0.4143471494392547,\n",
       "      'text_recall': 0.6255555555555555,\n",
       "      'text_precision': 0.05333333333333334,\n",
       "      'text_f1': 0.09557656406931768},\n",
       "     'improvements': {'page_mrr': 0.0455559666511679,\n",
       "      'page_recall': 0.02111111111111119,\n",
       "      'page_precision': 0.00033333333333333826,\n",
       "      'page_f1': 0.000688584530849426,\n",
       "      'text_mrr': 0.036927492986316535,\n",
       "      'text_recall': -0.00666666666666671,\n",
       "      'text_precision': 0.0,\n",
       "      'text_f1': -0.0002217921638211634},\n",
       "     'improvement_percentages': {'page_mrr': 8.799348736479425,\n",
       "      'page_recall': 2.5537634408602248,\n",
       "      'page_precision': 0.520833333333341,\n",
       "      'page_f1': 0.5868253097183367,\n",
       "      'text_mrr': 9.784199724351442,\n",
       "      'text_recall': -1.0544815465729418,\n",
       "      'text_precision': 0.0,\n",
       "      'text_f1': -0.2315198011137068}},\n",
       "    'term_expansion_context_addition': {'type': 'term_expansion',\n",
       "     'subtype': 'context_addition',\n",
       "     'filename': 'term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.5283078403078403,\n",
       "      'page_recall': 0.8277777777777778,\n",
       "      'page_precision': 0.06366666666666668,\n",
       "      'page_f1': 0.11652984696462956,\n",
       "      'text_mrr': 0.38779552854552857,\n",
       "      'text_recall': 0.6255555555555555,\n",
       "      'text_precision': 0.051666666666666666,\n",
       "      'text_f1': 0.09314015024159951},\n",
       "     'improvements': {'page_mrr': 0.010588086091182003,\n",
       "      'page_recall': 0.0011111111111111738,\n",
       "      'page_precision': -0.0003333333333333244,\n",
       "      'page_f1': -0.0008107856641729472,\n",
       "      'text_mrr': 0.010375872092590388,\n",
       "      'text_recall': -0.00666666666666671,\n",
       "      'text_precision': -0.0016666666666666705,\n",
       "      'text_f1': -0.0026582059915393336},\n",
       "     'improvement_percentages': {'page_mrr': 2.045138514600901,\n",
       "      'page_recall': 0.1344086021505452,\n",
       "      'page_precision': -0.5208333333333194,\n",
       "      'page_f1': -0.6909675242145671,\n",
       "      'text_mrr': 2.7491604942108236,\n",
       "      'text_recall': -1.0544815465729418,\n",
       "      'text_precision': -3.125000000000007,\n",
       "      'text_f1': -2.7747929046613424}},\n",
       "    'chain_of_thought_step_by_step': {'type': 'chain_of_thought',\n",
       "     'subtype': 'step_by_step',\n",
       "     'filename': 'chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.37676202773261597,\n",
       "      'page_recall': 0.7322222222222222,\n",
       "      'page_precision': 0.05533333333333334,\n",
       "      'page_f1': 0.10166447079490558,\n",
       "      'text_mrr': 0.24557941405000225,\n",
       "      'text_recall': 0.55,\n",
       "      'text_precision': 0.03933333333333334,\n",
       "      'text_f1': 0.0722818244557375},\n",
       "     'improvements': {'page_mrr': -0.1409577264840423,\n",
       "      'page_recall': -0.09444444444444444,\n",
       "      'page_precision': -0.008666666666666663,\n",
       "      'page_f1': -0.01567616183389693,\n",
       "      'text_mrr': -0.13184024240293593,\n",
       "      'text_recall': -0.0822222222222222,\n",
       "      'text_precision': -0.013999999999999999,\n",
       "      'text_f1': -0.023516531777401345},\n",
       "     'improvement_percentages': {'page_mrr': -27.226646334428555,\n",
       "      'page_recall': -11.424731182795698,\n",
       "      'page_precision': -13.54166666666666,\n",
       "      'page_f1': -13.359534104002307,\n",
       "      'text_mrr': -34.932002122516785,\n",
       "      'text_recall': -13.00527240773286,\n",
       "      'text_precision': -26.249999999999996,\n",
       "      'text_f1': -24.54794915287538}},\n",
       "    'chain_of_thought_explicit_context': {'type': 'chain_of_thought',\n",
       "     'subtype': 'explicit_context',\n",
       "     'filename': 'chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.5190317820580979,\n",
       "      'page_recall': 0.8288888888888889,\n",
       "      'page_precision': 0.064,\n",
       "      'page_f1': 0.11733343950735256,\n",
       "      'text_mrr': 0.3930936899357952,\n",
       "      'text_recall': 0.6222222222222222,\n",
       "      'text_precision': 0.052333333333333336,\n",
       "      'text_f1': 0.0941213912228405},\n",
       "     'improvements': {'page_mrr': 0.001312027841439578,\n",
       "      'page_recall': 0.0022222222222222365,\n",
       "      'page_precision': 0.0,\n",
       "      'page_f1': -7.19312144994988e-06,\n",
       "      'text_mrr': 0.015674033482857008,\n",
       "      'text_recall': -0.010000000000000009,\n",
       "      'text_precision': -0.0010000000000000009,\n",
       "      'text_f1': -0.001676965010298348},\n",
       "     'improvement_percentages': {'page_mrr': 0.2534243344499683,\n",
       "      'page_recall': 0.268817204301077,\n",
       "      'page_precision': 0.0,\n",
       "      'page_f1': -0.006130119881579922,\n",
       "      'text_mrr': 4.152945723644751,\n",
       "      'text_recall': -1.581722319859404,\n",
       "      'text_precision': -1.8750000000000018,\n",
       "      'text_f1': -1.7505154328715375}},\n",
       "    'domain_adaptation_accounting_perspective': {'type': 'domain_adaptation',\n",
       "     'subtype': 'accounting_perspective',\n",
       "     'filename': 'domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.5088232683495841,\n",
       "      'page_recall': 0.85,\n",
       "      'page_precision': 0.06366666666666668,\n",
       "      'page_f1': 0.11713093669615408,\n",
       "      'text_mrr': 0.3685856078619237,\n",
       "      'text_recall': 0.6344444444444445,\n",
       "      'text_precision': 0.054,\n",
       "      'text_f1': 0.09684138620370504},\n",
       "     'improvements': {'page_mrr': -0.008896485867074144,\n",
       "      'page_recall': 0.023333333333333317,\n",
       "      'page_precision': -0.0003333333333333244,\n",
       "      'page_f1': -0.00020969593264842656,\n",
       "      'text_mrr': -0.008834048591014498,\n",
       "      'text_recall': 0.0022222222222222365,\n",
       "      'text_precision': 0.0006666666666666626,\n",
       "      'text_f1': 0.0010430299705661977},\n",
       "     'improvement_percentages': {'page_mrr': -1.7183979932415507,\n",
       "      'page_recall': 2.8225806451612887,\n",
       "      'page_precision': -0.5208333333333194,\n",
       "      'page_f1': -0.17870700707041737,\n",
       "      'text_mrr': -2.3406434826523266,\n",
       "      'text_recall': 0.35149384885764723,\n",
       "      'text_precision': 1.2499999999999925,\n",
       "      'text_f1': 1.0887764796588335}},\n",
       "    'domain_adaptation_10k_language': {'type': 'domain_adaptation',\n",
       "     'subtype': '10k_language',\n",
       "     'filename': 'domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_global.json',\n",
       "     'metrics': {'page_mrr': 0.4927726347726348,\n",
       "      'page_recall': 0.7955555555555556,\n",
       "      'page_precision': 0.05866666666666667,\n",
       "      'page_f1': 0.10795393012784317,\n",
       "      'text_mrr': 0.35929743988954516,\n",
       "      'text_recall': 0.5955555555555555,\n",
       "      'text_precision': 0.05066666666666667,\n",
       "      'text_f1': 0.091079500209935},\n",
       "     'improvements': {'page_mrr': -0.024947119444023502,\n",
       "      'page_recall': -0.03111111111111109,\n",
       "      'page_precision': -0.005333333333333329,\n",
       "      'page_f1': -0.00938670250095934,\n",
       "      'text_mrr': -0.018122216563393023,\n",
       "      'text_recall': -0.036666666666666736,\n",
       "      'text_precision': -0.0026666666666666644,\n",
       "      'text_f1': -0.004718856023203849},\n",
       "     'improvement_percentages': {'page_mrr': -4.818653188493846,\n",
       "      'page_recall': -3.7634408602150513,\n",
       "      'page_precision': -8.333333333333325,\n",
       "      'page_f1': -7.999532890412654,\n",
       "      'text_mrr': -4.801609098399661,\n",
       "      'text_recall': -5.799648506151153,\n",
       "      'text_precision': -4.999999999999996,\n",
       "      'text_f1': -4.925821495015891}}}},\n",
       "  {'mode': 'singledoc',\n",
       "   'report_text': '\\n================================================================================\\nQUERY EXPANSION COMPARISON REPORT - MODE: SINGLEDOC\\n================================================================================\\n\\nConfiguration:\\n  Provider: voyage\\n  Model: voyage-3-large\\n  Chunk Size: 512\\n  K (retrieved): 20\\n  Mode: singledoc\\n  Expansion methods found: 12\\n\\n================================================================================\\nBASELINE PERFORMANCE (Original Queries - No Expansion)\\n================================================================================\\n\\nPage-Based Metrics:\\n  MRR:       0.5935\\n  Recall:    0.9267\\n  Precision: 0.1011\\n  F1:        0.1729\\n\\nText-Based Metrics:\\n  MRR:       0.4349\\n  Recall:    0.7044\\n  Precision: 0.0737\\n  F1:        0.1286\\n\\n================================================================================\\nEXPANSION METHODS - DETAILED RESULTS\\n================================================================================\\n\\n--------------------------------------------------------------------------------\\nMethod: term_expansion / abbreviation_synonym\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.6355 (Δ +0.0420, +7.08%)\\n  Recall:    0.9111 (Δ -0.0156, -1.68%)\\n  Precision: 0.0955 (Δ -0.0056, -5.58%)\\n  F1:        0.1655 (Δ -0.0074, -4.30%)\\n\\nText-Based Metrics:\\n  MRR:       0.4678 (Δ +0.0328, +7.55%)\\n  Recall:    0.6922 (Δ -0.0122, -1.74%)\\n  Precision: 0.0726 (Δ -0.0010, -1.39%)\\n  F1:        0.1270 (Δ -0.0015, -1.20%)\\n\\n--------------------------------------------------------------------------------\\nMethod: query_refinement / formal\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.6282 (Δ +0.0347, +5.85%)\\n  Recall:    0.9300 (Δ +0.0033, +0.36%)\\n  Precision: 0.0978 (Δ -0.0034, -3.35%)\\n  F1:        0.1683 (Δ -0.0046, -2.65%)\\n\\nText-Based Metrics:\\n  MRR:       0.4567 (Δ +0.0217, +5.00%)\\n  Recall:    0.6978 (Δ -0.0067, -0.95%)\\n  Precision: 0.0751 (Δ +0.0014, +1.94%)\\n  F1:        0.1306 (Δ +0.0020, +1.58%)\\n\\n--------------------------------------------------------------------------------\\nMethod: query_refinement / clarification\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.6007 (Δ +0.0072, +1.21%)\\n  Recall:    0.9144 (Δ -0.0122, -1.32%)\\n  Precision: 0.0969 (Δ -0.0042, -4.16%)\\n  F1:        0.1656 (Δ -0.0073, -4.22%)\\n\\nText-Based Metrics:\\n  MRR:       0.4415 (Δ +0.0065, +1.50%)\\n  Recall:    0.6844 (Δ -0.0200, -2.84%)\\n  Precision: 0.0732 (Δ -0.0005, -0.63%)\\n  F1:        0.1273 (Δ -0.0012, -0.94%)\\n\\n--------------------------------------------------------------------------------\\nMethod: domain_adaptation / accounting_perspective\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5959 (Δ +0.0024, +0.41%)\\n  Recall:    0.9200 (Δ -0.0067, -0.72%)\\n  Precision: 0.0983 (Δ -0.0028, -2.78%)\\n  F1:        0.1698 (Δ -0.0031, -1.80%)\\n\\nText-Based Metrics:\\n  MRR:       0.4315 (Δ -0.0034, -0.79%)\\n  Recall:    0.6911 (Δ -0.0133, -1.89%)\\n  Precision: 0.0759 (Δ +0.0022, +3.04%)\\n  F1:        0.1321 (Δ +0.0035, +2.74%)\\n\\n--------------------------------------------------------------------------------\\nMethod: term_expansion / context_addition\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5880 (Δ -0.0055, -0.92%)\\n  Recall:    0.9300 (Δ +0.0033, +0.36%)\\n  Precision: 0.1028 (Δ +0.0016, +1.61%)\\n  F1:        0.1753 (Δ +0.0024, +1.38%)\\n\\nText-Based Metrics:\\n  MRR:       0.4361 (Δ +0.0012, +0.27%)\\n  Recall:    0.7111 (Δ +0.0067, +0.95%)\\n  Precision: 0.0736 (Δ -0.0000, -0.03%)\\n  F1:        0.1288 (Δ +0.0002, +0.19%)\\n\\n--------------------------------------------------------------------------------\\nMethod: chain_of_thought / explicit_context\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5879 (Δ -0.0056, -0.94%)\\n  Recall:    0.8967 (Δ -0.0300, -3.24%)\\n  Precision: 0.0960 (Δ -0.0052, -5.13%)\\n  F1:        0.1636 (Δ -0.0093, -5.40%)\\n\\nText-Based Metrics:\\n  MRR:       0.4427 (Δ +0.0077, +1.77%)\\n  Recall:    0.6844 (Δ -0.0200, -2.84%)\\n  Precision: 0.0728 (Δ -0.0008, -1.11%)\\n  F1:        0.1267 (Δ -0.0019, -1.45%)\\n\\n--------------------------------------------------------------------------------\\nMethod: domain_adaptation / 10k_language\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5708 (Δ -0.0227, -3.82%)\\n  Recall:    0.9078 (Δ -0.0189, -2.04%)\\n  Precision: 0.0948 (Δ -0.0064, -6.31%)\\n  F1:        0.1636 (Δ -0.0093, -5.39%)\\n\\nText-Based Metrics:\\n  MRR:       0.4164 (Δ -0.0186, -4.27%)\\n  Recall:    0.6778 (Δ -0.0267, -3.79%)\\n  Precision: 0.0728 (Δ -0.0009, -1.20%)\\n  F1:        0.1269 (Δ -0.0016, -1.27%)\\n\\n--------------------------------------------------------------------------------\\nMethod: query_refinement / keyword_focused\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5650 (Δ -0.0285, -4.81%)\\n  Recall:    0.9211 (Δ -0.0056, -0.60%)\\n  Precision: 0.0974 (Δ -0.0037, -3.66%)\\n  F1:        0.1678 (Δ -0.0051, -2.94%)\\n\\nText-Based Metrics:\\n  MRR:       0.4172 (Δ -0.0178, -4.09%)\\n  Recall:    0.7000 (Δ -0.0044, -0.63%)\\n  Precision: 0.0748 (Δ +0.0011, +1.48%)\\n  F1:        0.1301 (Δ +0.0015, +1.17%)\\n\\n--------------------------------------------------------------------------------\\nMethod: hyde / basic\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.5171 (Δ -0.0764, -12.88%)\\n  Recall:    0.8756 (Δ -0.0511, -5.52%)\\n  Precision: 0.0964 (Δ -0.0048, -4.72%)\\n  F1:        0.1650 (Δ -0.0079, -4.54%)\\n\\nText-Based Metrics:\\n  MRR:       0.3568 (Δ -0.0782, -17.97%)\\n  Recall:    0.6578 (Δ -0.0467, -6.62%)\\n  Precision: 0.0624 (Δ -0.0112, -15.23%)\\n  F1:        0.1106 (Δ -0.0179, -13.95%)\\n\\n--------------------------------------------------------------------------------\\nMethod: hyde / financial_terminology\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.4964 (Δ -0.0971, -16.36%)\\n  Recall:    0.8567 (Δ -0.0700, -7.55%)\\n  Precision: 0.0964 (Δ -0.0048, -4.72%)\\n  F1:        0.1643 (Δ -0.0086, -4.98%)\\n\\nText-Based Metrics:\\n  MRR:       0.3191 (Δ -0.1159, -26.64%)\\n  Recall:    0.6489 (Δ -0.0556, -7.89%)\\n  Precision: 0.0591 (Δ -0.0146, -19.79%)\\n  F1:        0.1053 (Δ -0.0233, -18.13%)\\n\\n--------------------------------------------------------------------------------\\nMethod: hyde / detailed\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.4947 (Δ -0.0988, -16.65%)\\n  Recall:    0.8433 (Δ -0.0833, -8.99%)\\n  Precision: 0.0890 (Δ -0.0122, -12.03%)\\n  F1:        0.1551 (Δ -0.0178, -10.29%)\\n\\nText-Based Metrics:\\n  MRR:       0.3147 (Δ -0.1202, -27.64%)\\n  Recall:    0.6144 (Δ -0.0900, -12.78%)\\n  Precision: 0.0584 (Δ -0.0153, -20.72%)\\n  F1:        0.1034 (Δ -0.0252, -19.58%)\\n\\n--------------------------------------------------------------------------------\\nMethod: chain_of_thought / step_by_step\\n--------------------------------------------------------------------------------\\n\\nPage-Based Metrics:\\n  MRR:       0.4717 (Δ -0.1218, -20.53%)\\n  Recall:    0.8544 (Δ -0.0722, -7.79%)\\n  Precision: 0.0909 (Δ -0.0103, -10.18%)\\n  F1:        0.1572 (Δ -0.0157, -9.09%)\\n\\nText-Based Metrics:\\n  MRR:       0.3182 (Δ -0.1168, -26.85%)\\n  Recall:    0.6478 (Δ -0.0567, -8.04%)\\n  Precision: 0.0624 (Δ -0.0113, -15.31%)\\n  F1:        0.1105 (Δ -0.0181, -14.05%)\\n\\n================================================================================\\nRANKING BY PAGE MRR IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Page MRR | Δ MRR    | %\\n--------------------------------------------------------------------------------\\n   1 | term_expansion/abbreviation_synonym        | 0.6355   | +0.0420   | +7.08%\\n   2 | query_refinement/formal                    | 0.6282   | +0.0347   | +5.85%\\n   3 | query_refinement/clarification             | 0.6007   | +0.0072   | +1.21%\\n   4 | domain_adaptation/accounting_perspective   | 0.5959   | +0.0024   | +0.41%\\n   5 | term_expansion/context_addition            | 0.5880   | -0.0055   | -0.92%\\n   6 | chain_of_thought/explicit_context          | 0.5879   | -0.0056   | -0.94%\\n   7 | domain_adaptation/10k_language             | 0.5708   | -0.0227   | -3.82%\\n   8 | query_refinement/keyword_focused           | 0.5650   | -0.0285   | -4.81%\\n   9 | hyde/basic                                 | 0.5171   | -0.0764   | -12.88%\\n  10 | hyde/financial_terminology                 | 0.4964   | -0.0971   | -16.36%\\n  11 | hyde/detailed                              | 0.4947   | -0.0988   | -16.65%\\n  12 | chain_of_thought/step_by_step              | 0.4717   | -0.1218   | -20.53%\\n\\n================================================================================\\nRANKING BY PAGE RECALL IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Page Recall | Δ Recall | %\\n--------------------------------------------------------------------------------\\n   1 | query_refinement/formal                    | 0.9300      | +0.0033     | +0.36%\\n   2 | term_expansion/context_addition            | 0.9300      | +0.0033     | +0.36%\\n   3 | query_refinement/keyword_focused           | 0.9211      | -0.0056     | -0.60%\\n   4 | domain_adaptation/accounting_perspective   | 0.9200      | -0.0067     | -0.72%\\n   5 | query_refinement/clarification             | 0.9144      | -0.0122     | -1.32%\\n   6 | term_expansion/abbreviation_synonym        | 0.9111      | -0.0156     | -1.68%\\n   7 | domain_adaptation/10k_language             | 0.9078      | -0.0189     | -2.04%\\n   8 | chain_of_thought/explicit_context          | 0.8967      | -0.0300     | -3.24%\\n   9 | hyde/basic                                 | 0.8756      | -0.0511     | -5.52%\\n  10 | hyde/financial_terminology                 | 0.8567      | -0.0700     | -7.55%\\n  11 | chain_of_thought/step_by_step              | 0.8544      | -0.0722     | -7.79%\\n  12 | hyde/detailed                              | 0.8433      | -0.0833     | -8.99%\\n\\n================================================================================\\nRANKING BY PAGE PRECISION IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Page Precision | Δ Precision | %\\n--------------------------------------------------------------------------------\\n   1 | term_expansion/context_addition            | 0.1028         | +0.0016        | +1.61%\\n   2 | domain_adaptation/accounting_perspective   | 0.0983         | -0.0028        | -2.78%\\n   3 | query_refinement/formal                    | 0.0978         | -0.0034        | -3.35%\\n   4 | query_refinement/keyword_focused           | 0.0974         | -0.0037        | -3.66%\\n   5 | query_refinement/clarification             | 0.0969         | -0.0042        | -4.16%\\n   6 | hyde/financial_terminology                 | 0.0964         | -0.0048        | -4.72%\\n   7 | hyde/basic                                 | 0.0964         | -0.0048        | -4.72%\\n   8 | chain_of_thought/explicit_context          | 0.0960         | -0.0052        | -5.13%\\n   9 | term_expansion/abbreviation_synonym        | 0.0955         | -0.0056        | -5.58%\\n  10 | domain_adaptation/10k_language             | 0.0948         | -0.0064        | -6.31%\\n  11 | chain_of_thought/step_by_step              | 0.0909         | -0.0103        | -10.18%\\n  12 | hyde/detailed                              | 0.0890         | -0.0122        | -12.03%\\n\\n================================================================================\\nRANKING BY TEXT MRR IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Text MRR | Δ MRR    | %\\n--------------------------------------------------------------------------------\\n   1 | term_expansion/abbreviation_synonym        | 0.4678   | +0.0328   | +7.55%\\n   2 | query_refinement/formal                    | 0.4567   | +0.0217   | +5.00%\\n   3 | chain_of_thought/explicit_context          | 0.4427   | +0.0077   | +1.77%\\n   4 | query_refinement/clarification             | 0.4415   | +0.0065   | +1.50%\\n   5 | term_expansion/context_addition            | 0.4361   | +0.0012   | +0.27%\\n   6 | domain_adaptation/accounting_perspective   | 0.4315   | -0.0034   | -0.79%\\n   7 | query_refinement/keyword_focused           | 0.4172   | -0.0178   | -4.09%\\n   8 | domain_adaptation/10k_language             | 0.4164   | -0.0186   | -4.27%\\n   9 | hyde/basic                                 | 0.3568   | -0.0782   | -17.97%\\n  10 | hyde/financial_terminology                 | 0.3191   | -0.1159   | -26.64%\\n  11 | chain_of_thought/step_by_step              | 0.3182   | -0.1168   | -26.85%\\n  12 | hyde/detailed                              | 0.3147   | -0.1202   | -27.64%\\n\\n================================================================================\\nRANKING BY TEXT RECALL IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Text Recall | Δ Recall | %\\n--------------------------------------------------------------------------------\\n   1 | term_expansion/context_addition            | 0.7111      | +0.0067     | +0.95%\\n   2 | query_refinement/keyword_focused           | 0.7000      | -0.0044     | -0.63%\\n   3 | query_refinement/formal                    | 0.6978      | -0.0067     | -0.95%\\n   4 | term_expansion/abbreviation_synonym        | 0.6922      | -0.0122     | -1.74%\\n   5 | domain_adaptation/accounting_perspective   | 0.6911      | -0.0133     | -1.89%\\n   6 | query_refinement/clarification             | 0.6844      | -0.0200     | -2.84%\\n   7 | chain_of_thought/explicit_context          | 0.6844      | -0.0200     | -2.84%\\n   8 | domain_adaptation/10k_language             | 0.6778      | -0.0267     | -3.79%\\n   9 | hyde/basic                                 | 0.6578      | -0.0467     | -6.62%\\n  10 | hyde/financial_terminology                 | 0.6489      | -0.0556     | -7.89%\\n  11 | chain_of_thought/step_by_step              | 0.6478      | -0.0567     | -8.04%\\n  12 | hyde/detailed                              | 0.6144      | -0.0900     | -12.78%\\n\\n================================================================================\\nRANKING BY TEXT PRECISION IMPROVEMENT\\n================================================================================\\n\\nRank | Method                                    | Text Precision | Δ Precision | %\\n--------------------------------------------------------------------------------\\n   1 | domain_adaptation/accounting_perspective   | 0.0759         | +0.0022        | +3.04%\\n   2 | query_refinement/formal                    | 0.0751         | +0.0014        | +1.94%\\n   3 | query_refinement/keyword_focused           | 0.0748         | +0.0011        | +1.48%\\n   4 | term_expansion/context_addition            | 0.0736         | -0.0000        | -0.03%\\n   5 | query_refinement/clarification             | 0.0732         | -0.0005        | -0.63%\\n   6 | chain_of_thought/explicit_context          | 0.0728         | -0.0008        | -1.11%\\n   7 | domain_adaptation/10k_language             | 0.0728         | -0.0009        | -1.20%\\n   8 | term_expansion/abbreviation_synonym        | 0.0726         | -0.0010        | -1.39%\\n   9 | hyde/basic                                 | 0.0624         | -0.0112        | -15.23%\\n  10 | chain_of_thought/step_by_step              | 0.0624         | -0.0113        | -15.31%\\n  11 | hyde/financial_terminology                 | 0.0591         | -0.0146        | -19.79%\\n  12 | hyde/detailed                              | 0.0584         | -0.0153        | -20.72%\\n\\n================================================================================\\nANALYSIS BY EXPANSION CATEGORY\\n================================================================================\\n\\nCategory: CHAIN OF THOUGHT\\n  Number of variants: 2\\n  Avg Page MRR improvement: -0.0637\\n  Avg Text MRR improvement: -0.0545\\n  Variants:\\n    - step_by_step                   Page: -0.1218, Text: -0.1168\\n    - explicit_context               Page: -0.0056, Text: +0.0077\\n\\nCategory: DOMAIN ADAPTATION\\n  Number of variants: 2\\n  Avg Page MRR improvement: -0.0101\\n  Avg Text MRR improvement: -0.0110\\n  Variants:\\n    - accounting_perspective         Page: +0.0024, Text: -0.0034\\n    - 10k_language                   Page: -0.0227, Text: -0.0186\\n\\nCategory: HYDE\\n  Number of variants: 3\\n  Avg Page MRR improvement: -0.0908\\n  Avg Text MRR improvement: -0.1048\\n  Variants:\\n    - basic                          Page: -0.0764, Text: -0.0782\\n    - detailed                       Page: -0.0988, Text: -0.1202\\n    - financial_terminology          Page: -0.0971, Text: -0.1159\\n\\nCategory: QUERY REFINEMENT\\n  Number of variants: 3\\n  Avg Page MRR improvement: +0.0044\\n  Avg Text MRR improvement: +0.0035\\n  Variants:\\n    - clarification                  Page: +0.0072, Text: +0.0065\\n    - formal                         Page: +0.0347, Text: +0.0217\\n    - keyword_focused                Page: -0.0285, Text: -0.0178\\n\\nCategory: TERM EXPANSION\\n  Number of variants: 2\\n  Avg Page MRR improvement: +0.0183\\n  Avg Text MRR improvement: +0.0170\\n  Variants:\\n    - abbreviation_synonym           Page: +0.0420, Text: +0.0328\\n    - context_addition               Page: -0.0055, Text: +0.0012\\n\\n================================================================================\\nBEST AND WORST PERFORMERS\\n================================================================================\\n\\nBest Page MRR Improvement:\\n  Method: term_expansion/abbreviation_synonym\\n  MRR: 0.6355 (Δ +0.0420, +7.08%)\\n\\nWorst Page MRR Improvement:\\n  Method: chain_of_thought/step_by_step\\n  MRR: 0.4717 (Δ -0.1218, -20.53%)\\n\\nBest Text MRR Improvement:\\n  Method: term_expansion/abbreviation_synonym\\n  MRR: 0.4678 (Δ +0.0328, +7.55%)\\n\\nWorst Text MRR Improvement:\\n  Method: hyde/detailed\\n  MRR: 0.3147 (Δ -0.1202, -27.64%)\\n\\n================================================================================\\nKEY INSIGHTS\\n================================================================================\\n\\n• 4/12 (33.3%) methods improved Page MRR over baseline\\n• 5/12 (41.7%) methods improved Text MRR over baseline\\n• Average Page MRR change: -0.0308 (-5.20%)\\n• Average Text MRR change: -0.0334 (-7.68%)\\n\\n================================================================================\\nEND OF REPORT - MODE: SINGLEDOC\\n================================================================================',\n",
       "   'baseline_metrics': {'page_mrr': 0.5934980759980759,\n",
       "    'page_recall': 0.9266666666666666,\n",
       "    'page_precision': 0.10114882173783103,\n",
       "    'page_f1': 0.17289651224586708,\n",
       "    'text_mrr': 0.43494181403391935,\n",
       "    'text_recall': 0.7044444444444444,\n",
       "    'text_precision': 0.07366559950770478,\n",
       "    'text_f1': 0.12855203753469557},\n",
       "   'metrics_data': {'hyde_basic': {'type': 'hyde',\n",
       "     'subtype': 'basic',\n",
       "     'filename': 'hyde_basic_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.517060273060273,\n",
       "      'page_recall': 0.8755555555555556,\n",
       "      'page_precision': 0.09636991952549229,\n",
       "      'page_f1': 0.16504001666560558,\n",
       "      'text_mrr': 0.3567647907647908,\n",
       "      'text_recall': 0.6577777777777778,\n",
       "      'text_precision': 0.062445117919576125,\n",
       "      'text_f1': 0.11062169397667669},\n",
       "     'improvements': {'page_mrr': -0.07643780293780289,\n",
       "      'page_recall': -0.051111111111110996,\n",
       "      'page_precision': -0.004778902212338745,\n",
       "      'page_f1': -0.007856495580261497,\n",
       "      'text_mrr': -0.07817702326912856,\n",
       "      'text_recall': -0.046666666666666634,\n",
       "      'text_precision': -0.011220481588128654,\n",
       "      'text_f1': -0.017930343558018882},\n",
       "     'improvement_percentages': {'page_mrr': -12.879199786664634,\n",
       "      'page_recall': -5.515587529976007,\n",
       "      'page_precision': -4.724624696791076,\n",
       "      'page_f1': -4.5440451505980555,\n",
       "      'text_mrr': -17.974133722409096,\n",
       "      'text_recall': -6.624605678233434,\n",
       "      'text_precision': -15.231643620785427,\n",
       "      'text_f1': -13.94792638209221}},\n",
       "    'hyde_detailed': {'type': 'hyde',\n",
       "     'subtype': 'detailed',\n",
       "     'filename': 'hyde_detailed_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.49470409220409217,\n",
       "      'page_recall': 0.8433333333333334,\n",
       "      'page_precision': 0.0889797287335987,\n",
       "      'page_f1': 0.15510415051463647,\n",
       "      'text_mrr': 0.31471970553239903,\n",
       "      'text_recall': 0.6144444444444445,\n",
       "      'text_precision': 0.058398766524153524,\n",
       "      'text_f1': 0.10337973318598795},\n",
       "     'improvements': {'page_mrr': -0.09879398379398374,\n",
       "      'page_recall': -0.08333333333333326,\n",
       "      'page_precision': -0.012169093004232329,\n",
       "      'page_f1': -0.01779236173123061,\n",
       "      'text_mrr': -0.12022210850152032,\n",
       "      'text_recall': -0.08999999999999997,\n",
       "      'text_precision': -0.015266832983551255,\n",
       "      'text_f1': -0.025172304348707625},\n",
       "     'improvement_percentages': {'page_mrr': -16.646049547480594,\n",
       "      'page_recall': -8.992805755395676,\n",
       "      'page_precision': -12.030879643633972,\n",
       "      'page_f1': -10.2907580379233,\n",
       "      'text_mrr': -27.640963600741475,\n",
       "      'text_recall': -12.776025236593055,\n",
       "      'text_precision': -20.72450789184778,\n",
       "      'text_f1': -19.581412190307557}},\n",
       "    'hyde_financial_terminology': {'type': 'hyde',\n",
       "     'subtype': 'financial_terminology',\n",
       "     'filename': 'hyde_financial_terminology_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.4964062326562327,\n",
       "      'page_recall': 0.8566666666666667,\n",
       "      'page_precision': 0.09637613828093704,\n",
       "      'page_f1': 0.1642809334064358,\n",
       "      'text_mrr': 0.31906815678874506,\n",
       "      'text_recall': 0.6488888888888888,\n",
       "      'text_precision': 0.059086048454469506,\n",
       "      'text_f1': 0.10525156302578118},\n",
       "     'improvements': {'page_mrr': -0.09709184334184323,\n",
       "      'page_recall': -0.06999999999999995,\n",
       "      'page_precision': -0.004772683456893995,\n",
       "      'page_f1': -0.008615578839431287,\n",
       "      'text_mrr': -0.11587365724517429,\n",
       "      'text_recall': -0.05555555555555558,\n",
       "      'text_precision': -0.014579551053235273,\n",
       "      'text_f1': -0.0233004745089144},\n",
       "     'improvement_percentages': {'page_mrr': -16.359251574415886,\n",
       "      'page_recall': -7.553956834532369,\n",
       "      'page_precision': -4.718476572336528,\n",
       "      'page_f1': -4.983084232017083,\n",
       "      'text_mrr': -26.641185902659103,\n",
       "      'text_recall': -7.886435331230287,\n",
       "      'text_precision': -19.791532480110178,\n",
       "      'text_f1': -18.125324931256507}},\n",
       "    'query_refinement_clarification': {'type': 'query_refinement',\n",
       "     'subtype': 'clarification',\n",
       "     'filename': 'query_refinement_clarification_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.6006501334922387,\n",
       "      'page_recall': 0.9144444444444444,\n",
       "      'page_precision': 0.09694559754544274,\n",
       "      'page_f1': 0.16559901850854294,\n",
       "      'text_mrr': 0.44146849446849445,\n",
       "      'text_recall': 0.6844444444444445,\n",
       "      'text_precision': 0.07319789401058752,\n",
       "      'text_f1': 0.12734520701492477},\n",
       "     'improvements': {'page_mrr': 0.007152057494162811,\n",
       "      'page_recall': -0.012222222222222245,\n",
       "      'page_precision': -0.004203224192388291,\n",
       "      'page_f1': -0.007297493737324134,\n",
       "      'text_mrr': 0.006526680434575105,\n",
       "      'text_recall': -0.019999999999999907,\n",
       "      'text_precision': -0.00046770549711726284,\n",
       "      'text_f1': -0.0012068305197708018},\n",
       "     'improvement_percentages': {'page_mrr': 1.2050683537828348,\n",
       "      'page_recall': -1.3189448441247027,\n",
       "      'page_precision': -4.155485076516941,\n",
       "      'page_f1': -4.220729292067356,\n",
       "      'text_mrr': 1.5005870265823915,\n",
       "      'text_recall': -2.839116719242889,\n",
       "      'text_precision': -0.6349035373944726,\n",
       "      'text_f1': -0.9387875469846864}},\n",
       "    'query_refinement_formal': {'type': 'query_refinement',\n",
       "     'subtype': 'formal',\n",
       "     'filename': 'query_refinement_formal_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.6281988896036883,\n",
       "      'page_recall': 0.93,\n",
       "      'page_precision': 0.09776051617228088,\n",
       "      'page_f1': 0.16830805254097178,\n",
       "      'text_mrr': 0.45667845974115323,\n",
       "      'text_recall': 0.6977777777777778,\n",
       "      'text_precision': 0.07509812300988772,\n",
       "      'text_f1': 0.1305872104726145},\n",
       "     'improvements': {'page_mrr': 0.03470081360561239,\n",
       "      'page_recall': 0.0033333333333334103,\n",
       "      'page_precision': -0.0033883055655501565,\n",
       "      'page_f1': -0.004588459704895298,\n",
       "      'text_mrr': 0.02173664570723388,\n",
       "      'text_recall': -0.006666666666666599,\n",
       "      'text_precision': 0.0014325235021829391,\n",
       "      'text_f1': 0.0020351729379189387},\n",
       "     'improvement_percentages': {'page_mrr': 5.8468283232859015,\n",
       "      'page_recall': 0.35971223021583565,\n",
       "      'page_precision': -3.349822081301501,\n",
       "      'page_f1': -2.653876382636504,\n",
       "      'text_mrr': 4.997598530625232,\n",
       "      'text_recall': -0.9463722397476244,\n",
       "      'text_precision': 1.944630209699318,\n",
       "      'text_f1': 1.583151054583367}},\n",
       "    'query_refinement_keyword_focused': {'type': 'query_refinement',\n",
       "     'subtype': 'keyword_focused',\n",
       "     'filename': 'query_refinement_keyword_focused_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.5649762644762645,\n",
       "      'page_recall': 0.9211111111111111,\n",
       "      'page_precision': 0.0974464454247736,\n",
       "      'page_f1': 0.16781658251376344,\n",
       "      'text_mrr': 0.4171644771350653,\n",
       "      'text_recall': 0.7,\n",
       "      'text_precision': 0.07475402810696928,\n",
       "      'text_f1': 0.13006163356659162},\n",
       "     'improvements': {'page_mrr': -0.028521811521811435,\n",
       "      'page_recall': -0.005555555555555536,\n",
       "      'page_precision': -0.0037023763130574344,\n",
       "      'page_f1': -0.0050799297321036385,\n",
       "      'text_mrr': -0.017777336898854024,\n",
       "      'text_recall': -0.004444444444444473,\n",
       "      'text_precision': 0.0010884285992645015,\n",
       "      'text_f1': 0.0015095960318960433},\n",
       "     'improvement_percentages': {'page_mrr': -4.80571254992643,\n",
       "      'page_recall': -0.5995203836930435,\n",
       "      'page_precision': -3.660325695788798,\n",
       "      'page_f1': -2.938133144571324,\n",
       "      'text_mrr': -4.087290834140781,\n",
       "      'text_recall': -0.6309148264984268,\n",
       "      'text_precision': 1.477526289799164,\n",
       "      'text_f1': 1.1743073550962664}},\n",
       "    'term_expansion_abbreviation_synonym': {'type': 'term_expansion',\n",
       "     'subtype': 'abbreviation_synonym',\n",
       "     'filename': 'term_expansion_abbreviation_synonym_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.6355018315018315,\n",
       "      'page_recall': 0.9111111111111111,\n",
       "      'page_precision': 0.09550158893966944,\n",
       "      'page_f1': 0.16545852124772573,\n",
       "      'text_mrr': 0.4677716727716728,\n",
       "      'text_recall': 0.6922222222222222,\n",
       "      'text_precision': 0.07264409799007322,\n",
       "      'text_f1': 0.12700533134391437},\n",
       "     'improvements': {'page_mrr': 0.04200375550375557,\n",
       "      'page_recall': -0.015555555555555545,\n",
       "      'page_precision': -0.005647232798161594,\n",
       "      'page_f1': -0.007437990998141353,\n",
       "      'text_mrr': 0.03282985873775346,\n",
       "      'text_recall': -0.012222222222222245,\n",
       "      'text_precision': -0.0010215015176315567,\n",
       "      'text_f1': -0.0015467061907812052},\n",
       "     'improvement_percentages': {'page_mrr': 7.0773195739714145,\n",
       "      'page_recall': -1.6786570743405265,\n",
       "      'page_precision': -5.5830930119964535,\n",
       "      'page_f1': -4.301990191429758,\n",
       "      'text_mrr': 7.548103603392152,\n",
       "      'text_recall': -1.7350157728706659,\n",
       "      'text_precision': -1.3866737316441937,\n",
       "      'text_f1': -1.2031751658263345}},\n",
       "    'term_expansion_context_addition': {'type': 'term_expansion',\n",
       "     'subtype': 'context_addition',\n",
       "     'filename': 'term_expansion_context_addition_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.5880268771189824,\n",
       "      'page_recall': 0.93,\n",
       "      'page_precision': 0.10277827435722173,\n",
       "      'page_f1': 0.17527870346814445,\n",
       "      'text_mrr': 0.4361350494477429,\n",
       "      'text_recall': 0.7111111111111111,\n",
       "      'text_precision': 0.07364350951193056,\n",
       "      'text_f1': 0.12879699156645358},\n",
       "     'improvements': {'page_mrr': -0.005471198879093531,\n",
       "      'page_recall': 0.0033333333333334103,\n",
       "      'page_precision': 0.001629452619390695,\n",
       "      'page_f1': 0.002382191222277369,\n",
       "      'text_mrr': 0.0011932354138235457,\n",
       "      'text_recall': 0.00666666666666671,\n",
       "      'text_precision': -2.2089995774215998e-05,\n",
       "      'text_f1': 0.00024495403175800456},\n",
       "     'improvement_percentages': {'page_mrr': -0.9218562115627259,\n",
       "      'page_recall': 0.35971223021583565,\n",
       "      'page_precision': 1.6109457247204468,\n",
       "      'page_f1': 1.377813347032576,\n",
       "      'text_mrr': 0.2743436881261755,\n",
       "      'text_recall': 0.9463722397476402,\n",
       "      'text_precision': -0.02998685400219349,\n",
       "      'text_f1': 0.19054854085209863}},\n",
       "    'chain_of_thought_step_by_step': {'type': 'chain_of_thought',\n",
       "     'subtype': 'step_by_step',\n",
       "     'filename': 'chain_of_thought_step_by_step_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.4716547643389749,\n",
       "      'page_recall': 0.8544444444444443,\n",
       "      'page_precision': 0.0908520343891861,\n",
       "      'page_f1': 0.15717958814640737,\n",
       "      'text_mrr': 0.3181808308650414,\n",
       "      'text_recall': 0.6477777777777778,\n",
       "      'text_precision': 0.0623859401692219,\n",
       "      'text_f1': 0.1104930711176056},\n",
       "     'improvements': {'page_mrr': -0.121843311659101,\n",
       "      'page_recall': -0.0722222222222223,\n",
       "      'page_precision': -0.010296787348644934,\n",
       "      'page_f1': -0.01571692409945971,\n",
       "      'text_mrr': -0.11676098316887795,\n",
       "      'text_recall': -0.05666666666666664,\n",
       "      'text_precision': -0.011279659338482878,\n",
       "      'text_f1': -0.01805896641708997},\n",
       "     'improvement_percentages': {'page_mrr': -20.52968941039937,\n",
       "      'page_recall': -7.793764988009601,\n",
       "      'page_precision': -10.179839143686037,\n",
       "      'page_f1': -9.0903650370399,\n",
       "      'text_mrr': -26.84519616220947,\n",
       "      'text_recall': -8.044164037854888,\n",
       "      'text_precision': -15.311976572325491,\n",
       "      'text_f1': -14.047981473818291}},\n",
       "    'chain_of_thought_explicit_context': {'type': 'chain_of_thought',\n",
       "     'subtype': 'explicit_context',\n",
       "     'filename': 'chain_of_thought_explicit_context_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.5878943953649836,\n",
       "      'page_recall': 0.8966666666666666,\n",
       "      'page_precision': 0.09595767682609789,\n",
       "      'page_f1': 0.16356779280071207,\n",
       "      'text_mrr': 0.4426526460868566,\n",
       "      'text_recall': 0.6844444444444445,\n",
       "      'text_precision': 0.07284765818976345,\n",
       "      'text_f1': 0.12668230427650717},\n",
       "     'improvements': {'page_mrr': -0.005603680633092356,\n",
       "      'page_recall': -0.030000000000000027,\n",
       "      'page_precision': -0.005191144911733142,\n",
       "      'page_f1': -0.00932871944515501,\n",
       "      'text_mrr': 0.0077108320529372665,\n",
       "      'text_recall': -0.019999999999999907,\n",
       "      'text_precision': -0.0008179413179413286,\n",
       "      'text_f1': -0.0018697332581883996},\n",
       "     'improvement_percentages': {'page_mrr': -0.9441783991748818,\n",
       "      'page_recall': -3.237410071942449,\n",
       "      'page_precision': -5.132185251933175,\n",
       "      'page_f1': -5.395550970912083,\n",
       "      'text_mrr': 1.7728422065062546,\n",
       "      'text_recall': -2.839116719242889,\n",
       "      'text_precision': -1.1103436657103145,\n",
       "      'text_f1': -1.4544563384954265}},\n",
       "    'domain_adaptation_accounting_perspective': {'type': 'domain_adaptation',\n",
       "     'subtype': 'accounting_perspective',\n",
       "     'filename': 'domain_adaptation_accounting_perspective_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.5959286454286454,\n",
       "      'page_recall': 0.92,\n",
       "      'page_precision': 0.0983376463577702,\n",
       "      'page_f1': 0.16979295680478304,\n",
       "      'text_mrr': 0.43150928047986875,\n",
       "      'text_recall': 0.6911111111111111,\n",
       "      'text_precision': 0.07590577734385784,\n",
       "      'text_f1': 0.13207312284258485},\n",
       "     'improvements': {'page_mrr': 0.002430569430569518,\n",
       "      'page_recall': -0.006666666666666599,\n",
       "      'page_precision': -0.002811175380060829,\n",
       "      'page_f1': -0.0031035554410840382,\n",
       "      'text_mrr': -0.0034325335540505986,\n",
       "      'text_recall': -0.013333333333333308,\n",
       "      'text_precision': 0.0022401778361530594,\n",
       "      'text_f1': 0.0035210853078892768},\n",
       "     'improvement_percentages': {'page_mrr': 0.4095328239239983,\n",
       "      'page_recall': -0.7194244604316473,\n",
       "      'page_precision': -2.7792467888030883,\n",
       "      'page_f1': -1.7950364647440862,\n",
       "      'text_mrr': -0.7891937365633255,\n",
       "      'text_recall': -1.8927444794952648,\n",
       "      'text_precision': 3.041009441481239,\n",
       "      'text_f1': 2.7390350051347516}},\n",
       "    'domain_adaptation_10k_language': {'type': 'domain_adaptation',\n",
       "     'subtype': '10k_language',\n",
       "     'filename': 'domain_adaptation_10k_language_voyage_voyage-3-large_chunk512_k20_singledoc.json',\n",
       "     'metrics': {'page_mrr': 0.5708220911641964,\n",
       "      'page_recall': 0.9077777777777777,\n",
       "      'page_precision': 0.09476951751951752,\n",
       "      'page_f1': 0.16358281003695693,\n",
       "      'text_mrr': 0.41639028564028563,\n",
       "      'text_recall': 0.6777777777777778,\n",
       "      'text_precision': 0.07278440078440078,\n",
       "      'text_f1': 0.12692537741328516},\n",
       "     'improvements': {'page_mrr': -0.02267598483387956,\n",
       "      'page_recall': -0.018888888888888955,\n",
       "      'page_precision': -0.0063793042183135085,\n",
       "      'page_f1': -0.009313702208910146,\n",
       "      'text_mrr': -0.01855152839363372,\n",
       "      'text_recall': -0.026666666666666616,\n",
       "      'text_precision': -0.0008811987233039997,\n",
       "      'text_f1': -0.0016266601214104115},\n",
       "     'improvement_percentages': {'page_mrr': -3.8207343462311534,\n",
       "      'page_recall': -2.0383693045563622,\n",
       "      'page_precision': -6.306849757328969,\n",
       "      'page_f1': -5.386865291802774,\n",
       "      'text_mrr': -4.265289699690029,\n",
       "      'text_recall': -3.7854889589905296,\n",
       "      'text_precision': -1.1962146907008258,\n",
       "      'text_f1': -1.2653709366305328}}}}],\n",
       " 'csv_data': [{'method_type': 'term_expansion',\n",
       "   'method_subtype': 'abbreviation_synonym',\n",
       "   'method_name': 'term_expansion/abbreviation_synonym',\n",
       "   'rank_page_mrr': 1,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.5632757208678262,\n",
       "   'expanded_page_recall': 0.8477777777777779,\n",
       "   'expanded_page_precision': 0.06433333333333334,\n",
       "   'expanded_page_f1': 0.11802921715965194,\n",
       "   'expanded_text_mrr': 0.4143471494392547,\n",
       "   'expanded_text_recall': 0.6255555555555555,\n",
       "   'expanded_text_precision': 0.05333333333333334,\n",
       "   'expanded_text_f1': 0.09557656406931768,\n",
       "   'delta_page_mrr': 0.0455559666511679,\n",
       "   'delta_page_recall': 0.02111111111111119,\n",
       "   'delta_page_precision': 0.00033333333333333826,\n",
       "   'delta_page_f1': 0.000688584530849426,\n",
       "   'delta_text_mrr': 0.036927492986316535,\n",
       "   'delta_text_recall': -0.00666666666666671,\n",
       "   'delta_text_precision': 0.0,\n",
       "   'delta_text_f1': -0.0002217921638211634,\n",
       "   'pct_page_mrr': 8.799348736479425,\n",
       "   'pct_page_recall': 2.5537634408602248,\n",
       "   'pct_page_precision': 0.520833333333341,\n",
       "   'pct_page_f1': 0.5868253097183367,\n",
       "   'pct_text_mrr': 9.784199724351442,\n",
       "   'pct_text_recall': -1.0544815465729418,\n",
       "   'pct_text_precision': 0.0,\n",
       "   'pct_text_f1': -0.2315198011137068},\n",
       "  {'method_type': 'query_refinement',\n",
       "   'method_subtype': 'formal',\n",
       "   'method_name': 'query_refinement/formal',\n",
       "   'rank_page_mrr': 2,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.5593700863406745,\n",
       "   'expanded_page_recall': 0.8355555555555555,\n",
       "   'expanded_page_precision': 0.06366666666666668,\n",
       "   'expanded_page_f1': 0.11683591770548292,\n",
       "   'expanded_text_mrr': 0.40895395929606454,\n",
       "   'expanded_text_recall': 0.6255555555555555,\n",
       "   'expanded_text_precision': 0.05533333333333334,\n",
       "   'expanded_text_f1': 0.09888919346890361,\n",
       "   'delta_page_mrr': 0.041650332124016254,\n",
       "   'delta_page_recall': 0.008888888888888835,\n",
       "   'delta_page_precision': -0.0003333333333333244,\n",
       "   'delta_page_f1': -0.0005047149233195908,\n",
       "   'delta_text_mrr': 0.03153430284312636,\n",
       "   'delta_text_recall': -0.00666666666666671,\n",
       "   'delta_text_precision': 0.0020000000000000018,\n",
       "   'delta_text_f1': 0.003090837235764768,\n",
       "   'pct_page_mrr': 8.04495709981856,\n",
       "   'pct_page_recall': 1.0752688172042946,\n",
       "   'pct_page_precision': -0.5208333333333194,\n",
       "   'pct_page_f1': -0.4301280059706301,\n",
       "   'pct_text_mrr': 8.355235956571988,\n",
       "   'pct_text_recall': -1.0544815465729418,\n",
       "   'pct_text_precision': 3.7500000000000036,\n",
       "   'pct_text_f1': 3.2263990294810267},\n",
       "  {'method_type': 'term_expansion',\n",
       "   'method_subtype': 'context_addition',\n",
       "   'method_name': 'term_expansion/context_addition',\n",
       "   'rank_page_mrr': 3,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.5283078403078403,\n",
       "   'expanded_page_recall': 0.8277777777777778,\n",
       "   'expanded_page_precision': 0.06366666666666668,\n",
       "   'expanded_page_f1': 0.11652984696462956,\n",
       "   'expanded_text_mrr': 0.38779552854552857,\n",
       "   'expanded_text_recall': 0.6255555555555555,\n",
       "   'expanded_text_precision': 0.051666666666666666,\n",
       "   'expanded_text_f1': 0.09314015024159951,\n",
       "   'delta_page_mrr': 0.010588086091182003,\n",
       "   'delta_page_recall': 0.0011111111111111738,\n",
       "   'delta_page_precision': -0.0003333333333333244,\n",
       "   'delta_page_f1': -0.0008107856641729472,\n",
       "   'delta_text_mrr': 0.010375872092590388,\n",
       "   'delta_text_recall': -0.00666666666666671,\n",
       "   'delta_text_precision': -0.0016666666666666705,\n",
       "   'delta_text_f1': -0.0026582059915393336,\n",
       "   'pct_page_mrr': 2.045138514600901,\n",
       "   'pct_page_recall': 0.1344086021505452,\n",
       "   'pct_page_precision': -0.5208333333333194,\n",
       "   'pct_page_f1': -0.6909675242145671,\n",
       "   'pct_text_mrr': 2.7491604942108236,\n",
       "   'pct_text_recall': -1.0544815465729418,\n",
       "   'pct_text_precision': -3.125000000000007,\n",
       "   'pct_text_f1': -2.7747929046613424},\n",
       "  {'method_type': 'query_refinement',\n",
       "   'method_subtype': 'clarification',\n",
       "   'method_name': 'query_refinement/clarification',\n",
       "   'rank_page_mrr': 4,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.5220091814503579,\n",
       "   'expanded_page_recall': 0.8188888888888889,\n",
       "   'expanded_page_precision': 0.06266666666666666,\n",
       "   'expanded_page_f1': 0.11503216590173113,\n",
       "   'expanded_text_mrr': 0.38195226926496273,\n",
       "   'expanded_text_recall': 0.6155555555555555,\n",
       "   'expanded_text_precision': 0.053,\n",
       "   'expanded_text_f1': 0.09481867461577606,\n",
       "   'delta_page_mrr': 0.0042894272336996275,\n",
       "   'delta_page_recall': -0.007777777777777772,\n",
       "   'delta_page_precision': -0.0013333333333333391,\n",
       "   'delta_page_f1': -0.0023084667270713843,\n",
       "   'delta_text_mrr': 0.00453261281202455,\n",
       "   'delta_text_recall': -0.01666666666666672,\n",
       "   'delta_text_precision': -0.00033333333333333826,\n",
       "   'delta_text_f1': -0.000979681617362782,\n",
       "   'pct_page_mrr': 0.8285229989320755,\n",
       "   'pct_page_recall': -0.9408602150537628,\n",
       "   'pct_page_precision': -2.0833333333333424,\n",
       "   'pct_page_f1': -1.9673208464573648,\n",
       "   'pct_text_mrr': 1.2009477340483294,\n",
       "   'pct_text_recall': -2.6362038664323455,\n",
       "   'pct_text_precision': -0.6250000000000092,\n",
       "   'pct_text_f1': -1.0226497153861265},\n",
       "  {'method_type': 'chain_of_thought',\n",
       "   'method_subtype': 'explicit_context',\n",
       "   'method_name': 'chain_of_thought/explicit_context',\n",
       "   'rank_page_mrr': 5,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.5190317820580979,\n",
       "   'expanded_page_recall': 0.8288888888888889,\n",
       "   'expanded_page_precision': 0.064,\n",
       "   'expanded_page_f1': 0.11733343950735256,\n",
       "   'expanded_text_mrr': 0.3930936899357952,\n",
       "   'expanded_text_recall': 0.6222222222222222,\n",
       "   'expanded_text_precision': 0.052333333333333336,\n",
       "   'expanded_text_f1': 0.0941213912228405,\n",
       "   'delta_page_mrr': 0.001312027841439578,\n",
       "   'delta_page_recall': 0.0022222222222222365,\n",
       "   'delta_page_precision': 0.0,\n",
       "   'delta_page_f1': -7.19312144994988e-06,\n",
       "   'delta_text_mrr': 0.015674033482857008,\n",
       "   'delta_text_recall': -0.010000000000000009,\n",
       "   'delta_text_precision': -0.0010000000000000009,\n",
       "   'delta_text_f1': -0.001676965010298348,\n",
       "   'pct_page_mrr': 0.2534243344499683,\n",
       "   'pct_page_recall': 0.268817204301077,\n",
       "   'pct_page_precision': 0.0,\n",
       "   'pct_page_f1': -0.006130119881579922,\n",
       "   'pct_text_mrr': 4.152945723644751,\n",
       "   'pct_text_recall': -1.581722319859404,\n",
       "   'pct_text_precision': -1.8750000000000018,\n",
       "   'pct_text_f1': -1.7505154328715375},\n",
       "  {'method_type': 'domain_adaptation',\n",
       "   'method_subtype': 'accounting_perspective',\n",
       "   'method_name': 'domain_adaptation/accounting_perspective',\n",
       "   'rank_page_mrr': 6,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.5088232683495841,\n",
       "   'expanded_page_recall': 0.85,\n",
       "   'expanded_page_precision': 0.06366666666666668,\n",
       "   'expanded_page_f1': 0.11713093669615408,\n",
       "   'expanded_text_mrr': 0.3685856078619237,\n",
       "   'expanded_text_recall': 0.6344444444444445,\n",
       "   'expanded_text_precision': 0.054,\n",
       "   'expanded_text_f1': 0.09684138620370504,\n",
       "   'delta_page_mrr': -0.008896485867074144,\n",
       "   'delta_page_recall': 0.023333333333333317,\n",
       "   'delta_page_precision': -0.0003333333333333244,\n",
       "   'delta_page_f1': -0.00020969593264842656,\n",
       "   'delta_text_mrr': -0.008834048591014498,\n",
       "   'delta_text_recall': 0.0022222222222222365,\n",
       "   'delta_text_precision': 0.0006666666666666626,\n",
       "   'delta_text_f1': 0.0010430299705661977,\n",
       "   'pct_page_mrr': -1.7183979932415507,\n",
       "   'pct_page_recall': 2.8225806451612887,\n",
       "   'pct_page_precision': -0.5208333333333194,\n",
       "   'pct_page_f1': -0.17870700707041737,\n",
       "   'pct_text_mrr': -2.3406434826523266,\n",
       "   'pct_text_recall': 0.35149384885764723,\n",
       "   'pct_text_precision': 1.2499999999999925,\n",
       "   'pct_text_f1': 1.0887764796588335},\n",
       "  {'method_type': 'domain_adaptation',\n",
       "   'method_subtype': '10k_language',\n",
       "   'method_name': 'domain_adaptation/10k_language',\n",
       "   'rank_page_mrr': 7,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.4927726347726348,\n",
       "   'expanded_page_recall': 0.7955555555555556,\n",
       "   'expanded_page_precision': 0.05866666666666667,\n",
       "   'expanded_page_f1': 0.10795393012784317,\n",
       "   'expanded_text_mrr': 0.35929743988954516,\n",
       "   'expanded_text_recall': 0.5955555555555555,\n",
       "   'expanded_text_precision': 0.05066666666666667,\n",
       "   'expanded_text_f1': 0.091079500209935,\n",
       "   'delta_page_mrr': -0.024947119444023502,\n",
       "   'delta_page_recall': -0.03111111111111109,\n",
       "   'delta_page_precision': -0.005333333333333329,\n",
       "   'delta_page_f1': -0.00938670250095934,\n",
       "   'delta_text_mrr': -0.018122216563393023,\n",
       "   'delta_text_recall': -0.036666666666666736,\n",
       "   'delta_text_precision': -0.0026666666666666644,\n",
       "   'delta_text_f1': -0.004718856023203849,\n",
       "   'pct_page_mrr': -4.818653188493846,\n",
       "   'pct_page_recall': -3.7634408602150513,\n",
       "   'pct_page_precision': -8.333333333333325,\n",
       "   'pct_page_f1': -7.999532890412654,\n",
       "   'pct_text_mrr': -4.801609098399661,\n",
       "   'pct_text_recall': -5.799648506151153,\n",
       "   'pct_text_precision': -4.999999999999996,\n",
       "   'pct_text_f1': -4.925821495015891},\n",
       "  {'method_type': 'query_refinement',\n",
       "   'method_subtype': 'keyword_focused',\n",
       "   'method_name': 'query_refinement/keyword_focused',\n",
       "   'rank_page_mrr': 8,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.47265950034371085,\n",
       "   'expanded_page_recall': 0.8222222222222222,\n",
       "   'expanded_page_precision': 0.06266666666666666,\n",
       "   'expanded_page_f1': 0.1150479954827781,\n",
       "   'expanded_text_mrr': 0.3543193617241605,\n",
       "   'expanded_text_recall': 0.6388888888888888,\n",
       "   'expanded_text_precision': 0.054,\n",
       "   'expanded_text_f1': 0.09688505268215412,\n",
       "   'delta_page_mrr': -0.04506025387294743,\n",
       "   'delta_page_recall': -0.004444444444444473,\n",
       "   'delta_page_precision': -0.0013333333333333391,\n",
       "   'delta_page_f1': -0.002292637146024415,\n",
       "   'delta_text_mrr': -0.02310029472877767,\n",
       "   'delta_text_recall': 0.006666666666666599,\n",
       "   'delta_text_precision': 0.0006666666666666626,\n",
       "   'delta_text_f1': 0.0010866964490152814,\n",
       "   'pct_page_mrr': -8.703599487163931,\n",
       "   'pct_page_recall': -0.537634408602154,\n",
       "   'pct_page_precision': -2.0833333333333424,\n",
       "   'pct_page_f1': -1.953830565475972,\n",
       "   'pct_text_mrr': -6.120586019784619,\n",
       "   'pct_text_recall': 1.0544815465729243,\n",
       "   'pct_text_precision': 1.2499999999999925,\n",
       "   'pct_text_f1': 1.1343581369712148},\n",
       "  {'method_type': 'hyde',\n",
       "   'method_subtype': 'basic',\n",
       "   'method_name': 'hyde/basic',\n",
       "   'rank_page_mrr': 9,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.4129570456776339,\n",
       "   'expanded_page_recall': 0.7322222222222222,\n",
       "   'expanded_page_precision': 0.05733333333333333,\n",
       "   'expanded_page_f1': 0.10486730660643703,\n",
       "   'expanded_text_mrr': 0.2736495448995449,\n",
       "   'expanded_text_recall': 0.55,\n",
       "   'expanded_text_precision': 0.03966666666666667,\n",
       "   'expanded_text_f1': 0.07298764037894473,\n",
       "   'delta_page_mrr': -0.10476270853902436,\n",
       "   'delta_page_recall': -0.09444444444444444,\n",
       "   'delta_page_precision': -0.006666666666666668,\n",
       "   'delta_page_f1': -0.012473326022365477,\n",
       "   'delta_text_mrr': -0.10377011155339327,\n",
       "   'delta_text_recall': -0.0822222222222222,\n",
       "   'delta_text_precision': -0.013666666666666667,\n",
       "   'delta_text_f1': -0.022810715854194114,\n",
       "   'pct_page_mrr': -20.235408768115633,\n",
       "   'pct_page_recall': -11.424731182795698,\n",
       "   'pct_page_precision': -10.416666666666668,\n",
       "   'pct_page_f1': -10.630014295068465,\n",
       "   'pct_text_mrr': -27.49462296920212,\n",
       "   'pct_text_recall': -13.00527240773286,\n",
       "   'pct_text_precision': -25.624999999999996,\n",
       "   'pct_text_f1': -23.811176674765704},\n",
       "  {'method_type': 'hyde',\n",
       "   'method_subtype': 'financial_terminology',\n",
       "   'method_name': 'hyde/financial_terminology',\n",
       "   'rank_page_mrr': 10,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.3938531797579785,\n",
       "   'expanded_page_recall': 0.7144444444444444,\n",
       "   'expanded_page_precision': 0.05533333333333334,\n",
       "   'expanded_page_f1': 0.10156597026162242,\n",
       "   'expanded_text_mrr': 0.24688075091403264,\n",
       "   'expanded_text_recall': 0.5233333333333333,\n",
       "   'expanded_text_precision': 0.035,\n",
       "   'expanded_text_f1': 0.06482025221155656,\n",
       "   'delta_page_mrr': -0.12386657445867977,\n",
       "   'delta_page_recall': -0.11222222222222222,\n",
       "   'delta_page_precision': -0.008666666666666663,\n",
       "   'delta_page_f1': -0.015774662367180087,\n",
       "   'delta_text_mrr': -0.13053890553890554,\n",
       "   'delta_text_recall': -0.10888888888888892,\n",
       "   'delta_text_precision': -0.018333333333333333,\n",
       "   'delta_text_f1': -0.030978104021582284,\n",
       "   'pct_page_mrr': -23.925410118085505,\n",
       "   'pct_page_recall': -13.5752688172043,\n",
       "   'pct_page_precision': -13.54166666666666,\n",
       "   'pct_page_f1': -13.44347819998716,\n",
       "   'pct_text_mrr': -34.58720374178045,\n",
       "   'pct_text_recall': -17.22319859402461,\n",
       "   'pct_text_precision': -34.375,\n",
       "   'pct_text_f1': -32.33678033701611},\n",
       "  {'method_type': 'hyde',\n",
       "   'method_subtype': 'detailed',\n",
       "   'method_name': 'hyde/detailed',\n",
       "   'rank_page_mrr': 11,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.38371980728250077,\n",
       "   'expanded_page_recall': 0.7311111111111112,\n",
       "   'expanded_page_precision': 0.056,\n",
       "   'expanded_page_f1': 0.10282075412510196,\n",
       "   'expanded_text_mrr': 0.2412645653566706,\n",
       "   'expanded_text_recall': 0.5333333333333333,\n",
       "   'expanded_text_precision': 0.03766666666666667,\n",
       "   'expanded_text_f1': 0.06935190413451284,\n",
       "   'delta_page_mrr': -0.1339999469341575,\n",
       "   'delta_page_recall': -0.0955555555555555,\n",
       "   'delta_page_precision': -0.008,\n",
       "   'delta_page_f1': -0.014519878503700553,\n",
       "   'delta_text_mrr': -0.13615509109626758,\n",
       "   'delta_text_recall': -0.09888888888888892,\n",
       "   'delta_text_precision': -0.01566666666666667,\n",
       "   'delta_text_f1': -0.026446452098626005,\n",
       "   'pct_page_mrr': -25.88271856400528,\n",
       "   'pct_page_recall': -11.55913978494623,\n",
       "   'pct_page_precision': -12.5,\n",
       "   'pct_page_f1': -12.374126658778977,\n",
       "   'pct_text_mrr': -36.075251717379814,\n",
       "   'pct_text_recall': -15.641476274165205,\n",
       "   'pct_text_precision': -29.375,\n",
       "   'pct_text_f1': -27.606373573117292},\n",
       "  {'method_type': 'chain_of_thought',\n",
       "   'method_subtype': 'step_by_step',\n",
       "   'method_name': 'chain_of_thought/step_by_step',\n",
       "   'rank_page_mrr': 12,\n",
       "   'mode': 'global',\n",
       "   'baseline_page_mrr': 0.5177197542166583,\n",
       "   'baseline_page_recall': 0.8266666666666667,\n",
       "   'baseline_page_precision': 0.064,\n",
       "   'baseline_page_f1': 0.11734063262880251,\n",
       "   'baseline_text_mrr': 0.3774196564529382,\n",
       "   'baseline_text_recall': 0.6322222222222222,\n",
       "   'baseline_text_precision': 0.05333333333333334,\n",
       "   'baseline_text_f1': 0.09579835623313884,\n",
       "   'expanded_page_mrr': 0.37676202773261597,\n",
       "   'expanded_page_recall': 0.7322222222222222,\n",
       "   'expanded_page_precision': 0.05533333333333334,\n",
       "   'expanded_page_f1': 0.10166447079490558,\n",
       "   'expanded_text_mrr': 0.24557941405000225,\n",
       "   'expanded_text_recall': 0.55,\n",
       "   'expanded_text_precision': 0.03933333333333334,\n",
       "   'expanded_text_f1': 0.0722818244557375,\n",
       "   'delta_page_mrr': -0.1409577264840423,\n",
       "   'delta_page_recall': -0.09444444444444444,\n",
       "   'delta_page_precision': -0.008666666666666663,\n",
       "   'delta_page_f1': -0.01567616183389693,\n",
       "   'delta_text_mrr': -0.13184024240293593,\n",
       "   'delta_text_recall': -0.0822222222222222,\n",
       "   'delta_text_precision': -0.013999999999999999,\n",
       "   'delta_text_f1': -0.023516531777401345,\n",
       "   'pct_page_mrr': -27.226646334428555,\n",
       "   'pct_page_recall': -11.424731182795698,\n",
       "   'pct_page_precision': -13.54166666666666,\n",
       "   'pct_page_f1': -13.359534104002307,\n",
       "   'pct_text_mrr': -34.932002122516785,\n",
       "   'pct_text_recall': -13.00527240773286,\n",
       "   'pct_text_precision': -26.249999999999996,\n",
       "   'pct_text_f1': -24.54794915287538},\n",
       "  {'method_type': 'term_expansion',\n",
       "   'method_subtype': 'abbreviation_synonym',\n",
       "   'method_name': 'term_expansion/abbreviation_synonym',\n",
       "   'rank_page_mrr': 1,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.6355018315018315,\n",
       "   'expanded_page_recall': 0.9111111111111111,\n",
       "   'expanded_page_precision': 0.09550158893966944,\n",
       "   'expanded_page_f1': 0.16545852124772573,\n",
       "   'expanded_text_mrr': 0.4677716727716728,\n",
       "   'expanded_text_recall': 0.6922222222222222,\n",
       "   'expanded_text_precision': 0.07264409799007322,\n",
       "   'expanded_text_f1': 0.12700533134391437,\n",
       "   'delta_page_mrr': 0.04200375550375557,\n",
       "   'delta_page_recall': -0.015555555555555545,\n",
       "   'delta_page_precision': -0.005647232798161594,\n",
       "   'delta_page_f1': -0.007437990998141353,\n",
       "   'delta_text_mrr': 0.03282985873775346,\n",
       "   'delta_text_recall': -0.012222222222222245,\n",
       "   'delta_text_precision': -0.0010215015176315567,\n",
       "   'delta_text_f1': -0.0015467061907812052,\n",
       "   'pct_page_mrr': 7.0773195739714145,\n",
       "   'pct_page_recall': -1.6786570743405265,\n",
       "   'pct_page_precision': -5.5830930119964535,\n",
       "   'pct_page_f1': -4.301990191429758,\n",
       "   'pct_text_mrr': 7.548103603392152,\n",
       "   'pct_text_recall': -1.7350157728706659,\n",
       "   'pct_text_precision': -1.3866737316441937,\n",
       "   'pct_text_f1': -1.2031751658263345},\n",
       "  {'method_type': 'query_refinement',\n",
       "   'method_subtype': 'formal',\n",
       "   'method_name': 'query_refinement/formal',\n",
       "   'rank_page_mrr': 2,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.6281988896036883,\n",
       "   'expanded_page_recall': 0.93,\n",
       "   'expanded_page_precision': 0.09776051617228088,\n",
       "   'expanded_page_f1': 0.16830805254097178,\n",
       "   'expanded_text_mrr': 0.45667845974115323,\n",
       "   'expanded_text_recall': 0.6977777777777778,\n",
       "   'expanded_text_precision': 0.07509812300988772,\n",
       "   'expanded_text_f1': 0.1305872104726145,\n",
       "   'delta_page_mrr': 0.03470081360561239,\n",
       "   'delta_page_recall': 0.0033333333333334103,\n",
       "   'delta_page_precision': -0.0033883055655501565,\n",
       "   'delta_page_f1': -0.004588459704895298,\n",
       "   'delta_text_mrr': 0.02173664570723388,\n",
       "   'delta_text_recall': -0.006666666666666599,\n",
       "   'delta_text_precision': 0.0014325235021829391,\n",
       "   'delta_text_f1': 0.0020351729379189387,\n",
       "   'pct_page_mrr': 5.8468283232859015,\n",
       "   'pct_page_recall': 0.35971223021583565,\n",
       "   'pct_page_precision': -3.349822081301501,\n",
       "   'pct_page_f1': -2.653876382636504,\n",
       "   'pct_text_mrr': 4.997598530625232,\n",
       "   'pct_text_recall': -0.9463722397476244,\n",
       "   'pct_text_precision': 1.944630209699318,\n",
       "   'pct_text_f1': 1.583151054583367},\n",
       "  {'method_type': 'query_refinement',\n",
       "   'method_subtype': 'clarification',\n",
       "   'method_name': 'query_refinement/clarification',\n",
       "   'rank_page_mrr': 3,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.6006501334922387,\n",
       "   'expanded_page_recall': 0.9144444444444444,\n",
       "   'expanded_page_precision': 0.09694559754544274,\n",
       "   'expanded_page_f1': 0.16559901850854294,\n",
       "   'expanded_text_mrr': 0.44146849446849445,\n",
       "   'expanded_text_recall': 0.6844444444444445,\n",
       "   'expanded_text_precision': 0.07319789401058752,\n",
       "   'expanded_text_f1': 0.12734520701492477,\n",
       "   'delta_page_mrr': 0.007152057494162811,\n",
       "   'delta_page_recall': -0.012222222222222245,\n",
       "   'delta_page_precision': -0.004203224192388291,\n",
       "   'delta_page_f1': -0.007297493737324134,\n",
       "   'delta_text_mrr': 0.006526680434575105,\n",
       "   'delta_text_recall': -0.019999999999999907,\n",
       "   'delta_text_precision': -0.00046770549711726284,\n",
       "   'delta_text_f1': -0.0012068305197708018,\n",
       "   'pct_page_mrr': 1.2050683537828348,\n",
       "   'pct_page_recall': -1.3189448441247027,\n",
       "   'pct_page_precision': -4.155485076516941,\n",
       "   'pct_page_f1': -4.220729292067356,\n",
       "   'pct_text_mrr': 1.5005870265823915,\n",
       "   'pct_text_recall': -2.839116719242889,\n",
       "   'pct_text_precision': -0.6349035373944726,\n",
       "   'pct_text_f1': -0.9387875469846864},\n",
       "  {'method_type': 'domain_adaptation',\n",
       "   'method_subtype': 'accounting_perspective',\n",
       "   'method_name': 'domain_adaptation/accounting_perspective',\n",
       "   'rank_page_mrr': 4,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.5959286454286454,\n",
       "   'expanded_page_recall': 0.92,\n",
       "   'expanded_page_precision': 0.0983376463577702,\n",
       "   'expanded_page_f1': 0.16979295680478304,\n",
       "   'expanded_text_mrr': 0.43150928047986875,\n",
       "   'expanded_text_recall': 0.6911111111111111,\n",
       "   'expanded_text_precision': 0.07590577734385784,\n",
       "   'expanded_text_f1': 0.13207312284258485,\n",
       "   'delta_page_mrr': 0.002430569430569518,\n",
       "   'delta_page_recall': -0.006666666666666599,\n",
       "   'delta_page_precision': -0.002811175380060829,\n",
       "   'delta_page_f1': -0.0031035554410840382,\n",
       "   'delta_text_mrr': -0.0034325335540505986,\n",
       "   'delta_text_recall': -0.013333333333333308,\n",
       "   'delta_text_precision': 0.0022401778361530594,\n",
       "   'delta_text_f1': 0.0035210853078892768,\n",
       "   'pct_page_mrr': 0.4095328239239983,\n",
       "   'pct_page_recall': -0.7194244604316473,\n",
       "   'pct_page_precision': -2.7792467888030883,\n",
       "   'pct_page_f1': -1.7950364647440862,\n",
       "   'pct_text_mrr': -0.7891937365633255,\n",
       "   'pct_text_recall': -1.8927444794952648,\n",
       "   'pct_text_precision': 3.041009441481239,\n",
       "   'pct_text_f1': 2.7390350051347516},\n",
       "  {'method_type': 'term_expansion',\n",
       "   'method_subtype': 'context_addition',\n",
       "   'method_name': 'term_expansion/context_addition',\n",
       "   'rank_page_mrr': 5,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.5880268771189824,\n",
       "   'expanded_page_recall': 0.93,\n",
       "   'expanded_page_precision': 0.10277827435722173,\n",
       "   'expanded_page_f1': 0.17527870346814445,\n",
       "   'expanded_text_mrr': 0.4361350494477429,\n",
       "   'expanded_text_recall': 0.7111111111111111,\n",
       "   'expanded_text_precision': 0.07364350951193056,\n",
       "   'expanded_text_f1': 0.12879699156645358,\n",
       "   'delta_page_mrr': -0.005471198879093531,\n",
       "   'delta_page_recall': 0.0033333333333334103,\n",
       "   'delta_page_precision': 0.001629452619390695,\n",
       "   'delta_page_f1': 0.002382191222277369,\n",
       "   'delta_text_mrr': 0.0011932354138235457,\n",
       "   'delta_text_recall': 0.00666666666666671,\n",
       "   'delta_text_precision': -2.2089995774215998e-05,\n",
       "   'delta_text_f1': 0.00024495403175800456,\n",
       "   'pct_page_mrr': -0.9218562115627259,\n",
       "   'pct_page_recall': 0.35971223021583565,\n",
       "   'pct_page_precision': 1.6109457247204468,\n",
       "   'pct_page_f1': 1.377813347032576,\n",
       "   'pct_text_mrr': 0.2743436881261755,\n",
       "   'pct_text_recall': 0.9463722397476402,\n",
       "   'pct_text_precision': -0.02998685400219349,\n",
       "   'pct_text_f1': 0.19054854085209863},\n",
       "  {'method_type': 'chain_of_thought',\n",
       "   'method_subtype': 'explicit_context',\n",
       "   'method_name': 'chain_of_thought/explicit_context',\n",
       "   'rank_page_mrr': 6,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.5878943953649836,\n",
       "   'expanded_page_recall': 0.8966666666666666,\n",
       "   'expanded_page_precision': 0.09595767682609789,\n",
       "   'expanded_page_f1': 0.16356779280071207,\n",
       "   'expanded_text_mrr': 0.4426526460868566,\n",
       "   'expanded_text_recall': 0.6844444444444445,\n",
       "   'expanded_text_precision': 0.07284765818976345,\n",
       "   'expanded_text_f1': 0.12668230427650717,\n",
       "   'delta_page_mrr': -0.005603680633092356,\n",
       "   'delta_page_recall': -0.030000000000000027,\n",
       "   'delta_page_precision': -0.005191144911733142,\n",
       "   'delta_page_f1': -0.00932871944515501,\n",
       "   'delta_text_mrr': 0.0077108320529372665,\n",
       "   'delta_text_recall': -0.019999999999999907,\n",
       "   'delta_text_precision': -0.0008179413179413286,\n",
       "   'delta_text_f1': -0.0018697332581883996,\n",
       "   'pct_page_mrr': -0.9441783991748818,\n",
       "   'pct_page_recall': -3.237410071942449,\n",
       "   'pct_page_precision': -5.132185251933175,\n",
       "   'pct_page_f1': -5.395550970912083,\n",
       "   'pct_text_mrr': 1.7728422065062546,\n",
       "   'pct_text_recall': -2.839116719242889,\n",
       "   'pct_text_precision': -1.1103436657103145,\n",
       "   'pct_text_f1': -1.4544563384954265},\n",
       "  {'method_type': 'domain_adaptation',\n",
       "   'method_subtype': '10k_language',\n",
       "   'method_name': 'domain_adaptation/10k_language',\n",
       "   'rank_page_mrr': 7,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.5708220911641964,\n",
       "   'expanded_page_recall': 0.9077777777777777,\n",
       "   'expanded_page_precision': 0.09476951751951752,\n",
       "   'expanded_page_f1': 0.16358281003695693,\n",
       "   'expanded_text_mrr': 0.41639028564028563,\n",
       "   'expanded_text_recall': 0.6777777777777778,\n",
       "   'expanded_text_precision': 0.07278440078440078,\n",
       "   'expanded_text_f1': 0.12692537741328516,\n",
       "   'delta_page_mrr': -0.02267598483387956,\n",
       "   'delta_page_recall': -0.018888888888888955,\n",
       "   'delta_page_precision': -0.0063793042183135085,\n",
       "   'delta_page_f1': -0.009313702208910146,\n",
       "   'delta_text_mrr': -0.01855152839363372,\n",
       "   'delta_text_recall': -0.026666666666666616,\n",
       "   'delta_text_precision': -0.0008811987233039997,\n",
       "   'delta_text_f1': -0.0016266601214104115,\n",
       "   'pct_page_mrr': -3.8207343462311534,\n",
       "   'pct_page_recall': -2.0383693045563622,\n",
       "   'pct_page_precision': -6.306849757328969,\n",
       "   'pct_page_f1': -5.386865291802774,\n",
       "   'pct_text_mrr': -4.265289699690029,\n",
       "   'pct_text_recall': -3.7854889589905296,\n",
       "   'pct_text_precision': -1.1962146907008258,\n",
       "   'pct_text_f1': -1.2653709366305328},\n",
       "  {'method_type': 'query_refinement',\n",
       "   'method_subtype': 'keyword_focused',\n",
       "   'method_name': 'query_refinement/keyword_focused',\n",
       "   'rank_page_mrr': 8,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.5649762644762645,\n",
       "   'expanded_page_recall': 0.9211111111111111,\n",
       "   'expanded_page_precision': 0.0974464454247736,\n",
       "   'expanded_page_f1': 0.16781658251376344,\n",
       "   'expanded_text_mrr': 0.4171644771350653,\n",
       "   'expanded_text_recall': 0.7,\n",
       "   'expanded_text_precision': 0.07475402810696928,\n",
       "   'expanded_text_f1': 0.13006163356659162,\n",
       "   'delta_page_mrr': -0.028521811521811435,\n",
       "   'delta_page_recall': -0.005555555555555536,\n",
       "   'delta_page_precision': -0.0037023763130574344,\n",
       "   'delta_page_f1': -0.0050799297321036385,\n",
       "   'delta_text_mrr': -0.017777336898854024,\n",
       "   'delta_text_recall': -0.004444444444444473,\n",
       "   'delta_text_precision': 0.0010884285992645015,\n",
       "   'delta_text_f1': 0.0015095960318960433,\n",
       "   'pct_page_mrr': -4.80571254992643,\n",
       "   'pct_page_recall': -0.5995203836930435,\n",
       "   'pct_page_precision': -3.660325695788798,\n",
       "   'pct_page_f1': -2.938133144571324,\n",
       "   'pct_text_mrr': -4.087290834140781,\n",
       "   'pct_text_recall': -0.6309148264984268,\n",
       "   'pct_text_precision': 1.477526289799164,\n",
       "   'pct_text_f1': 1.1743073550962664},\n",
       "  {'method_type': 'hyde',\n",
       "   'method_subtype': 'basic',\n",
       "   'method_name': 'hyde/basic',\n",
       "   'rank_page_mrr': 9,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.517060273060273,\n",
       "   'expanded_page_recall': 0.8755555555555556,\n",
       "   'expanded_page_precision': 0.09636991952549229,\n",
       "   'expanded_page_f1': 0.16504001666560558,\n",
       "   'expanded_text_mrr': 0.3567647907647908,\n",
       "   'expanded_text_recall': 0.6577777777777778,\n",
       "   'expanded_text_precision': 0.062445117919576125,\n",
       "   'expanded_text_f1': 0.11062169397667669,\n",
       "   'delta_page_mrr': -0.07643780293780289,\n",
       "   'delta_page_recall': -0.051111111111110996,\n",
       "   'delta_page_precision': -0.004778902212338745,\n",
       "   'delta_page_f1': -0.007856495580261497,\n",
       "   'delta_text_mrr': -0.07817702326912856,\n",
       "   'delta_text_recall': -0.046666666666666634,\n",
       "   'delta_text_precision': -0.011220481588128654,\n",
       "   'delta_text_f1': -0.017930343558018882,\n",
       "   'pct_page_mrr': -12.879199786664634,\n",
       "   'pct_page_recall': -5.515587529976007,\n",
       "   'pct_page_precision': -4.724624696791076,\n",
       "   'pct_page_f1': -4.5440451505980555,\n",
       "   'pct_text_mrr': -17.974133722409096,\n",
       "   'pct_text_recall': -6.624605678233434,\n",
       "   'pct_text_precision': -15.231643620785427,\n",
       "   'pct_text_f1': -13.94792638209221},\n",
       "  {'method_type': 'hyde',\n",
       "   'method_subtype': 'financial_terminology',\n",
       "   'method_name': 'hyde/financial_terminology',\n",
       "   'rank_page_mrr': 10,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.4964062326562327,\n",
       "   'expanded_page_recall': 0.8566666666666667,\n",
       "   'expanded_page_precision': 0.09637613828093704,\n",
       "   'expanded_page_f1': 0.1642809334064358,\n",
       "   'expanded_text_mrr': 0.31906815678874506,\n",
       "   'expanded_text_recall': 0.6488888888888888,\n",
       "   'expanded_text_precision': 0.059086048454469506,\n",
       "   'expanded_text_f1': 0.10525156302578118,\n",
       "   'delta_page_mrr': -0.09709184334184323,\n",
       "   'delta_page_recall': -0.06999999999999995,\n",
       "   'delta_page_precision': -0.004772683456893995,\n",
       "   'delta_page_f1': -0.008615578839431287,\n",
       "   'delta_text_mrr': -0.11587365724517429,\n",
       "   'delta_text_recall': -0.05555555555555558,\n",
       "   'delta_text_precision': -0.014579551053235273,\n",
       "   'delta_text_f1': -0.0233004745089144,\n",
       "   'pct_page_mrr': -16.359251574415886,\n",
       "   'pct_page_recall': -7.553956834532369,\n",
       "   'pct_page_precision': -4.718476572336528,\n",
       "   'pct_page_f1': -4.983084232017083,\n",
       "   'pct_text_mrr': -26.641185902659103,\n",
       "   'pct_text_recall': -7.886435331230287,\n",
       "   'pct_text_precision': -19.791532480110178,\n",
       "   'pct_text_f1': -18.125324931256507},\n",
       "  {'method_type': 'hyde',\n",
       "   'method_subtype': 'detailed',\n",
       "   'method_name': 'hyde/detailed',\n",
       "   'rank_page_mrr': 11,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.49470409220409217,\n",
       "   'expanded_page_recall': 0.8433333333333334,\n",
       "   'expanded_page_precision': 0.0889797287335987,\n",
       "   'expanded_page_f1': 0.15510415051463647,\n",
       "   'expanded_text_mrr': 0.31471970553239903,\n",
       "   'expanded_text_recall': 0.6144444444444445,\n",
       "   'expanded_text_precision': 0.058398766524153524,\n",
       "   'expanded_text_f1': 0.10337973318598795,\n",
       "   'delta_page_mrr': -0.09879398379398374,\n",
       "   'delta_page_recall': -0.08333333333333326,\n",
       "   'delta_page_precision': -0.012169093004232329,\n",
       "   'delta_page_f1': -0.01779236173123061,\n",
       "   'delta_text_mrr': -0.12022210850152032,\n",
       "   'delta_text_recall': -0.08999999999999997,\n",
       "   'delta_text_precision': -0.015266832983551255,\n",
       "   'delta_text_f1': -0.025172304348707625,\n",
       "   'pct_page_mrr': -16.646049547480594,\n",
       "   'pct_page_recall': -8.992805755395676,\n",
       "   'pct_page_precision': -12.030879643633972,\n",
       "   'pct_page_f1': -10.2907580379233,\n",
       "   'pct_text_mrr': -27.640963600741475,\n",
       "   'pct_text_recall': -12.776025236593055,\n",
       "   'pct_text_precision': -20.72450789184778,\n",
       "   'pct_text_f1': -19.581412190307557},\n",
       "  {'method_type': 'chain_of_thought',\n",
       "   'method_subtype': 'step_by_step',\n",
       "   'method_name': 'chain_of_thought/step_by_step',\n",
       "   'rank_page_mrr': 12,\n",
       "   'mode': 'singledoc',\n",
       "   'baseline_page_mrr': 0.5934980759980759,\n",
       "   'baseline_page_recall': 0.9266666666666666,\n",
       "   'baseline_page_precision': 0.10114882173783103,\n",
       "   'baseline_page_f1': 0.17289651224586708,\n",
       "   'baseline_text_mrr': 0.43494181403391935,\n",
       "   'baseline_text_recall': 0.7044444444444444,\n",
       "   'baseline_text_precision': 0.07366559950770478,\n",
       "   'baseline_text_f1': 0.12855203753469557,\n",
       "   'expanded_page_mrr': 0.4716547643389749,\n",
       "   'expanded_page_recall': 0.8544444444444443,\n",
       "   'expanded_page_precision': 0.0908520343891861,\n",
       "   'expanded_page_f1': 0.15717958814640737,\n",
       "   'expanded_text_mrr': 0.3181808308650414,\n",
       "   'expanded_text_recall': 0.6477777777777778,\n",
       "   'expanded_text_precision': 0.0623859401692219,\n",
       "   'expanded_text_f1': 0.1104930711176056,\n",
       "   'delta_page_mrr': -0.121843311659101,\n",
       "   'delta_page_recall': -0.0722222222222223,\n",
       "   'delta_page_precision': -0.010296787348644934,\n",
       "   'delta_page_f1': -0.01571692409945971,\n",
       "   'delta_text_mrr': -0.11676098316887795,\n",
       "   'delta_text_recall': -0.05666666666666664,\n",
       "   'delta_text_precision': -0.011279659338482878,\n",
       "   'delta_text_f1': -0.01805896641708997,\n",
       "   'pct_page_mrr': -20.52968941039937,\n",
       "   'pct_page_recall': -7.793764988009601,\n",
       "   'pct_page_precision': -10.179839143686037,\n",
       "   'pct_page_f1': -9.0903650370399,\n",
       "   'pct_text_mrr': -26.84519616220947,\n",
       "   'pct_text_recall': -8.044164037854888,\n",
       "   'pct_text_precision': -15.311976572325491,\n",
       "   'pct_text_f1': -14.047981473818291}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate report for ollama, embed-text, chunk 512, global mode\n",
    "quick_expansion_report(provider=\"ollama\", model=\"nomic-embed-text\", chunk_size=512, k=20)\n",
    "quick_expansion_report(provider=\"voyage\", model=\"voyage-finance-2\", chunk_size=512, k=20)\n",
    "quick_expansion_report(provider=\"voyage\", model=\"voyage-3-large\", chunk_size=512, k=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
